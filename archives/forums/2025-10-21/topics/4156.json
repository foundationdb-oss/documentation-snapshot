{
  "post_stream": {
    "posts": [
      {
        "id": 13291,
        "name": null,
        "username": "stefanvasilic4",
        "avatar_template": "https://avatars.discourse-cdn.com/v4/letter/s/a8b319/{size}.png",
        "created_at": "2023-09-19T21:03:38.190Z",
        "cooked": "<p>Setup:</p>\n<ul>\n<li>\n<p>multi_dc setup with 1 k8s cluster and 3 namespaces that map to 3 dc</p>\n</li>\n<li>\n<p>dc1 serves as Primary ; dc3  - Secondary ; dc2 - Satellite</p>\n</li>\n</ul>\n<pre><code class=\"lang-auto\">Configuration:\n  Redundancy mode        - triple\n  Storage engine         - ssd-2\n  Coordinators           - 9\n  Desired Commit Proxies - 2\n  Desired GRV Proxies    - 1\n  Desired Resolvers      - 1\n  Desired Logs           - 3\n  Desired Remote Logs    - 3\n  Desired Log Routers    - 3\n  Usable Regions         - 2\n  Regions: \n    Primary -\n        Datacenter                    - dc1\n        Satellite datacenters         - dc2, dc3\n        Satellite Logs                - 3\n    Remote -\n        Datacenter                    - dc3\n        Satellite datacenters         - dc2, dc1\n        Satellite Logs                - 3\n\nCluster:\n  FoundationDB processes - 81\n  Zones                  - 47\n  Machines               - 47\n  Memory availability    - 8.0 GB per process on machine with least available\n  Retransmissions rate   - 0 Hz\n  Fault Tolerance        - 2 machines\n  Server time            - 09/17/23 01:59:16\n\nData:\n  Replication health     - Healthy\n  Moving data            - 0.000 GB\n  Sum of key-value sizes - 1.158 TB\n  Disk space used        - 8.639 TB\n</code></pre>\n<p>The problem:</p>\n<p>During a DR test, i simulated Primary dc1 going down, bringing it back up and let data being replicated back, but it\u2019s stuck at the moment (see below errors).</p>\n<ul>\n<li>i would like to understand why this happened, how to recover and how to prevent this type of situation</li>\n<li>i\u2019ve noticed that fdb operator added a storage pod in dc1 namespace , from k8s perspective how is the recovery process handled ?</li>\n</ul>\n<pre><code class=\"lang-auto\">Configuration:\n  Redundancy mode        - triple\n  Storage engine         - ssd-2\n  Coordinators           - 9\n  Desired Commit Proxies - 2\n  Desired GRV Proxies    - 1\n  Desired Resolvers      - 1\n  Desired Logs           - 3\n  Desired Remote Logs    - 3\n  Desired Log Routers    - 3\n  Usable Regions         - 2\n  Regions: \n    Remote -\n        Datacenter                    - dc1\n        Satellite datacenters         - dc2, dc3\n        Satellite Logs                - 3\n    Primary -\n        Datacenter                    - dc3\n        Satellite datacenters         - dc2, dc1\n        Satellite Logs                - 3\n\nCluster:\n  FoundationDB processes - 81 (less 0 excluded; 12 with errors)\n  Zones                  - 47\n  Machines               - 47\n  Memory availability    - 8.0 GB per process on machine with least available\n  Retransmissions rate   - 1 Hz\n  Fault Tolerance        - -1 machines\n\n  Warning: the database may have data loss and availability loss. Please restart following tlog interfaces, otherwise storage servers may never be able to catch up.\n  Old log epoch: 253 begin: 752008734932 end: 752125253003, missing log interfaces(id,address): 55cfd4bc6e3b0a8f, 9ab3ab3fdefabd20, 91fa9bbe4783efbb, \n  Old log epoch: 250 begin: 751872585983 end: 752008734932, missing log interfaces(id,address): 055aa740d22950ef, 2bfa78e37a663789, bc810043cb1a881b, \n  Old log epoch: 248 begin: 751768423814 end: 751872585983, missing log interfaces(id,address): 60b3598fd80246f7, e841f74ebd3955bb, 0e8b32bcfc4a4ae2, \n  Old log epoch: 246 begin: 751657077872 end: 751768423814, missing log interfaces(id,address): 730ccd96ca1256b0, a77e054a4e8f1279, 0c79570a7b4707d0, \n  Old log epoch: 244 begin: 751552887228 end: 751657077872, missing log interfaces(id,address): 0ed852c5e99c862c, d28c7dae960cea90, 991deec06ebdd74d, \n  Old log epoch: 242 begin: 751440887046 end: 751552887228, missing log interfaces(id,address): 15e823d14fde4dfb, 3d716439331bb3be, c82bcf34b648311e, \n  Old log epoch: 240 begin: 751332177172 end: 751440887046, missing log interfaces(id,address): 68c1e97818bf5ef4, 0abc75e178f47ee7, 81991d47565c137a, \n  Old log epoch: 237 begin: 751187559126 end: 751332177172, missing log interfaces(id,address): 1493a5a1f23cf477, 0960fcaf02bd12e3, f76dfe8ef10992f5, \n  Old log epoch: 235 begin: 751050558192 end: 751187559126, missing log interfaces(id,address): 0b38863b2b4e2ceb, 725bcab59e5c9ea0, 1de0783cc2013219, \n  Old log epoch: 233 begin: 747960335254 end: 751050558192, missing log interfaces(id,address): 3c4efb7aa938ab14, f286a82bf78eeae2, c0ce84e3fedb16c5, \n\n  Server time            - 09/17/23 14:30:07\n\nData:\n  Replication health     - (Re)initializing automatic data distribution\n  Moving data            - unknown (initializing)\n  Sum of key-value sizes - unknown\n  Disk space used        - 4.287 TB\n\nOperating space:\n  Storage server         - 1541.7 GB free on most full server\n  Log server             - 1542.0 GB free on most full server\n\nWorkload:\n  Read rate              - 56 Hz\n  Write rate             - 0 Hz\n  Transactions started   - 19 Hz\n  Transactions committed - 1 Hz\n  Conflict rate          - 0 Hz\n\nBackup and DR:\n  Running backups        - 0\n  Running DRs            - 0\n\nProcess performance details:\n  10.113.237.132:4501    (  1% cpu;  1% machine; 0.000 Gbps;  0% disk IO; 0.2 GB / 8.0 GB RAM  )\n  10.113.237.133:4501    (  1% cpu;  2% machine; 0.002 Gbps;  0% disk IO; 5.7 GB / 8.0 GB RAM  )\n  10.113.237.133:4503    (  2% cpu;  2% machine; 0.002 Gbps;  0% disk IO; 4.7 GB / 8.0 GB RAM  )\n  10.113.237.134:4501    (  1% cpu;  1% machine; 0.001 Gbps;  0% disk IO; 0.2 GB / 8.0 GB RAM  )\n    Storage server lagging by 350 seconds.\n  10.113.237.134:4503    (  0% cpu;  1% machine; 0.001 Gbps;  0% disk IO; 0.2 GB / 8.0 GB RAM  )\n  10.113.237.135:4501    (  1% cpu;  1% machine; 0.001 Gbps;  4% disk IO; 0.2 GB / 8.0 GB RAM  )\n    Storage server lagging by 342 seconds.\n  10.113.237.135:4503    (  0% cpu;  1% machine; 0.001 Gbps;  4% disk IO; 0.2 GB / 8.0 GB RAM  )\n  10.113.237.136:4501    (  1% cpu;  1% machine; 0.001 Gbps;  9% disk IO; 0.2 GB / 8.0 GB RAM  )\n    Storage server lagging by 340 seconds.\n  10.113.237.136:4503    (  1% cpu;  1% machine; 0.001 Gbps;  9% disk IO; 0.2 GB / 8.0 GB RAM  )\n    Storage server lagging by 280 seconds.\n  10.113.237.137:4501    (  0% cpu;  1% machine; 0.001 Gbps;  2% disk IO; 0.2 GB / 8.0 GB RAM  )\n  10.113.237.137:4503    (  1% cpu;  1% machine; 0.001 Gbps;  2% disk IO; 0.2 GB / 8.0 GB RAM  )\n    Storage server lagging by 280 seconds.\n  10.113.237.138:4501    (  1% cpu;  1% machine; 0.001 Gbps;  0% disk IO; 0.2 GB / 8.0 GB RAM  )\n    Storage server lagging by 280 seconds.\n  10.113.237.138:4503    (  0% cpu;  1% machine; 0.001 Gbps;  0% disk IO; 0.2 GB / 8.0 GB RAM  )\n  10.113.237.139:4501    (  0% cpu;  1% machine; 0.001 Gbps; 10% disk IO; 0.1 GB / 8.0 GB RAM  )\n  10.113.237.140:4501    (  1% cpu;  1% machine; 0.001 Gbps; 10% disk IO; 0.2 GB / 8.0 GB RAM  )\n    Storage server lagging by 249 seconds.\n  10.113.237.140:4503    (  1% cpu;  1% machine; 0.001 Gbps; 10% disk IO; 0.2 GB / 8.0 GB RAM  )\n    Storage server lagging by 249 seconds.\n  10.113.237.141:4501    (  1% cpu;  1% machine; 0.001 Gbps;  1% disk IO; 0.2 GB / 8.0 GB RAM  )\n    Storage server lagging by 250 seconds.\n  10.113.237.141:4503    (  0% cpu;  1% machine; 0.001 Gbps;  1% disk IO; 0.2 GB / 8.0 GB RAM  )\n  10.113.237.142:4501    (  0% cpu;  1% machine; 0.001 Gbps;  3% disk IO; 0.2 GB / 8.0 GB RAM  )\n    Storage server lagging by 315 seconds.\n  10.113.237.142:4503    (  1% cpu;  1% machine; 0.001 Gbps;  3% disk IO; 0.2 GB / 8.0 GB RAM  )\n    Storage server lagging by 315 seconds.\n  10.113.237.143:4501    (  0% cpu;  2% machine; 0.001 Gbps;  9% disk IO; 0.2 GB / 8.0 GB RAM  )\n  10.113.237.143:4503    (  0% cpu;  2% machine; 0.001 Gbps;  9% disk IO; 0.2 GB / 8.0 GB RAM  )\n    Storage server lagging by 250 seconds.\n  10.113.237.144:4501    (  0% cpu;  2% machine; 0.001 Gbps;  9% disk IO; 0.2 GB / 8.0 GB RAM  )\n  10.113.237.144:4503    (  0% cpu;  2% machine; 0.001 Gbps;  9% disk IO; 0.2 GB / 8.0 GB RAM  )\n  10.113.237.145:4501    (  0% cpu;  2% machine; 0.001 Gbps;  9% disk IO; 0.2 GB / 8.0 GB RAM  )\n  10.113.237.145:4503    (  0% cpu;  2% machine; 0.001 Gbps;  9% disk IO; 0.1 GB / 8.0 GB RAM  )\n  10.113.237.146:4501    (  1% cpu;  2% machine; 0.001 Gbps; 10% disk IO; 0.1 GB / 8.0 GB RAM  )\n  10.113.237.147:4501    (  1% cpu;  2% machine; 0.001 Gbps; 10% disk IO; 0.2 GB / 8.0 GB RAM  )\n  10.113.237.147:4503    (  0% cpu;  2% machine; 0.001 Gbps; 10% disk IO; 0.1 GB / 8.0 GB RAM  )\n  10.113.237.148:4501    (  0% cpu;  2% machine; 0.001 Gbps; 10% disk IO; 0.1 GB / 8.0 GB RAM  )\n  10.113.237.148:4503    (  0% cpu;  2% machine; 0.001 Gbps; 10% disk IO; 0.2 GB / 8.0 GB RAM  )\n  10.113.237.149:4501    (  0% cpu;  2% machine; 0.001 Gbps; 10% disk IO; 0.1 GB / 8.0 GB RAM  )\n  10.113.237.149:4503    (  0% cpu;  2% machine; 0.001 Gbps; 10% disk IO; 0.2 GB / 8.0 GB RAM  )\n  10.113.237.150:4501    (  0% cpu;  1% machine; 0.001 Gbps; 10% disk IO; 0.1 GB / 8.0 GB RAM  )\n  10.113.237.150:4503    (  0% cpu;  1% machine; 0.001 Gbps; 10% disk IO; 0.1 GB / 8.0 GB RAM  )\n  10.113.237.151:4501    (  0% cpu;  1% machine; 0.001 Gbps;  7% disk IO; 0.1 GB / 8.0 GB RAM  )\n  10.113.237.151:4503    (  0% cpu;  1% machine; 0.001 Gbps;  7% disk IO; 0.1 GB / 8.0 GB RAM  )\n  10.113.237.152:4501    (  0% cpu;  1% machine; 0.001 Gbps;  9% disk IO; 0.1 GB / 8.0 GB RAM  )\n  10.113.237.152:4503    (  0% cpu;  1% machine; 0.001 Gbps;  9% disk IO; 0.1 GB / 8.0 GB RAM  )\n  10.113.237.153:4501    (  1% cpu;  5% machine; 0.001 Gbps;  2% disk IO; 0.1 GB / 8.0 GB RAM  )\n  10.113.237.154:4501    (  1% cpu;  6% machine; 0.017 Gbps;  0% disk IO; 0.2 GB / 8.0 GB RAM  )\n  10.113.237.155:4501    (  1% cpu;  2% machine; 0.001 Gbps;  0% disk IO; 0.2 GB / 8.0 GB RAM  )\n  10.113.237.156:4501    (  2% cpu;  2% machine; 0.001 Gbps;  0% disk IO; 5.5 GB / 8.0 GB RAM  )\n  10.113.237.156:4503    (  1% cpu;  2% machine; 0.001 Gbps;  0% disk IO; 4.7 GB / 8.0 GB RAM  )\n  10.113.237.157:4501    (  1% cpu;  4% machine; 0.001 Gbps;  0% disk IO; 5.7 GB / 8.0 GB RAM  )\n  10.113.237.157:4503    (  1% cpu;  4% machine; 0.001 Gbps;  0% disk IO; 5.5 GB / 8.0 GB RAM  )\n  10.113.237.158:4501    (  1% cpu;  1% machine; 0.000 Gbps;  0% disk IO; 4.1 GB / 8.0 GB RAM  )\n  10.113.237.158:4503    (  1% cpu;  1% machine; 0.000 Gbps;  0% disk IO; 4.9 GB / 8.0 GB RAM  )\n  10.113.237.159:4501    (  1% cpu;  3% machine; 0.001 Gbps;  0% disk IO; 4.7 GB / 8.0 GB RAM  )\n  10.113.237.159:4503    (  1% cpu;  3% machine; 0.001 Gbps;  0% disk IO; 4.7 GB / 8.0 GB RAM  )\n  10.113.237.160:4501    (  1% cpu;  1% machine; 0.000 Gbps;  0% disk IO; 4.7 GB / 8.0 GB RAM  )\n  10.113.237.160:4503    (  1% cpu;  1% machine; 0.000 Gbps;  0% disk IO; 4.7 GB / 8.0 GB RAM  )\n  10.113.237.161:4501    (  1% cpu;  1% machine; 0.001 Gbps;  0% disk IO; 5.5 GB / 8.0 GB RAM  )\n  10.113.237.161:4503    (  1% cpu;  1% machine; 0.001 Gbps;  0% disk IO; 4.7 GB / 8.0 GB RAM  )\n  10.113.237.162:4501    (  1% cpu;  1% machine; 0.001 Gbps;  0% disk IO; 5.5 GB / 8.0 GB RAM  )\n  10.113.237.162:4503    (  1% cpu;  1% machine; 0.001 Gbps;  0% disk IO; 5.5 GB / 8.0 GB RAM  )\n  10.113.237.163:4501    (  1% cpu;  2% machine; 0.017 Gbps;  0% disk IO; 4.7 GB / 8.0 GB RAM  )\n  10.113.237.163:4503    (  1% cpu;  2% machine; 0.017 Gbps;  0% disk IO; 4.7 GB / 8.0 GB RAM  )\n  10.113.237.164:4501    (  1% cpu;  1% machine; 0.001 Gbps;  0% disk IO; 0.6 GB / 8.0 GB RAM  )\n  10.113.237.165:4501    (  1% cpu;  1% machine; 0.001 Gbps;  0% disk IO; 5.5 GB / 8.0 GB RAM  )\n  10.113.237.165:4503    (  1% cpu;  1% machine; 0.001 Gbps;  0% disk IO; 5.5 GB / 8.0 GB RAM  )\n  10.113.237.166:4501    (  1% cpu;  5% machine; 0.002 Gbps;  0% disk IO; 5.5 GB / 8.0 GB RAM  )\n  10.113.237.166:4503    (  1% cpu;  5% machine; 0.002 Gbps;  0% disk IO; 4.8 GB / 8.0 GB RAM  )\n  10.113.237.167:4501    (  1% cpu;  1% machine; 0.001 Gbps;  0% disk IO; 4.7 GB / 8.0 GB RAM  )\n  10.113.237.167:4503    (  1% cpu;  1% machine; 0.001 Gbps;  0% disk IO; 4.7 GB / 8.0 GB RAM  )\n  10.113.237.168:4501    (  1% cpu;  2% machine; 0.001 Gbps;  0% disk IO; 4.1 GB / 8.0 GB RAM  )\n  10.113.237.168:4503    (  1% cpu;  2% machine; 0.001 Gbps;  0% disk IO; 4.7 GB / 8.0 GB RAM  )\n  10.113.237.169:4501    (  1% cpu;  1% machine; 0.000 Gbps;  0% disk IO; 4.7 GB / 8.0 GB RAM  )\n  10.113.237.169:4503    (  1% cpu;  1% machine; 0.000 Gbps;  0% disk IO; 4.7 GB / 8.0 GB RAM  )\n  10.113.237.170:4501    (  1% cpu;  2% machine; 0.001 Gbps;  0% disk IO; 5.5 GB / 8.0 GB RAM  )\n  10.113.237.170:4503    (  1% cpu;  2% machine; 0.001 Gbps;  0% disk IO; 5.5 GB / 8.0 GB RAM  )\n  10.113.237.171:4501    (  1% cpu;  1% machine; 0.000 Gbps;  0% disk IO; 4.7 GB / 8.0 GB RAM  )\n  10.113.237.171:4503    (  1% cpu;  1% machine; 0.000 Gbps;  0% disk IO; 5.5 GB / 8.0 GB RAM  )\n  10.113.237.172:4501    (  1% cpu;  2% machine; 0.001 Gbps;  0% disk IO; 4.7 GB / 8.0 GB RAM  )\n  10.113.237.172:4503    (  1% cpu;  2% machine; 0.001 Gbps;  0% disk IO; 4.9 GB / 8.0 GB RAM  )\n  10.113.237.173:4501    (  2% cpu;  2% machine; 0.001 Gbps;  0% disk IO; 0.6 GB / 8.0 GB RAM  )\n  10.113.237.174:4501    (  7% cpu;  5% machine; 0.004 Gbps;  2% disk IO; 0.3 GB / 8.0 GB RAM  )\n  10.113.237.175:4501    (  1% cpu;  6% machine; 0.001 Gbps;  2% disk IO; 0.1 GB / 8.0 GB RAM  )\n  10.113.237.176:4501    (  0% cpu;  5% machine; 0.001 Gbps; 18% disk IO; 0.1 GB / 8.0 GB RAM  )\n  10.113.237.177:4501    (  6% cpu;  5% machine; 0.006 Gbps;  1% disk IO; 0.3 GB / 8.0 GB RAM  )\n  10.113.237.178:4501    (  3% cpu;  4% machine; 0.004 Gbps;  1% disk IO; 0.3 GB / 8.0 GB RAM  )\n\nCoordination servers:\n  10.113.237.132:4501  (reachable)\n  10.113.237.133:4503  (reachable)\n  10.113.237.139:4501  (reachable)\n  10.113.237.146:4501  (reachable)\n  10.113.237.147:4501  (reachable)\n  10.113.237.154:4501  (reachable)\n  10.113.237.155:4501  (reachable)\n  10.113.237.164:4501  (reachable)\n  10.113.237.173:4501  (reachable)\n\nClient time: 09/17/23 14:30:04\n</code></pre>",
        "post_number": 1,
        "post_type": 1,
        "posts_count": 17,
        "updated_at": "2023-09-19T21:03:38.190Z",
        "reply_count": 0,
        "reply_to_post_number": null,
        "quote_count": 0,
        "incoming_link_count": 62,
        "reads": 29,
        "readers_count": 28,
        "score": 315.8,
        "yours": false,
        "topic_id": 4156,
        "topic_slug": "multi-dc-replication-fails-during-dr-test",
        "display_username": null,
        "primary_group_name": null,
        "flair_name": null,
        "flair_url": null,
        "flair_bg_color": null,
        "flair_color": null,
        "flair_group_id": null,
        "badges_granted": [],
        "version": 1,
        "can_edit": false,
        "can_delete": false,
        "can_recover": false,
        "can_see_hidden_post": false,
        "can_wiki": false,
        "read": true,
        "user_title": null,
        "bookmarked": false,
        "actions_summary": [],
        "moderator": false,
        "admin": false,
        "staff": false,
        "user_id": 1320,
        "hidden": false,
        "trust_level": 1,
        "deleted_at": null,
        "user_deleted": false,
        "edit_reason": null,
        "can_view_edit_history": true,
        "wiki": false,
        "post_url": "/t/multi-dc-replication-fails-during-dr-test/4156/1",
        "can_accept_answer": false,
        "can_unaccept_answer": false,
        "accepted_answer": false,
        "topic_accepted_answer": null,
        "can_vote": false
      },
      {
        "id": 13297,
        "name": "Johannes Scheuermann",
        "username": "johscheuer",
        "avatar_template": "https://avatars.discourse-cdn.com/v4/letter/j/f475e1/{size}.png",
        "created_at": "2023-09-20T08:43:34.906Z",
        "cooked": "<p>Could you share some more details, e.g. how did you simulate the failure of dc1? Are you able to share the logs of the k8s operator(s)?</p>\n<blockquote>\n<ul>\n<li>i\u2019ve noticed that fdb operator added a storage pod in dc1 namespace , from k8s perspective how is the recovery process handled ?</li>\n</ul>\n</blockquote>\n<p>In theory if the operator is able to connect to the cluster it should be recreating the resources. If the issue was only a network partition the operator has nothing to do and the FDB cluster would be doing the recovery.</p>",
        "post_number": 2,
        "post_type": 1,
        "posts_count": 17,
        "updated_at": "2023-09-20T08:43:34.906Z",
        "reply_count": 0,
        "reply_to_post_number": null,
        "quote_count": 0,
        "incoming_link_count": 0,
        "reads": 25,
        "readers_count": 24,
        "score": 5.0,
        "yours": false,
        "topic_id": 4156,
        "topic_slug": "multi-dc-replication-fails-during-dr-test",
        "display_username": "Johannes Scheuermann",
        "primary_group_name": null,
        "flair_name": null,
        "flair_url": null,
        "flair_bg_color": null,
        "flair_color": null,
        "flair_group_id": null,
        "badges_granted": [],
        "version": 1,
        "can_edit": false,
        "can_delete": false,
        "can_recover": false,
        "can_see_hidden_post": false,
        "can_wiki": false,
        "read": true,
        "user_title": "",
        "bookmarked": false,
        "actions_summary": [],
        "moderator": false,
        "admin": false,
        "staff": false,
        "user_id": 849,
        "hidden": false,
        "trust_level": 2,
        "deleted_at": null,
        "user_deleted": false,
        "edit_reason": null,
        "can_view_edit_history": true,
        "wiki": false,
        "post_url": "/t/multi-dc-replication-fails-during-dr-test/4156/2",
        "can_accept_answer": false,
        "can_unaccept_answer": false,
        "accepted_answer": false,
        "topic_accepted_answer": null
      },
      {
        "id": 13301,
        "name": null,
        "username": "stefanvasilic4",
        "avatar_template": "https://avatars.discourse-cdn.com/v4/letter/s/a8b319/{size}.png",
        "created_at": "2023-09-20T14:19:41.627Z",
        "cooked": "<p>in current setup, using <code>nodeSelectors</code> and <code>topologySpreadConstraints</code> every pod (fdb process) is placed on a k8s node (cloud vm), using networkHost ; hence, pods/nodes belong to 3 namespaces (dc1, dc2, dc3) but from cloud infra perspective a namespaces is mapped to an AZ. Simulating dc1 failure is terminating all pods in dc1 namespace (all VMs in AZ1), and bringing them back. Operator pod is free to move around and is not on host Network.<br>\nAt the moment  there are some processes that are stuck and operator is trying to exclude them.</p>\n<pre><code class=\"lang-auto\">status:\n  processGroups:\n    - addresses:\n        - 10.113.237.136\n      processClass: log\n      processGroupID: dc1-log-1\n    - addresses:\n        - 10.113.237.142\n      processClass: log\n      processGroupID: dc1-log-2\n    - addresses:\n        - 10.113.237.180\n      processClass: stateless\n      processGroupID: dc1-stateless-1\n    - addresses:\n        - 10.113.237.176\n      processClass: stateless\n      processGroupID: dc1-stateless-2\n    - addresses:\n        - 10.113.237.179\n      processClass: stateless\n      processGroupID: dc1-stateless-3\n    - addresses:\n        - 10.113.237.147\n        - 10.113.237.149\n        - 10.113.237.152\n        - 10.113.237.155\n        - 10.113.237.173\n      processClass: storage\n      processGroupConditions:\n        - timestamp: 1694989929\n          type: ResourcesTerminating          &lt;&lt;&lt;&lt;&lt;&lt;\n      processGroupID: dc1-storage-1\n      removalTimestamp: '2023-09-20T14:02:39Z'\n    - addresses:\n        - 10.113.237.141\n      processClass: storage\n      processGroupID: dc1-storage-10\n    - addresses:\n        - 10.113.237.148\n      processClass: storage\n      processGroupID: dc1-storage-11\n    - addresses:\n        - 10.113.237.154\n      processClass: storage\n      processGroupID: dc1-storage-12\n    - addresses:\n        - 10.113.237.147\n      processClass: storage\n      processGroupID: dc1-storage-13\n    - addresses:\n        - 10.113.237.151\n      processClass: storage\n      processGroupID: dc1-storage-14\n    - addresses:\n        - 10.113.237.138\n      processClass: storage\n      processGroupID: dc1-storage-15\n    - addresses:\n        - 10.113.237.139\n      processClass: storage\n      processGroupID: dc1-storage-16\n    - addresses:\n        - 10.113.237.145\n      processClass: storage\n      processGroupID: dc1-storage-17\n    - addresses:\n        - 10.113.237.137\n      processClass: storage\n      processGroupID: dc1-storage-18\n    - addresses:\n        - 10.113.237.155\n      processClass: storage\n      processGroupID: dc1-storage-19\n    - addresses:\n        - 10.113.237.150\n      processClass: storage\n      processGroupID: dc1-storage-2\n    - addresses:\n        - 10.113.237.135\n      processClass: storage\n      processGroupID: dc1-storage-3\n    - addresses:\n        - 10.113.237.144\n      processClass: storage\n      processGroupID: dc1-storage-4\n    - addresses:\n        - 10.113.237.149\n      processClass: storage\n      processGroupID: dc1-storage-5\n    - addresses:\n        - 10.113.237.152\n      processClass: storage\n      processGroupID: dc1-storage-6\n    - addresses:\n        - 10.113.237.140\n      processClass: storage\n      processGroupID: dc1-storage-7\n    - addresses:\n        - 10.113.237.143\n      processClass: storage\n      processGroupID: dc1-storage-8\n    - addresses:\n        - 10.113.237.135\n        - 10.113.237.146\n      processClass: storage\n      processGroupConditions:\n        - timestamp: 1695160643\n          type: MissingPod                                       &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;\n      processGroupID: dc1-storage-9\n      removalTimestamp: '2023-09-20T14:02:39Z'\n</code></pre>\n<ul>\n<li>some pod logs:</li>\n</ul>\n<pre><code class=\"lang-auto\">\"level\":\"info\",\"ts\":1695218561.8718004,\"logger\":\"fdbclient\",\"msg\":\"Fetch values from FDB\",\"namespace\":\"dc1\",\"cluster\":\"fdb-cluster-1\",\"key\":\"\\ufffd\\ufffd/status/json\"}\n{\"level\":\"info\",\"ts\":1695218563.9435072,\"logger\":\"fdbclient\",\"msg\":\"Done fetching values from FDB\",\"namespace\":\"dc1\",\"cluster\":\"fdb-cluster-1\",\"key\":\"\\ufffd\\ufffd/status/json\"}\n{\"level\":\"info\",\"ts\":1695218563.948019,\"logger\":\"controller\",\"msg\":\"Attempting to run sub-reconciler\",\"namespace\":\"dc1\",\"cluster\":\"fdb-cluster-1\",\"subReconciler\":\"controllers.updateSidecarVersions\"}\n{\"level\":\"info\",\"ts\":1695218563.948068,\"logger\":\"controller\",\"msg\":\"Attempting to run sub-reconciler\",\"namespace\":\"dc1\",\"cluster\":\"fdb-cluster-1\",\"subReconciler\":\"controllers.updatePodConfig\"}\n{\"level\":\"info\",\"ts\":1695218563.9488695,\"logger\":\"controller\",\"msg\":\"Attempting to run sub-reconciler\",\"namespace\":\"dc1\",\"cluster\":\"fdb-cluster-1\",\"subReconciler\":\"controllers.updateLabels\"}\n{\"level\":\"info\",\"ts\":1695218563.9493287,\"logger\":\"controller\",\"msg\":\"Attempting to run sub-reconciler\",\"namespace\":\"dc1\",\"cluster\":\"fdb-cluster-1\",\"subReconciler\":\"controllers.updateDatabaseConfiguration\"}\n{\"level\":\"info\",\"ts\":1695218563.9493825,\"logger\":\"fdbclient\",\"msg\":\"Fetch values from FDB\",\"namespace\":\"dc1\",\"cluster\":\"fdb-cluster-1\",\"key\":\"\\ufffd\\ufffd/status/json\"}\n{\"level\":\"info\",\"ts\":1695218566.0212674,\"logger\":\"fdbclient\",\"msg\":\"Done fetching values from FDB\",\"namespace\":\"dc1\",\"cluster\":\"fdb-cluster-1\",\"key\":\"\\ufffd\\ufffd/status/json\"}\n{\"level\":\"info\",\"ts\":1695218566.0240517,\"logger\":\"controller\",\"msg\":\"Attempting to run sub-reconciler\",\"namespace\":\"dc1\",\"cluster\":\"fdb-cluster-1\",\"subReconciler\":\"controllers.chooseRemovals\"}\n{\"level\":\"info\",\"ts\":1695218566.0241134,\"logger\":\"fdbclient\",\"msg\":\"Fetch values from FDB\",\"namespace\":\"dc1\",\"cluster\":\"fdb-cluster-1\",\"key\":\"\\ufffd\\ufffd/status/json\"}\n{\"level\":\"info\",\"ts\":1695218568.0982757,\"logger\":\"fdbclient\",\"msg\":\"Done fetching values from FDB\",\"namespace\":\"dc1\",\"cluster\":\"fdb-cluster-1\",\"key\":\"\\ufffd\\ufffd/status/json\"}\n{\"level\":\"info\",\"ts\":1695218568.1017754,\"logger\":\"controller\",\"msg\":\"Attempting to run sub-reconciler\",\"namespace\":\"dc1\",\"cluster\":\"fdb-cluster-1\",\"subReconciler\":\"controllers.excludeProcesses\"}\n{\"level\":\"info\",\"ts\":1695218568.1018329,\"logger\":\"fdbclient\",\"msg\":\"Fetch values from FDB\",\"namespace\":\"dc1\",\"cluster\":\"fdb-cluster-1\",\"key\":\"\\ufffd\\ufffd/status/json\"}\n{\"level\":\"info\",\"ts\":1695218570.1727428,\"logger\":\"fdbclient\",\"msg\":\"Done fetching values from FDB\",\"namespace\":\"dc1\",\"cluster\":\"fdb-cluster-1\",\"key\":\"\\ufffd\\ufffd/status/json\"}\n{\"level\":\"info\",\"ts\":1695218570.1753511,\"logger\":\"controller\",\"msg\":\"current exclusions\",\"namespace\":\"dc1\",\"cluster\":\"fdb-cluster-1\",\"reconciler\":\"excludeProcesses\",\"ex\":[\"10.113.237.134:4501\",\"10.113.237.147\",\"10.113.237.149\",\"10.113.237.152\"]}\n{\"level\":\"info\",\"ts\":1695218570.17548,\"logger\":\"fdbclient\",\"msg\":\"Running command\",\"namespace\":\"dc1\",\"cluster\":\"fdb-cluster-1\",\"path\":\"/usr/bin/fdb/7.1/fdbcli\",\"args\":[\"/usr/bin/fdb/7.1/fdbcli\",\"--exec\",\"exclude 10.113.237.155 10.113.237.173 10.113.237.135 10.113.237.146\",\"-C\",\"/tmp/4db61298-4806-40b6-9d18-07c5ca38f2c2\",\"--log\",\"--log\",\"--trace_format\",\"xml\",\"--log-dir\",\"/var/log/fdb\",\"--timeout\",\"10\"]}\n{\"level\":\"error\",\"ts\":1695218572.3537273,\"logger\":\"fdbclient\",\"msg\":\"Error from FDB command\",\"namespace\":\"dc1\",\"cluster\":\"fdb-cluster-1\",\"code\":1,\"stdout\":\"ERROR: Could not calculate the impact of this exclude on the total free space in the cluster.\\nPlease try the exclude again in 30 seconds.\\nType `exclude FORCE &lt;ADDRESS...&gt;' to exclude without checking free space.\\n\",\"stderr\":\"\",\"error\":\"exit status 1\",\"stacktrace\":\"github.com/FoundationDB/fdb-kubernetes-operator/fdbclient.(*cliAdminClient).runCommandWithBackoff\\n\\t/workspace/fdbclient/admin_client.go:282\\ngithub.com/FoundationDB/fdb-kubernetes-operator/fdbclient.(*cliAdminClient).ExcludeProcesses\\n\\t/workspace/fdbclient/admin_client.go:432\\ngithub.com/FoundationDB/fdb-kubernetes-operator/controllers.excludeProcesses.reconcile\\n\\t/workspace/controllers/exclude_processes.go:84\\ngithub.com/FoundationDB/fdb-kubernetes-operator/controllers.(*FoundationDBClusterReconciler).Reconcile\\n\\t/workspace/controllers/cluster_controller.go:166\\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).Reconcile\\n\\t/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.12.3/pkg/internal/controller/controller.go:121\\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).reconcileHandler\\n\\t/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.12.3/pkg/internal/controller/controller.go:320\\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).processNextWorkItem\\n\\t/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.12.3/pkg/internal/controller/controller.go:273\\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).Start.func2.2\\n\\t/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.12.3/pkg/internal/controller/controller.go:234\"}\n{\"level\":\"info\",\"ts\":1695218572.3538575,\"logger\":\"controller\",\"msg\":\"Delaying requeue for sub-reconciler\",\"namespace\":\"dc1\",\"cluster\":\"fdb-cluster-1\",\"subReconciler\":\"controllers.excludeProcesses\",\"message\":\"\",\"error\":\"exit status 1\"}\n{\"level\":\"info\",\"ts\":1695218572.3539171,\"logger\":\"controller\",\"msg\":\"Attempting to run sub-reconciler\",\"namespace\":\"dc1\",\"cluster\":\"fdb-cluster-1\",\"subReconciler\":\"controllers.changeCoordinators\"}\n{\"level\":\"info\",\"ts\":1695218572.3539553,\"logger\":\"fdbclient\",\"msg\":\"Fetch values from FDB\",\"namespace\":\"dc1\",\"cluster\":\"fdb-cluster-1\",\"key\":\"\\ufffd\\ufffd/status/json\"}\n{\"level\":\"info\",\"ts\":1695218574.425527,\"logger\":\"fdbclient\",\"msg\":\"Done fetching values from FDB\",\"namespace\":\"dc1\",\"cluster\":\"fdb-cluster-1\",\"key\":\"\\ufffd\\ufffd/status/json\"}\n{\"level\":\"info\",\"ts\":1695218574.4308026,\"logger\":\"controller\",\"msg\":\"Attempting to run sub-reconciler\",\"namespace\":\"dc1\",\"cluster\":\"fdb-cluster-1\",\"subReconciler\":\"controllers.bounceProcesses\"}\n{\"level\":\"info\",\"ts\":1695218574.4308512,\"logger\":\"fdbclient\",\"msg\":\"Fetch values from FDB\",\"namespace\":\"dc1\",\"cluster\":\"fdb-cluster-1\",\"key\":\"\\ufffd\\ufffd/status/json\"}\n{\"level\":\"info\",\"ts\":1695218576.5043163,\"logger\":\"fdbclient\",\"msg\":\"Done fetching values from FDB\",\"namespace\":\"dc1\",\"cluster\":\"fdb-cluster-1\",\"key\":\"\\ufffd\\ufffd/status/json\"}\n{\"level\":\"info\",\"ts\":1695218576.5072148,\"logger\":\"controller\",\"msg\":\"Attempting to run sub-reconciler\",\"namespace\":\"dc1\",\"cluster\":\"fdb-cluster-1\",\"subReconciler\":\"controllers.maintenanceModeChecker\"}\n{\"level\":\"info\",\"ts\":1695218576.507269,\"logger\":\"controller\",\"msg\":\"Attempting to run sub-reconciler\",\"namespace\":\"dc1\",\"cluster\":\"fdb-cluster-1\",\"subReconciler\":\"controllers.updatePods\"}\n{\"level\":\"info\",\"ts\":1695218576.508645,\"logger\":\"controller\",\"msg\":\"Attempting to run sub-reconciler\",\"namespace\":\"dc1\",\"cluster\":\"fdb-cluster-1\",\"subReconciler\":\"controllers.removeProcessGroups\"}\n{\"level\":\"info\",\"ts\":1695218576.508712,\"logger\":\"fdbclient\",\"msg\":\"Fetch values from FDB\",\"namespace\":\"dc1\",\"cluster\":\"fdb-cluster-1\",\"key\":\"\\ufffd\\ufffd/status/json\"}\n{\"level\":\"info\",\"ts\":1695218578.5825465,\"logger\":\"fdbclient\",\"msg\":\"Done fetching values from FDB\",\"namespace\":\"dc1\",\"cluster\":\"fdb-cluster-1\",\"key\":\"\\ufffd\\ufffd/status/json\"}\n{\"level\":\"info\",\"ts\":1695218578.5856998,\"logger\":\"fdbclient\",\"msg\":\"Filtering excluded processes\",\"namespace\":\"dc1\",\"cluster\":\"fdb-cluster-1\",\"inProgress\":[\"10.113.237.147\",\"10.113.237.149\",\"10.113.237.152\"],\"fullyExcluded\":[],\"notExcluded\":[\"10.113.237.155\",\"10.113.237.173\",\"10.113.237.135\",\"10.113.237.146\"],\"missingInStatus\":[]}\n{\"level\":\"info\",\"ts\":1695218578.5857313,\"logger\":\"controller\",\"msg\":\"Exclusions to complete\",\"namespace\":\"dc1\",\"cluster\":\"fdb-cluster-1\",\"reconciler\":\"removeProcessGroups\",\"remainingServers\":[\"10.113.237.155\",\"10.113.237.173\",\"10.113.237.135\",\"10.113.237.146\",\"10.113.237.147\",\"10.113.237.149\",\"10.113.237.152\"]}\n{\"level\":\"info\",\"ts\":1695218578.5857813,\"logger\":\"fdbclient\",\"msg\":\"Fetch values from FDB\",\"namespace\":\"dc1\",\"cluster\":\"fdb-cluster-1\",\"key\":\"\\ufffd\\ufffd/status/json\"}\n{\"level\":\"info\",\"ts\":1695218580.6584988,\"logger\":\"fdbclient\",\"msg\":\"Done fetching values from FDB\",\"namespace\":\"dc1\",\"cluster\":\"fdb-cluster-1\",\"key\":\"\\ufffd\\ufffd/status/json\"}\n{\"level\":\"info\",\"ts\":1695218580.6614013,\"logger\":\"controller\",\"msg\":\"Incomplete exclusion still present in removeProcessGroups step\",\"namespace\":\"dc1\",\"cluster\":\"fdb-cluster-1\",\"reconciler\":\"removeProcessGroups\",\"processGroupID\":\"dc1-storage-1\",\"error\":\"process has missing address in exclusion results: 10.113.237.147\"}\n{\"level\":\"info\",\"ts\":1695218580.661425,\"logger\":\"controller\",\"msg\":\"Incomplete exclusion still present in removeProcessGroups step\",\"namespace\":\"dc1\",\"cluster\":\"fdb-cluster-1\",\"reconciler\":\"removeProcessGroups\",\"processGroupID\":\"dc1-storage-9\",\"error\":\"process has missing address in exclusion results: 10.113.237.135\"}\n{\"level\":\"info\",\"ts\":1695218580.6614563,\"logger\":\"controller\",\"msg\":\"Reconciliation terminated early\",\"namespace\":\"dc1\",\"cluster\":\"fdb-cluster-1\",\"subReconciler\":\"controllers.removeProcessGroups\",\"requeueAfter\":0,\"message\":\"Reconciliation needs to exclude more processes\"}\n</code></pre>\n<p>Note: i performed several successful test like this , so i am not sure what went wrong.</p>",
        "post_number": 3,
        "post_type": 1,
        "posts_count": 17,
        "updated_at": "2023-09-20T14:20:36.371Z",
        "reply_count": 1,
        "reply_to_post_number": null,
        "quote_count": 0,
        "incoming_link_count": 2,
        "reads": 25,
        "readers_count": 24,
        "score": 20.0,
        "yours": false,
        "topic_id": 4156,
        "topic_slug": "multi-dc-replication-fails-during-dr-test",
        "display_username": null,
        "primary_group_name": null,
        "flair_name": null,
        "flair_url": null,
        "flair_bg_color": null,
        "flair_color": null,
        "flair_group_id": null,
        "badges_granted": [],
        "version": 1,
        "can_edit": false,
        "can_delete": false,
        "can_recover": false,
        "can_see_hidden_post": false,
        "can_wiki": false,
        "read": true,
        "user_title": null,
        "bookmarked": false,
        "actions_summary": [],
        "moderator": false,
        "admin": false,
        "staff": false,
        "user_id": 1320,
        "hidden": false,
        "trust_level": 1,
        "deleted_at": null,
        "user_deleted": false,
        "edit_reason": null,
        "can_view_edit_history": true,
        "wiki": false,
        "post_url": "/t/multi-dc-replication-fails-during-dr-test/4156/3",
        "can_accept_answer": false,
        "can_unaccept_answer": false,
        "accepted_answer": false,
        "topic_accepted_answer": null
      },
      {
        "id": 13302,
        "name": "Johannes Scheuermann",
        "username": "johscheuer",
        "avatar_template": "https://avatars.discourse-cdn.com/v4/letter/j/f475e1/{size}.png",
        "created_at": "2023-09-20T16:15:10.924Z",
        "cooked": "<p>Thanks for sharing the logs, I take a look tomorrow. Could you share the operator version you used for the test?</p>",
        "post_number": 4,
        "post_type": 1,
        "posts_count": 17,
        "updated_at": "2023-09-20T16:15:10.924Z",
        "reply_count": 1,
        "reply_to_post_number": 3,
        "quote_count": 0,
        "incoming_link_count": 0,
        "reads": 23,
        "readers_count": 22,
        "score": 9.6,
        "yours": false,
        "topic_id": 4156,
        "topic_slug": "multi-dc-replication-fails-during-dr-test",
        "display_username": "Johannes Scheuermann",
        "primary_group_name": null,
        "flair_name": null,
        "flair_url": null,
        "flair_bg_color": null,
        "flair_color": null,
        "flair_group_id": null,
        "badges_granted": [],
        "version": 1,
        "can_edit": false,
        "can_delete": false,
        "can_recover": false,
        "can_see_hidden_post": false,
        "can_wiki": false,
        "read": true,
        "user_title": "",
        "reply_to_user": {
          "id": 1320,
          "username": "stefanvasilic4",
          "name": null,
          "avatar_template": "https://avatars.discourse-cdn.com/v4/letter/s/a8b319/{size}.png"
        },
        "bookmarked": false,
        "actions_summary": [],
        "moderator": false,
        "admin": false,
        "staff": false,
        "user_id": 849,
        "hidden": false,
        "trust_level": 2,
        "deleted_at": null,
        "user_deleted": false,
        "edit_reason": null,
        "can_view_edit_history": true,
        "wiki": false,
        "post_url": "/t/multi-dc-replication-fails-during-dr-test/4156/4",
        "can_accept_answer": false,
        "can_unaccept_answer": false,
        "accepted_answer": false,
        "topic_accepted_answer": null
      },
      {
        "id": 13304,
        "name": null,
        "username": "stefanvasilic4",
        "avatar_template": "https://avatars.discourse-cdn.com/v4/letter/s/a8b319/{size}.png",
        "created_at": "2023-09-20T16:34:15.334Z",
        "cooked": "<p>fdb: <code>7.1.26</code><br>\noperator: <code>v1.16.0</code></p>\n<p>thanks for help!</p>",
        "post_number": 5,
        "post_type": 1,
        "posts_count": 17,
        "updated_at": "2023-09-20T16:34:15.334Z",
        "reply_count": 0,
        "reply_to_post_number": 4,
        "quote_count": 0,
        "incoming_link_count": 4,
        "reads": 23,
        "readers_count": 22,
        "score": 24.6,
        "yours": false,
        "topic_id": 4156,
        "topic_slug": "multi-dc-replication-fails-during-dr-test",
        "display_username": null,
        "primary_group_name": null,
        "flair_name": null,
        "flair_url": null,
        "flair_bg_color": null,
        "flair_color": null,
        "flair_group_id": null,
        "badges_granted": [],
        "version": 1,
        "can_edit": false,
        "can_delete": false,
        "can_recover": false,
        "can_see_hidden_post": false,
        "can_wiki": false,
        "read": true,
        "user_title": null,
        "reply_to_user": {
          "id": 849,
          "username": "johscheuer",
          "name": "Johannes Scheuermann",
          "avatar_template": "https://avatars.discourse-cdn.com/v4/letter/j/f475e1/{size}.png"
        },
        "bookmarked": false,
        "actions_summary": [],
        "moderator": false,
        "admin": false,
        "staff": false,
        "user_id": 1320,
        "hidden": false,
        "trust_level": 1,
        "deleted_at": null,
        "user_deleted": false,
        "edit_reason": null,
        "can_view_edit_history": true,
        "wiki": false,
        "post_url": "/t/multi-dc-replication-fails-during-dr-test/4156/5",
        "can_accept_answer": false,
        "can_unaccept_answer": false,
        "accepted_answer": false,
        "topic_accepted_answer": null
      },
      {
        "id": 13319,
        "name": null,
        "username": "stefanvasilic4",
        "avatar_template": "https://avatars.discourse-cdn.com/v4/letter/s/a8b319/{size}.png",
        "created_at": "2023-09-22T01:58:19.817Z",
        "cooked": "<p>following on this issue:</p>\n<ul>\n<li>i was able to replicate the same issue in a different cluster</li>\n<li>i used latest operator version and all pods/(processes) recovered ; nothing of value in logs as everything is reconciled</li>\n<li>the data is not getting replicated to primary , i think this is foundationdb layer</li>\n</ul>\n<p>What is the process to restart Tlogs Interfaces (manually) ?</p>\n<pre><code class=\"lang-auto\">Using cluster file `/var/dynamic-conf/fdb.cluster'.\n\nConfiguration:\n  Redundancy mode        - triple\n  Storage engine         - ssd-2\n  Coordinators           - 9\n  Desired Commit Proxies - 2\n  Desired GRV Proxies    - 1\n  Desired Resolvers      - 1\n  Desired Logs           - 3\n  Desired Remote Logs    - 3\n  Desired Log Routers    - 3\n  Usable Regions         - 2\n  Regions: \n    Primary -\n        Datacenter                    - dc1\n        Satellite datacenters         - dc2, dc3\n        Satellite Logs                - 3\n    Remote -\n        Datacenter                    - dc3\n        Satellite datacenters         - dc2, dc1\n        Satellite Logs                - 3\n\nCluster:\n  FoundationDB processes - 88\n  Zones                  - 47\n  Machines               - 47\n  Memory availability    - 7.2 GB per process on machine with least available\n  Retransmissions rate   - 1 Hz\n  Fault Tolerance        - -1 machines\n\n  Warning: the database may have data loss and availability loss. Please restart following tlog interfaces, otherwise storage servers may never be able to catch up.\n  Old log epoch: 61 begin: 67747007429 end: 67862561162, missing log interfaces(id,address): 702bb3191d379a75, e2f31f2ec89c3ea8, 0e8867a3cedf9d49, \n  Old log epoch: 57 begin: 67633217945 end: 67747007429, missing log interfaces(id,address): b78ad3e928f598b3, 347462edcd47ca65, ef55f1c0644d9947, \n  Old log epoch: 54 begin: 67522181213 end: 67633217945, missing log interfaces(id,address): 53a5357d543c3689, d2226fd86c5e4438, 03d2166c63706f71, \n  Old log epoch: 52 begin: 67392885066 end: 67522181213, missing log interfaces(id,address): c115949861718c45, 6f94496c83dbfa4d, a29f67a398b280f0, \n  Old log epoch: 50 begin: 67276398632 end: 67392885066, missing log interfaces(id,address): 1ee2a591852d31f8, d55326815f9961fd, c0a8494a55bc0801, \n  Old log epoch: 47 begin: 67160817068 end: 67276398632, missing log interfaces(id,address): 7f5eee096b3696fd, d98c85335819c2c2, c222722bc97d9ba3, \n  Old log epoch: 45 begin: 67040025375 end: 67160817068, missing log interfaces(id,address): 444e5c6f3f8baeaa, 83bb01e32d493108, dac3f70601069d4b, \n  Old log epoch: 43 begin: 66922430237 end: 67040025375, missing log interfaces(id,address): 8c5201059109ec7a, eb9fdc998f238375, 9f9c019b466d372d, \n  Old log epoch: 41 begin: 66797519416 end: 66922430237, missing log interfaces(id,address): 1adc6b952c144d1e, 5df11c41622c8012, c74557cd9aafe021, \n  Old log epoch: 39 begin: 66689005581 end: 66797519416, missing log interfaces(id,address): 42cce254c5a04d12, 72265d0fb2500d78, ed0242fd8c8211ed, \n  Old log epoch: 37 begin: 66573370304 end: 66689005581, missing log interfaces(id,address): fea5c6457e5ecd86, c3e17575ac55487b, 064c7fd246c37ef7, \n  Old log epoch: 35 begin: 66405317743 end: 66573370304, missing log interfaces(id,address): c557b060d856f82f, 044bb1ff6e8ac834, 0342f98cd441be44, \n  Old log epoch: 33 begin: 66295640128 end: 66405317743, missing log interfaces(id,address): c4653c3267281519, f0bbc162395d2017, 75c42aad636f5f3e, \n  Old log epoch: 31 begin: 59531875452 end: 66295640128, missing log interfaces(id,address): e2539e896af33195, ec5a827750f277a1, 82791cad4b47b650, \n\n  Server time            - 09/22/23 01:49:50\n\nData:\n  Replication health     - UNHEALTHY: No replicas remain of some data\n  Moving data            - 807.670 GB\n  Sum of key-value sizes - 1.158 TB\n  Disk space used        - 6.196 TB\n\nOperating space:\n  Storage server         - 1744.2 GB free on most full server\n  Log server             - 1746.4 GB free on most full server\n\nWorkload:\n  Read rate              - 198 Hz\n  Write rate             - 0 Hz\n  Transactions started   - 44 Hz\n  Transactions committed - 0 Hz\n  Conflict rate          - 0 Hz\n\nBackup and DR:\n  Running backups        - 0\n  Running DRs            - 0\n\nProcess performance details:\n  10.113.237.132:4501    (  1% cpu;  3% machine; 0.001 Gbps;  0% disk IO; 0.2 GB / 8.0 GB RAM  )\n  10.113.237.132:4503    (  1% cpu;  3% machine; 0.001 Gbps;  0% disk IO; 0.4 GB / 8.0 GB RAM  )\n  10.113.237.133:4501    (  1% cpu;  3% machine; 0.001 Gbps;  1% disk IO; 3.9 GB / 8.0 GB RAM  )\n  10.113.237.133:4503    (  7% cpu;  3% machine; 0.001 Gbps;  1% disk IO; 3.3 GB / 8.0 GB RAM  )\n  10.113.237.134:4501    (  6% cpu;  3% machine; 0.001 Gbps;  1% disk IO; 3.3 GB / 8.0 GB RAM  )\n  10.113.237.134:4503    (  2% cpu;  3% machine; 0.001 Gbps;  1% disk IO; 3.8 GB / 8.0 GB RAM  )\n  10.113.237.135:4501    (  4% cpu;  3% machine; 0.001 Gbps;  1% disk IO; 3.8 GB / 8.0 GB RAM  )\n  10.113.237.135:4503    (  4% cpu;  3% machine; 0.001 Gbps;  1% disk IO; 3.3 GB / 8.0 GB RAM  )\n  10.113.237.136:4501    (  4% cpu;  7% machine; 0.120 Gbps;  5% disk IO; 3.3 GB / 8.0 GB RAM  )\n  10.113.237.136:4503    ( 20% cpu;  7% machine; 0.120 Gbps;  5% disk IO; 4.0 GB / 8.0 GB RAM  )\n  10.113.237.137:4501    (  5% cpu;  4% machine; 0.001 Gbps;  1% disk IO; 3.8 GB / 8.0 GB RAM  )\n  10.113.237.137:4503    (  5% cpu;  4% machine; 0.001 Gbps;  1% disk IO; 3.3 GB / 8.0 GB RAM  )\n  10.113.237.138:4501    (  5% cpu;  4% machine; 0.001 Gbps;  1% disk IO; 3.8 GB / 8.0 GB RAM  )\n  10.113.237.138:4503    (  6% cpu;  4% machine; 0.001 Gbps;  1% disk IO; 3.8 GB / 8.0 GB RAM  )\n  10.113.237.139:4501    (  5% cpu;  3% machine; 0.001 Gbps;  1% disk IO; 3.8 GB / 8.0 GB RAM  )\n  10.113.237.139:4503    (  6% cpu;  3% machine; 0.001 Gbps;  1% disk IO; 3.3 GB / 8.0 GB RAM  )\n  10.113.237.140:4501    (  6% cpu;  3% machine; 0.001 Gbps;  1% disk IO; 3.8 GB / 8.0 GB RAM  )\n  10.113.237.140:4503    (  2% cpu;  3% machine; 0.001 Gbps;  1% disk IO; 3.3 GB / 8.0 GB RAM  )\n  10.113.237.141:4501    (  1% cpu;  2% machine; 0.001 Gbps;  0% disk IO; 0.3 GB / 8.0 GB RAM  )\n  10.113.237.141:4503    (  1% cpu;  2% machine; 0.001 Gbps;  0% disk IO; 0.2 GB / 8.0 GB RAM  )\n  10.113.237.142:4501    (  4% cpu;  3% machine; 0.001 Gbps;  0% disk IO; 3.3 GB / 8.0 GB RAM  )\n  10.113.237.142:4503    (  5% cpu;  3% machine; 0.001 Gbps;  0% disk IO; 3.8 GB / 8.0 GB RAM  )\n  10.113.237.143:4501    (  1% cpu;  5% machine; 0.034 Gbps;  5% disk IO; 3.3 GB / 8.0 GB RAM  )\n  10.113.237.143:4503    ( 10% cpu;  5% machine; 0.034 Gbps;  5% disk IO; 3.8 GB / 8.0 GB RAM  )\n  10.113.237.144:4501    (  6% cpu;  4% machine; 0.001 Gbps;  1% disk IO; 3.3 GB / 8.0 GB RAM  )\n  10.113.237.144:4503    (  6% cpu;  4% machine; 0.001 Gbps;  1% disk IO; 3.3 GB / 8.0 GB RAM  )\n  10.113.237.145:4501    (  5% cpu;  4% machine; 0.001 Gbps;  1% disk IO; 3.3 GB / 8.0 GB RAM  )\n  10.113.237.145:4503    (  5% cpu;  4% machine; 0.001 Gbps;  1% disk IO; 3.3 GB / 8.0 GB RAM  )\n  10.113.237.146:4501    (  6% cpu;  4% machine; 0.001 Gbps;  1% disk IO; 3.8 GB / 8.0 GB RAM  )\n  10.113.237.146:4503    (  2% cpu;  4% machine; 0.001 Gbps;  1% disk IO; 3.3 GB / 8.0 GB RAM  )\n  10.113.237.147:4501    (  5% cpu;  7% machine; 0.188 Gbps;  1% disk IO; 3.8 GB / 8.0 GB RAM  )\n  10.113.237.147:4503    ( 10% cpu;  7% machine; 0.188 Gbps;  1% disk IO; 3.8 GB / 8.0 GB RAM  )\n  10.113.237.148:4501    (  4% cpu;  9% machine; 0.129 Gbps;  1% disk IO; 3.3 GB / 8.0 GB RAM  )\n  10.113.237.148:4503    ( 21% cpu;  9% machine; 0.129 Gbps;  1% disk IO; 3.3 GB / 8.0 GB RAM  )\n  10.113.237.149:4501    (  5% cpu;  3% machine; 0.001 Gbps;  1% disk IO; 3.8 GB / 8.0 GB RAM  )\n  10.113.237.149:4503    (  5% cpu;  3% machine; 0.001 Gbps;  1% disk IO; 3.3 GB / 8.0 GB RAM  )\n  10.113.237.150:4501    (  4% cpu;  3% machine; 0.001 Gbps;  1% disk IO; 3.3 GB / 8.0 GB RAM  )\n  10.113.237.150:4503    (  4% cpu;  3% machine; 0.001 Gbps;  1% disk IO; 3.8 GB / 8.0 GB RAM  )\n  10.113.237.151:4501    (  2% cpu;  4% machine; 0.001 Gbps;  3% disk IO; 9.4 GB / 8.0 GB RAM  )\n  10.113.237.151:4503    (  9% cpu;  4% machine; 0.001 Gbps;  3% disk IO; 5.6 GB / 8.0 GB RAM  )\n  10.113.237.152:4501    (  1% cpu;  2% machine; 0.001 Gbps;  0% disk IO; 2.5 GB / 8.0 GB RAM  )\n  10.113.237.152:4503    (  1% cpu;  2% machine; 0.001 Gbps;  0% disk IO; 2.4 GB / 8.0 GB RAM  )\n  10.113.237.154:4501    (  3% cpu;  3% machine; 0.002 Gbps;  3% disk IO; 4.8 GB / 8.0 GB RAM  )\n  10.113.237.154:4503    (  4% cpu;  3% machine; 0.002 Gbps;  3% disk IO; 4.8 GB / 8.0 GB RAM  )\n  10.113.237.155:4501    (  8% cpu;  4% machine; 0.001 Gbps;  7% disk IO; 6.8 GB / 8.0 GB RAM  )\n  10.113.237.155:4503    (  9% cpu;  4% machine; 0.001 Gbps;  7% disk IO; 6.8 GB / 8.0 GB RAM  )\n  10.113.237.156:4501    ( 18% cpu;  7% machine; 0.089 Gbps; 24% disk IO; 6.8 GB / 8.0 GB RAM  )\n  10.113.237.156:4503    ( 24% cpu;  7% machine; 0.089 Gbps; 22% disk IO; 9.4 GB / 8.0 GB RAM  )\n  10.113.237.157:4501    (  9% cpu;  4% machine; 0.003 Gbps;  6% disk IO; 6.8 GB / 8.0 GB RAM  )\n  10.113.237.157:4503    ( 10% cpu;  4% machine; 0.003 Gbps;  6% disk IO; 6.9 GB / 8.0 GB RAM  )\n  10.113.237.158:4501    (  5% cpu;  3% machine; 0.001 Gbps;  2% disk IO; 8.4 GB / 8.0 GB RAM  )\n  10.113.237.158:4503    (  2% cpu;  3% machine; 0.001 Gbps;  2% disk IO; 6.8 GB / 8.0 GB RAM  )\n  10.113.237.159:4501    (  3% cpu;  4% machine; 0.057 Gbps; 12% disk IO; 6.8 GB / 8.0 GB RAM  )\n  10.113.237.159:4503    ( 19% cpu;  4% machine; 0.057 Gbps; 13% disk IO; 9.4 GB / 8.0 GB RAM  )\n  10.113.237.160:4501    (  9% cpu;  4% machine; 0.001 Gbps;  5% disk IO; 6.8 GB / 8.0 GB RAM  )\n  10.113.237.160:4503    (  7% cpu;  4% machine; 0.001 Gbps;  5% disk IO; 6.9 GB / 8.0 GB RAM  )\n  10.113.237.161:4501    (  5% cpu;  2% machine; 0.001 Gbps;  3% disk IO; 8.4 GB / 8.0 GB RAM  )\n  10.113.237.161:4503    (  3% cpu;  2% machine; 0.001 Gbps;  4% disk IO; 6.8 GB / 8.0 GB RAM  )\n  10.113.237.162:4501    (  2% cpu;  3% machine; 0.040 Gbps;  4% disk IO; 6.7 GB / 8.0 GB RAM  )\n  10.113.237.162:4503    ( 10% cpu;  3% machine; 0.040 Gbps;  4% disk IO; 6.7 GB / 8.0 GB RAM  )\n  10.113.237.163:4501    ( 23% cpu;  7% machine; 0.170 Gbps; 19% disk IO; 4.8 GB / 8.0 GB RAM  )\n  10.113.237.163:4503    ( 18% cpu;  7% machine; 0.170 Gbps; 19% disk IO; 4.8 GB / 8.0 GB RAM  )\n  10.113.237.165:4501    (  8% cpu;  3% machine; 0.001 Gbps;  3% disk IO; 4.8 GB / 8.0 GB RAM  )\n  10.113.237.165:4503    (  2% cpu;  3% machine; 0.001 Gbps;  3% disk IO; 4.8 GB / 8.0 GB RAM  )\n  10.113.237.166:4501    ( 23% cpu;  4% machine; 0.001 Gbps; 10% disk IO; 5.9 GB / 8.0 GB RAM  )\n  10.113.237.166:4503    (  2% cpu;  4% machine; 0.001 Gbps;  7% disk IO; 7.4 GB / 8.0 GB RAM  )\n  10.113.237.167:4501    (  1% cpu;  2% machine; 0.001 Gbps;  0% disk IO; 2.5 GB / 8.0 GB RAM  )\n  10.113.237.167:4503    (  1% cpu;  2% machine; 0.001 Gbps;  0% disk IO; 2.6 GB / 8.0 GB RAM  )\n  10.113.237.168:4501    (  8% cpu;  3% machine; 0.002 Gbps;  4% disk IO; 9.4 GB / 8.0 GB RAM  )\n  10.113.237.168:4503    (  2% cpu;  3% machine; 0.002 Gbps;  3% disk IO; 6.8 GB / 8.0 GB RAM  )\n  10.113.237.169:4501    (  8% cpu;  4% machine; 0.001 Gbps;  5% disk IO; 7.0 GB / 8.0 GB RAM  )\n  10.113.237.169:4503    (  7% cpu;  4% machine; 0.001 Gbps;  4% disk IO; 6.8 GB / 8.0 GB RAM  )\n  10.113.237.170:4501    (  3% cpu;  4% machine; 0.100 Gbps;  9% disk IO; 7.1 GB / 8.0 GB RAM  )\n  10.113.237.170:4503    ( 14% cpu;  4% machine; 0.100 Gbps;  9% disk IO; 4.8 GB / 8.0 GB RAM  )\n  10.113.237.171:4501    (  3% cpu;  3% machine; 0.001 Gbps;  3% disk IO; 4.8 GB / 8.0 GB RAM  )\n  10.113.237.171:4503    (  8% cpu;  3% machine; 0.001 Gbps;  3% disk IO; 4.8 GB / 8.0 GB RAM  )\n  10.113.237.172:4501    (  1% cpu;  2% machine; 0.001 Gbps;  0% disk IO; 0.2 GB / 8.0 GB RAM  )\n  10.113.237.172:4503    (  1% cpu;  2% machine; 0.001 Gbps;  0% disk IO; 0.2 GB / 8.0 GB RAM  )\n  10.113.237.173:4501    (  1% cpu;  2% machine; 0.001 Gbps;  0% disk IO; 0.2 GB / 8.0 GB RAM  )\n  10.113.237.173:4503    (  1% cpu;  2% machine; 0.001 Gbps;  0% disk IO; 0.2 GB / 8.0 GB RAM  )\n  10.113.237.174:4501    (  2% cpu; 12% machine; 0.001 Gbps;  3% disk IO; 0.3 GB / 7.2 GB RAM  )\n  10.113.237.176:4501    (  4% cpu;  9% machine; 0.004 Gbps;  3% disk IO; 0.2 GB / 8.0 GB RAM  )\n  10.113.237.177:4501    (  1% cpu;  5% machine; 0.000 Gbps;  2% disk IO; 0.3 GB / 8.0 GB RAM  )\n  10.113.237.178:4501    (  2% cpu;  5% machine; 0.000 Gbps;  2% disk IO; 0.2 GB / 8.0 GB RAM  )\n  10.113.237.179:4501    (  3% cpu;  7% machine; 0.000 Gbps;  2% disk IO; 0.2 GB / 8.0 GB RAM  )\n  10.113.237.180:4501    ( 13% cpu; 14% machine; 0.005 Gbps;  2% disk IO; 0.3 GB / 8.0 GB RAM  )\n  10.113.237.181:4501    (  1% cpu;  1% machine; 0.001 Gbps;  0% disk IO; 0.1 GB / 8.0 GB RAM  )\n  10.113.237.181:4503    (  1% cpu;  1% machine; 0.001 Gbps;  0% disk IO; 0.2 GB / 8.0 GB RAM  )\n\nCoordination servers:\n  10.113.237.132:4501  (reachable)\n  10.113.237.134:4503  (reachable)\n  10.113.237.138:4503  (reachable)\n  10.113.237.152:4501  (reachable)\n  10.113.237.167:4503  (reachable)\n  10.113.237.171:4501  (reachable)\n  10.113.237.172:4503  (reachable)\n  10.113.237.173:4503  (reachable)\n  10.113.237.181:4503  (reachable)\n\nClient time: 09/22/23 01:49:50\n\nWARNING: A single process is both a transaction log and a storage server.\n  For best performance use dedicated disks for the transaction logs by setting process classes.\n</code></pre>",
        "post_number": 6,
        "post_type": 1,
        "posts_count": 17,
        "updated_at": "2023-09-22T01:58:19.817Z",
        "reply_count": 1,
        "reply_to_post_number": null,
        "quote_count": 0,
        "incoming_link_count": 0,
        "reads": 25,
        "readers_count": 24,
        "score": 10.0,
        "yours": false,
        "topic_id": 4156,
        "topic_slug": "multi-dc-replication-fails-during-dr-test",
        "display_username": null,
        "primary_group_name": null,
        "flair_name": null,
        "flair_url": null,
        "flair_bg_color": null,
        "flair_color": null,
        "flair_group_id": null,
        "badges_granted": [],
        "version": 1,
        "can_edit": false,
        "can_delete": false,
        "can_recover": false,
        "can_see_hidden_post": false,
        "can_wiki": false,
        "read": true,
        "user_title": null,
        "bookmarked": false,
        "actions_summary": [],
        "moderator": false,
        "admin": false,
        "staff": false,
        "user_id": 1320,
        "hidden": false,
        "trust_level": 1,
        "deleted_at": null,
        "user_deleted": false,
        "edit_reason": null,
        "can_view_edit_history": true,
        "wiki": false,
        "post_url": "/t/multi-dc-replication-fails-during-dr-test/4156/6",
        "can_accept_answer": false,
        "can_unaccept_answer": false,
        "accepted_answer": false,
        "topic_accepted_answer": null
      },
      {
        "id": 13324,
        "name": "Johannes Scheuermann",
        "username": "johscheuer",
        "avatar_template": "https://avatars.discourse-cdn.com/v4/letter/j/f475e1/{size}.png",
        "created_at": "2023-09-25T08:52:15.413Z",
        "cooked": "<p>Could you share the operator logs for your test run? I would be interested to see what the subreconciler <code>addPods</code> and <code>addPVCs</code> is saying.</p>\n<blockquote>\n<p>Simulating dc1 failure is terminating all pods in dc1 namespace (all VMs in AZ1), and bringing them back.</p>\n</blockquote>\n<p>I assume you are running a \u201ckubectl delete \u2026\u201d, correct? Are all the deleted Pods are actually created again? And the PVCs in this namespace are not touched?</p>\n<blockquote>\n<p>What is the process to restart Tlogs Interfaces (manually) ?</p>\n</blockquote>\n<p>Those should be automatically restarted once the Pod is recreated and the according PVC is mounted. You can manually restart a process by using the kill command from fdbcli e.g. <code>kill; kill &lt;IP:Port&gt;</code>.</p>",
        "post_number": 7,
        "post_type": 1,
        "posts_count": 17,
        "updated_at": "2023-09-25T08:52:15.413Z",
        "reply_count": 2,
        "reply_to_post_number": 6,
        "quote_count": 0,
        "incoming_link_count": 0,
        "reads": 24,
        "readers_count": 23,
        "score": 14.8,
        "yours": false,
        "topic_id": 4156,
        "topic_slug": "multi-dc-replication-fails-during-dr-test",
        "display_username": "Johannes Scheuermann",
        "primary_group_name": null,
        "flair_name": null,
        "flair_url": null,
        "flair_bg_color": null,
        "flair_color": null,
        "flair_group_id": null,
        "badges_granted": [],
        "version": 1,
        "can_edit": false,
        "can_delete": false,
        "can_recover": false,
        "can_see_hidden_post": false,
        "can_wiki": false,
        "read": true,
        "user_title": "",
        "reply_to_user": {
          "id": 1320,
          "username": "stefanvasilic4",
          "name": null,
          "avatar_template": "https://avatars.discourse-cdn.com/v4/letter/s/a8b319/{size}.png"
        },
        "bookmarked": false,
        "actions_summary": [],
        "moderator": false,
        "admin": false,
        "staff": false,
        "user_id": 849,
        "hidden": false,
        "trust_level": 2,
        "deleted_at": null,
        "user_deleted": false,
        "edit_reason": null,
        "can_view_edit_history": true,
        "wiki": false,
        "post_url": "/t/multi-dc-replication-fails-during-dr-test/4156/7",
        "can_accept_answer": false,
        "can_unaccept_answer": false,
        "accepted_answer": false,
        "topic_accepted_answer": null
      },
      {
        "id": 13329,
        "name": null,
        "username": "stefanvasilic4",
        "avatar_template": "https://avatars.discourse-cdn.com/v4/letter/s/a8b319/{size}.png",
        "created_at": "2023-09-25T14:50:57.838Z",
        "cooked": "<p>Yes pods are created back and running\u2026</p>\n<ul>\n<li>since pods map to nodes , i scale down nodes in that particular AZ (i use ocp mchineset for this) , and pods stay in <code>Pending</code> until i scale back up</li>\n<li>i also, have to delete pvc in ns otherwise pods do not start again</li>\n<li>i use local storage operator to create a storageclass (that will create pvcs) out of VM\u2019s nvme disk</li>\n</ul>\n<p>i restarted processes with kubectl fdb plugin and left it over the weekend \u2026 so that worked , but have to test it more\u2026</p>\n<pre><code class=\"lang-auto\">{\"level\":\"info\",\"ts\":\"2023-09-21T21:28:21Z\",\"logger\":\"controller\",\"msg\":\"Has unhealthy process group\",\"namespace\":\"dc1\",\"cluster\":\"fdb-cluster-1\",\"reconciler\":\"controllers.updateStatus\",\"method\":\"CheckReconciliation\",\"namespace\":\"dc1\",\"cluster\":\"fdb-cluster-1\",\"processGroupID\":\"dc1-storage-11\",\"state\":\"HasUnhealthyProcess\",\"conditions\":[\"MissingProcesses\"]}\n{\"level\":\"info\",\"ts\":\"2023-09-21T21:28:21Z\",\"logger\":\"controller\",\"msg\":\"Not all process groups are reconciled\",\"namespace\":\"dc1\",\"cluster\":\"fdb-cluster-1\",\"reconciler\":\"controllers.updateStatus\",\"method\":\"CheckReconciliation\",\"namespace\":\"dc1\",\"cluster\":\"fdb-cluster-1\",\"desiredProcessGroups\":22,\"reconciledProcessGroups\":21}\n{\"level\":\"info\",\"ts\":\"2023-09-21T21:28:21Z\",\"logger\":\"controller\",\"msg\":\"Subreconciler finished run\",\"namespace\":\"dc1\",\"cluster\":\"fdb-cluster-1\",\"reconciler\":\"controllers.updateStatus\",\"duration_seconds\":0.087244812}\n{\"level\":\"info\",\"ts\":\"2023-09-21T21:28:21Z\",\"logger\":\"controller\",\"msg\":\"Cluster was not fully reconciled by reconciliation process\",\"namespace\":\"dc1\",\"cluster\":\"fdb-cluster-1\",\"status\":{\"hasUnhealthyProcess\":2},\"CurrentGeneration\":0,\"OriginalGeneration\":2,\"DelayedRequeue\":false}\n{\"level\":\"info\",\"ts\":\"2023-09-21T21:28:21Z\",\"logger\":\"controller\",\"msg\":\"Reconciliation run finished\",\"namespace\":\"dc1\",\"cluster\":\"fdb-cluster-1\",\"duration_seconds\":0.342980124,\"cacheStatus\":true}\n{\"level\":\"info\",\"ts\":\"2023-09-21T21:28:21Z\",\"logger\":\"controller\",\"msg\":\"Fetch machine-readable status for reconcilitation loop\",\"namespace\":\"dc1\",\"cluster\":\"fdb-cluster-1\",\"cacheStatus\":true}\n{\"level\":\"info\",\"ts\":\"2023-09-21T21:28:21Z\",\"logger\":\"controller\",\"msg\":\"Trying connection options\",\"namespace\":\"dc1\",\"cluster\":\"fdb-cluster-1\",\"connectionString\":[\"fdb_cluster_1:jBYTGxM4zAJ2fdbYTAWUctcWWs8bNS13@10.113.237.132:4501,10.113.237.134:4503,10.113.237.138:4503,10.113.237.152:4501,10.113.237.167:4503,10.113.237.171:4501,10.113.237.172:4503,10.113.237.173:4503,10.113.237.181:4503\",\"fdb_cluster_1:VXpHlwDugQ4N9oTlUTQDIwDS1aZf18BP@10.113.237.144:4501,10.113.237.145:4501,10.113.237.150:4501,10.113.237.148:4501,10.113.237.136:4501\"]}\n{\"level\":\"info\",\"ts\":\"2023-09-21T21:28:21Z\",\"logger\":\"controller\",\"msg\":\"Attempting to get connection string from cluster\",\"namespace\":\"dc1\",\"cluster\":\"fdb-cluster-1\",\"connectionString\":\"fdb_cluster_1:jBYTGxM4zAJ2fdbYTAWUctcWWs8bNS13@10.113.237.132:4501,10.113.237.134:4503,10.113.237.138:4503,10.113.237.152:4501,10.113.237.167:4503,10.113.237.171:4501,10.113.237.172:4503,10.113.237.173:4503,10.113.237.181:4503\"}\n{\"level\":\"info\",\"ts\":\"2023-09-21T21:28:21Z\",\"logger\":\"fdbclient\",\"msg\":\"Fetch values from FDB\",\"namespace\":\"dc1\",\"cluster\":\"fdb-cluster-1\",\"key\":\"\\ufffd/coordinators\"}\n{\"level\":\"info\",\"ts\":\"2023-09-21T21:28:21Z\",\"logger\":\"fdbclient\",\"msg\":\"Done fetching values from FDB\",\"namespace\":\"dc1\",\"cluster\":\"fdb-cluster-1\",\"key\":\"\\ufffd/coordinators\"}\n{\"level\":\"info\",\"ts\":\"2023-09-21T21:28:21Z\",\"logger\":\"controller\",\"msg\":\"Chose connection option\",\"namespace\":\"dc1\",\"cluster\":\"fdb-cluster-1\",\"connectionString\":\"fdb_cluster_1:jBYTGxM4zAJ2fdbYTAWUctcWWs8bNS13@10.113.237.132:4501,10.113.237.134:4503,10.113.237.138:4503,10.113.237.152:4501,10.113.237.167:4503,10.113.237.171:4501,10.113.237.172:4503,10.113.237.173:4503,10.113.237.181:4503\"}\n{\"level\":\"info\",\"ts\":\"2023-09-21T21:28:21Z\",\"logger\":\"fdbclient\",\"msg\":\"Fetch values from FDB\",\"namespace\":\"dc1\",\"cluster\":\"fdb-cluster-1\",\"key\":\"\\ufffd\\ufffd/status/json\"}\n{\"level\":\"info\",\"ts\":\"2023-09-21T21:28:21Z\",\"logger\":\"fdbclient\",\"msg\":\"Done fetching values from FDB\",\"namespace\":\"dc1\",\"cluster\":\"fdb-cluster-1\",\"key\":\"\\ufffd\\ufffd/status/json\"}\n{\"level\":\"info\",\"ts\":\"2023-09-21T21:28:21Z\",\"logger\":\"controller\",\"msg\":\"Attempting to run sub-reconciler\",\"namespace\":\"dc1\",\"cluster\":\"fdb-cluster-1\",\"reconciler\":\"controllers.updateStatus\"}\n{\"level\":\"info\",\"ts\":\"2023-09-21T21:28:21Z\",\"logger\":\"controller\",\"msg\":\"Disable taint feature\",\"namespace\":\"dc1\",\"cluster\":\"fdb-cluster-1\",\"reconciler\":\"controllers.updateStatus\",\"Disabled\":true}\n{\"level\":\"info\",\"ts\":\"2023-09-21T21:28:21Z\",\"logger\":\"controller\",\"msg\":\"Subreconciler finished run\",\"namespace\":\"dc1\",\"cluster\":\"fdb-cluster-1\",\"reconciler\":\"controllers.updateStatus\",\"duration_seconds\":0.112349926}\n{\"level\":\"info\",\"ts\":\"2023-09-21T21:28:21Z\",\"logger\":\"controller\",\"msg\":\"Attempting to run sub-reconciler\",\"namespace\":\"dc1\",\"cluster\":\"fdb-cluster-1\",\"reconciler\":\"controllers.updateLockConfiguration\"}\n{\"level\":\"info\",\"ts\":\"2023-09-21T21:28:21Z\",\"logger\":\"controller\",\"msg\":\"Subreconciler finished run\",\"namespace\":\"dc1\",\"cluster\":\"fdb-cluster-1\",\"reconciler\":\"controllers.updateLockConfiguration\",\"duration_seconds\":0.000006051}\n{\"level\":\"info\",\"ts\":\"2023-09-21T21:28:21Z\",\"logger\":\"controller\",\"msg\":\"Attempting to run sub-reconciler\",\"namespace\":\"dc1\",\"cluster\":\"fdb-cluster-1\",\"reconciler\":\"controllers.updateConfigMap\"}\n{\"level\":\"info\",\"ts\":\"2023-09-21T21:28:21Z\",\"logger\":\"controller\",\"msg\":\"Subreconciler finished run\",\"namespace\":\"dc1\",\"cluster\":\"fdb-cluster-1\",\"reconciler\":\"controllers.updateConfigMap\",\"duration_seconds\":0.000147837}\n{\"level\":\"info\",\"ts\":\"2023-09-21T21:28:21Z\",\"logger\":\"controller\",\"msg\":\"Attempting to run sub-reconciler\",\"namespace\":\"dc1\",\"cluster\":\"fdb-cluster-1\",\"reconciler\":\"controllers.checkClientCompatibility\"}\n{\"level\":\"info\",\"ts\":\"2023-09-21T21:28:21Z\",\"logger\":\"controller\",\"msg\":\"Subreconciler finished run\",\"namespace\":\"dc1\",\"cluster\":\"fdb-cluster-1\",\"reconciler\":\"controllers.checkClientCompatibility\",\"duration_seconds\":0.000014101}\n{\"level\":\"info\",\"ts\":\"2023-09-21T21:28:21Z\",\"logger\":\"controller\",\"msg\":\"Attempting to run sub-reconciler\",\"namespace\":\"dc1\",\"cluster\":\"fdb-cluster-1\",\"reconciler\":\"controllers.deletePodsForBuggification\"}\n{\"level\":\"info\",\"ts\":\"2023-09-21T21:28:21Z\",\"logger\":\"controller\",\"msg\":\"Subreconciler finished run\",\"namespace\":\"dc1\",\"cluster\":\"fdb-cluster-1\",\"reconciler\":\"controllers.deletePodsForBuggification\",\"duration_seconds\":0.000503897}\n{\"level\":\"info\",\"ts\":\"2023-09-21T21:28:21Z\",\"logger\":\"controller\",\"msg\":\"Attempting to run sub-reconciler\",\"namespace\":\"dc1\",\"cluster\":\"fdb-cluster-1\",\"reconciler\":\"controllers.replaceMisconfiguredProcessGroups\"}\n{\"level\":\"info\",\"ts\":\"2023-09-21T21:28:21Z\",\"logger\":\"controller\",\"msg\":\"Subreconciler finished run\",\"namespace\":\"dc1\",\"cluster\":\"fdb-cluster-1\",\"reconciler\":\"controllers.replaceMisconfiguredProcessGroups\",\"duration_seconds\":0.001388085}\n{\"level\":\"info\",\"ts\":\"2023-09-21T21:28:21Z\",\"logger\":\"controller\",\"msg\":\"Attempting to run sub-reconciler\",\"namespace\":\"dc1\",\"cluster\":\"fdb-cluster-1\",\"reconciler\":\"controllers.replaceFailedProcessGroups\"}\n{\"level\":\"info\",\"ts\":\"2023-09-21T21:28:21Z\",\"logger\":\"controller\",\"msg\":\"Check desired fault tolerance\",\"namespace\":\"dc1\",\"cluster\":\"fdb-cluster-1\",\"reconciler\":\"controllers.replaceFailedProcessGroups\",\"expectedFaultTolerance\":2,\"maxZoneFailuresWithoutLosingData\":-1,\"maxZoneFailuresWithoutLosingAvailability\":-1}\n{\"level\":\"info\",\"ts\":\"2023-09-21T21:28:21Z\",\"logger\":\"controller\",\"msg\":\"Subreconciler finished run\",\"namespace\":\"dc1\",\"cluster\":\"fdb-cluster-1\",\"reconciler\":\"controllers.replaceFailedProcessGroups\",\"duration_seconds\":0.000012672}\n{\"level\":\"info\",\"ts\":\"2023-09-21T21:28:21Z\",\"logger\":\"controller\",\"msg\":\"Attempting to run sub-reconciler\",\"namespace\":\"dc1\",\"cluster\":\"fdb-cluster-1\",\"reconciler\":\"controllers.addProcessGroups\"}\n{\"level\":\"info\",\"ts\":\"2023-09-21T21:28:21Z\",\"logger\":\"controller\",\"msg\":\"Subreconciler finished run\",\"namespace\":\"dc1\",\"cluster\":\"fdb-cluster-1\",\"reconciler\":\"controllers.addProcessGroups\",\"duration_seconds\":0.000021395}\n{\"level\":\"info\",\"ts\":\"2023-09-21T21:28:21Z\",\"logger\":\"controller\",\"msg\":\"Attempting to run sub-reconciler\",\"namespace\":\"dc1\",\"cluster\":\"fdb-cluster-1\",\"reconciler\":\"controllers.addServices\"}\n{\"level\":\"info\",\"ts\":\"2023-09-21T21:28:21Z\",\"logger\":\"controller\",\"msg\":\"Subreconciler finished run\",\"namespace\":\"dc1\",\"cluster\":\"fdb-cluster-1\",\"reconciler\":\"controllers.addServices\",\"duration_seconds\":0.00002893}\n{\"level\":\"info\",\"ts\":\"2023-09-21T21:28:21Z\",\"logger\":\"controller\",\"msg\":\"Attempting to run sub-reconciler\",\"namespace\":\"dc1\",\"cluster\":\"fdb-cluster-1\",\"reconciler\":\"controllers.addPVCs\"}\n{\"level\":\"info\",\"ts\":\"2023-09-21T21:28:21Z\",\"logger\":\"controller\",\"msg\":\"Subreconciler finished run\",\"namespace\":\"dc1\",\"cluster\":\"fdb-cluster-1\",\"reconciler\":\"controllers.addPVCs\",\"duration_seconds\":0.000232452}\n{\"level\":\"info\",\"ts\":\"2023-09-21T21:28:21Z\",\"logger\":\"controller\",\"msg\":\"Attempting to run sub-reconciler\",\"namespace\":\"dc1\",\"cluster\":\"fdb-cluster-1\",\"reconciler\":\"controllers.addPods\"}\n{\"level\":\"info\",\"ts\":\"2023-09-21T21:28:21Z\",\"logger\":\"controller\",\"msg\":\"Subreconciler finished run\",\"namespace\":\"dc1\",\"cluster\":\"fdb-cluster-1\",\"reconciler\":\"controllers.addPods\",\"duration_seconds\":0.000455288}\n{\"level\":\"info\",\"ts\":\"2023-09-21T21:28:21Z\",\"logger\":\"controller\",\"msg\":\"Attempting to run sub-reconciler\",\"namespace\":\"dc1\",\"cluster\":\"fdb-cluster-1\",\"reconciler\":\"controllers.generateInitialClusterFile\"}\n{\"level\":\"info\",\"ts\":\"2023-09-21T21:28:21Z\",\"logger\":\"controller\",\"msg\":\"Subreconciler finished run\",\"namespace\":\"dc1\",\"cluster\":\"fdb-cluster-1\",\"reconciler\":\"controllers.generateInitialClusterFile\",\"duration_seconds\":0.00000533}\n{\"level\":\"info\",\"ts\":\"2023-09-21T21:28:21Z\",\"logger\":\"controller\",\"msg\":\"Attempting to run sub-reconciler\",\"namespace\":\"dc1\",\"cluster\":\"fdb-cluster-1\",\"reconciler\":\"controllers.removeIncompatibleProcesses\"}\n{\"level\":\"info\",\"ts\":\"2023-09-21T21:28:21Z\",\"logger\":\"controller\",\"msg\":\"Subreconciler finished run\",\"namespace\":\"dc1\",\"cluster\":\"fdb-cluster-1\",\"reconciler\":\"controllers.removeIncompatibleProcesses\",\"duration_seconds\":0.000011198}\n{\"level\":\"info\",\"ts\":\"2023-09-21T21:28:21Z\",\"logger\":\"controller\",\"msg\":\"Attempting to run sub-reconciler\",\"namespace\":\"dc1\",\"cluster\":\"fdb-cluster-1\",\"reconciler\":\"controllers.updateSidecarVersions\"}\n{\"level\":\"info\",\"ts\":\"2023-09-21T21:28:21Z\",\"logger\":\"controller\",\"msg\":\"Subreconciler finished run\",\"namespace\":\"dc1\",\"cluster\":\"fdb-cluster-1\",\"reconciler\":\"controllers.updateSidecarVersions\",\"duration_seconds\":0.000002623}\n{\"level\":\"info\",\"ts\":\"2023-09-21T21:28:21Z\",\"logger\":\"controller\",\"msg\":\"Attempting to run sub-reconciler\",\"namespace\":\"dc1\",\"cluster\":\"fdb-cluster-1\",\"reconciler\":\"controllers.updatePodConfig\"}\n{\"level\":\"info\",\"ts\":\"2023-09-21T21:28:21Z\",\"logger\":\"controller\",\"msg\":\"Subreconciler finished run\",\"namespace\":\"dc1\",\"cluster\":\"fdb-cluster-1\",\"reconciler\":\"controllers.updatePodConfig\",\"duration_seconds\":0.000850175}\n{\"level\":\"info\",\"ts\":\"2023-09-21T21:28:21Z\",\"logger\":\"controller\",\"msg\":\"Attempting to run sub-reconciler\",\"namespace\":\"dc1\",\"cluster\":\"fdb-cluster-1\",\"reconciler\":\"controllers.updateMetadata\"}\n{\"level\":\"info\",\"ts\":\"2023-09-21T21:28:21Z\",\"logger\":\"controller\",\"msg\":\"Subreconciler finished run\",\"namespace\":\"dc1\",\"cluster\":\"fdb-cluster-1\",\"reconciler\":\"controllers.updateMetadata\",\"duration_seconds\":0.000577766}\n{\"level\":\"info\",\"ts\":\"2023-09-21T21:28:21Z\",\"logger\":\"controller\",\"msg\":\"Attempting to run sub-reconciler\",\"namespace\":\"dc1\",\"cluster\":\"fdb-cluster-1\",\"reconciler\":\"controllers.updateDatabaseConfiguration\"}\n{\"level\":\"info\",\"ts\":\"2023-09-21T21:28:21Z\",\"logger\":\"controller\",\"msg\":\"Subreconciler finished run\",\"namespace\":\"dc1\",\"cluster\":\"fdb-cluster-1\",\"reconciler\":\"controllers.updateDatabaseConfiguration\",\"duration_seconds\":0.000055063}\n{\"level\":\"info\",\"ts\":\"2023-09-21T21:28:21Z\",\"logger\":\"controller\",\"msg\":\"Attempting to run sub-reconciler\",\"namespace\":\"dc1\",\"cluster\":\"fdb-cluster-1\",\"reconciler\":\"controllers.chooseRemovals\"}\n{\"level\":\"info\",\"ts\":\"2023-09-21T21:28:21Z\",\"logger\":\"controller\",\"msg\":\"Subreconciler finished run\",\"namespace\":\"dc1\",\"cluster\":\"fdb-cluster-1\",\"reconciler\":\"controllers.chooseRemovals\",\"duration_seconds\":0.000054176}\n{\"level\":\"info\",\"ts\":\"2023-09-21T21:28:21Z\",\"logger\":\"controller\",\"msg\":\"Attempting to run sub-reconciler\",\"namespace\":\"dc1\",\"cluster\":\"fdb-cluster-1\",\"reconciler\":\"controllers.excludeProcesses\"}\n{\"level\":\"info\",\"ts\":\"2023-09-21T21:28:21Z\",\"logger\":\"controller\",\"msg\":\"Subreconciler finished run\",\"namespace\":\"dc1\",\"cluster\":\"fdb-cluster-1\",\"reconciler\":\"controllers.excludeProcesses\",\"duration_seconds\":0.000020555}\n{\"level\":\"info\",\"ts\":\"2023-09-21T21:28:21Z\",\"logger\":\"controller\",\"msg\":\"Attempting to run sub-reconciler\",\"namespace\":\"dc1\",\"cluster\":\"fdb-cluster-1\",\"reconciler\":\"controllers.changeCoordinators\"}\n{\"level\":\"info\",\"ts\":\"2023-09-21T21:28:21Z\",\"logger\":\"controller\",\"msg\":\"Subreconciler finished run\",\"namespace\":\"dc1\",\"cluster\":\"fdb-cluster-1\",\"reconciler\":\"controllers.changeCoordinators\",\"duration_seconds\":0.000960452}\n{\"level\":\"info\",\"ts\":\"2023-09-21T21:28:21Z\",\"logger\":\"controller\",\"msg\":\"Attempting to run sub-reconciler\",\"namespace\":\"dc1\",\"cluster\":\"fdb-cluster-1\",\"reconciler\":\"controllers.bounceProcesses\"}\n{\"level\":\"info\",\"ts\":\"2023-09-21T21:28:21Z\",\"logger\":\"controller\",\"msg\":\"Subreconciler finished run\",\"namespace\":\"dc1\",\"cluster\":\"fdb-cluster-1\",\"reconciler\":\"controllers.bounceProcesses\",\"duration_seconds\":0.000116449}\n{\"level\":\"info\",\"ts\":\"2023-09-21T21:28:21Z\",\"logger\":\"controller\",\"msg\":\"Attempting to run sub-reconciler\",\"namespace\":\"dc1\",\"cluster\":\"fdb-cluster-1\",\"reconciler\":\"controllers.maintenanceModeChecker\"}\n{\"level\":\"info\",\"ts\":\"2023-09-21T21:28:21Z\",\"logger\":\"controller\",\"msg\":\"Subreconciler finished run\",\"namespace\":\"dc1\",\"cluster\":\"fdb-cluster-1\",\"reconciler\":\"controllers.maintenanceModeChecker\",\"duration_seconds\":0.000003884}\n{\"level\":\"info\",\"ts\":\"2023-09-21T21:28:21Z\",\"logger\":\"controller\",\"msg\":\"Attempting to run sub-reconciler\",\"namespace\":\"dc1\",\"cluster\":\"fdb-cluster-1\",\"reconciler\":\"controllers.updatePods\"}\n{\"level\":\"info\",\"ts\":\"2023-09-21T21:28:21Z\",\"logger\":\"controller\",\"msg\":\"Subreconciler finished run\",\"namespace\":\"dc1\",\"cluster\":\"fdb-cluster-1\",\"reconciler\":\"controllers.updatePods\",\"duration_seconds\":0.001538568}\n{\"level\":\"info\",\"ts\":\"2023-09-21T21:28:21Z\",\"logger\":\"controller\",\"msg\":\"Attempting to run sub-reconciler\",\"namespace\":\"dc1\",\"cluster\":\"fdb-cluster-1\",\"reconciler\":\"controllers.removeProcessGroups\"}\n{\"level\":\"info\",\"ts\":\"2023-09-21T21:28:21Z\",\"logger\":\"controller\",\"msg\":\"Subreconciler finished run\",\"namespace\":\"dc1\",\"cluster\":\"fdb-cluster-1\",\"reconciler\":\"controllers.removeProcessGroups\",\"duration_seconds\":0.000048341}\n{\"level\":\"info\",\"ts\":\"2023-09-21T21:28:21Z\",\"logger\":\"controller\",\"msg\":\"Attempting to run sub-reconciler\",\"namespace\":\"dc1\",\"cluster\":\"fdb-cluster-1\",\"reconciler\":\"controllers.removeServices\"}\n{\"level\":\"info\",\"ts\":\"2023-09-21T21:28:21Z\",\"logger\":\"controller\",\"msg\":\"Subreconciler finished run\",\"namespace\":\"dc1\",\"cluster\":\"fdb-cluster-1\",\"reconciler\":\"controllers.removeServices\",\"duration_seconds\":0.000007047}\n{\"level\":\"info\",\"ts\":\"2023-09-21T21:28:21Z\",\"logger\":\"controller\",\"msg\":\"Attempting to run sub-reconciler\",\"namespace\":\"dc1\",\"cluster\":\"fdb-cluster-1\",\"reconciler\":\"controllers.updateStatus\"}\n{\"level\":\"info\",\"ts\":\"2023-09-21T21:28:21Z\",\"logger\":\"controller\",\"msg\":\"Disable taint feature\",\"namespace\":\"dc1\",\"cluster\":\"fdb-cluster-1\",\"reconciler\":\"controllers.updateStatus\",\"Disabled\":true}\n{\"level\":\"info\",\"ts\":\"2023-09-21T21:28:21Z\",\"logger\":\"controller\",\"msg\":\"Subreconciler finished run\",\"namespace\":\"dc1\",\"cluster\":\"fdb-cluster-1\",\"reconciler\":\"controllers.updateStatus\",\"duration_seconds\":0.080311831}\n{\"level\":\"info\",\"ts\":\"2023-09-21T21:28:21Z\",\"logger\":\"controller\",\"msg\":\"Reconciliation complete\",\"namespace\":\"dc1\",\"cluster\":\"fdb-cluster-1\",\"generation\":2}\n{\"level\":\"info\",\"ts\":\"2023-09-21T21:28:21Z\",\"logger\":\"controller\",\"msg\":\"Reconciliation run finished\",\"namespace\":\"dc1\",\"cluster\":\"fdb-cluster-1\",\"duration_seconds\":0.362400171,\"cacheStatus\":true}\n\n\n</code></pre>",
        "post_number": 8,
        "post_type": 1,
        "posts_count": 17,
        "updated_at": "2023-09-25T14:50:57.838Z",
        "reply_count": 1,
        "reply_to_post_number": 7,
        "quote_count": 0,
        "incoming_link_count": 6,
        "reads": 23,
        "readers_count": 22,
        "score": 39.6,
        "yours": false,
        "topic_id": 4156,
        "topic_slug": "multi-dc-replication-fails-during-dr-test",
        "display_username": null,
        "primary_group_name": null,
        "flair_name": null,
        "flair_url": null,
        "flair_bg_color": null,
        "flair_color": null,
        "flair_group_id": null,
        "badges_granted": [],
        "version": 1,
        "can_edit": false,
        "can_delete": false,
        "can_recover": false,
        "can_see_hidden_post": false,
        "can_wiki": false,
        "read": true,
        "user_title": null,
        "reply_to_user": {
          "id": 849,
          "username": "johscheuer",
          "name": "Johannes Scheuermann",
          "avatar_template": "https://avatars.discourse-cdn.com/v4/letter/j/f475e1/{size}.png"
        },
        "bookmarked": false,
        "actions_summary": [],
        "moderator": false,
        "admin": false,
        "staff": false,
        "user_id": 1320,
        "hidden": false,
        "trust_level": 1,
        "deleted_at": null,
        "user_deleted": false,
        "edit_reason": null,
        "can_view_edit_history": true,
        "wiki": false,
        "post_url": "/t/multi-dc-replication-fails-during-dr-test/4156/8",
        "can_accept_answer": false,
        "can_unaccept_answer": false,
        "accepted_answer": false,
        "topic_accepted_answer": null
      },
      {
        "id": 13331,
        "name": "Johannes Scheuermann",
        "username": "johscheuer",
        "avatar_template": "https://avatars.discourse-cdn.com/v4/letter/j/f475e1/{size}.png",
        "created_at": "2023-09-26T06:17:47.765Z",
        "cooked": "<blockquote>\n<ul>\n<li>i also, have to delete pvc in ns otherwise pods do not start again</li>\n</ul>\n</blockquote>\n<p>That probably means all data for those PVCs are lost. The Pods are probably not being scheduled as the PVC cannot be bound to the previously existing PV (as you removed the node).</p>\n<blockquote>\n<ul>\n<li>i use local storage operator to create a storageclass (that will create pvcs) out of VM\u2019s nvme disk</li>\n</ul>\n</blockquote>\n<p>Basically what you are testing is what happens when a whole DC gets all resources deleted, including the data. Is that the intention?</p>",
        "post_number": 9,
        "post_type": 1,
        "posts_count": 17,
        "updated_at": "2023-09-26T06:17:47.765Z",
        "reply_count": 1,
        "reply_to_post_number": 8,
        "quote_count": 0,
        "incoming_link_count": 0,
        "reads": 24,
        "readers_count": 23,
        "score": 9.8,
        "yours": false,
        "topic_id": 4156,
        "topic_slug": "multi-dc-replication-fails-during-dr-test",
        "display_username": "Johannes Scheuermann",
        "primary_group_name": null,
        "flair_name": null,
        "flair_url": null,
        "flair_bg_color": null,
        "flair_color": null,
        "flair_group_id": null,
        "badges_granted": [],
        "version": 1,
        "can_edit": false,
        "can_delete": false,
        "can_recover": false,
        "can_see_hidden_post": false,
        "can_wiki": false,
        "read": true,
        "user_title": "",
        "reply_to_user": {
          "id": 1320,
          "username": "stefanvasilic4",
          "name": null,
          "avatar_template": "https://avatars.discourse-cdn.com/v4/letter/s/a8b319/{size}.png"
        },
        "bookmarked": false,
        "actions_summary": [],
        "moderator": false,
        "admin": false,
        "staff": false,
        "user_id": 849,
        "hidden": false,
        "trust_level": 2,
        "deleted_at": null,
        "user_deleted": false,
        "edit_reason": null,
        "can_view_edit_history": true,
        "wiki": false,
        "post_url": "/t/multi-dc-replication-fails-during-dr-test/4156/9",
        "can_accept_answer": false,
        "can_unaccept_answer": false,
        "accepted_answer": false,
        "topic_accepted_answer": null
      },
      {
        "id": 13336,
        "name": null,
        "username": "stefanvasilic4",
        "avatar_template": "https://avatars.discourse-cdn.com/v4/letter/s/a8b319/{size}.png",
        "created_at": "2023-09-26T15:43:42.758Z",
        "cooked": "<p>yes, the intention is to test losing the entire AZ, with VMs and its data and let fdb. cluster replicate data back to primary.</p>\n<p>i see some storage server lagging and i assume this is related to networking which in cloud we do not control. am i right in my assumption ? how to remediate ?</p>\n<pre><code class=\"lang-auto\">bash kubectl-fdb-plugin.sh \"fdb analyze fdb-cluster-1\"                  \nChecking cluster: dc1/fdb-cluster-1\n\u2714 Cluster is available\n\u2714 Cluster is fully replicated\n\u2714 Cluster is reconciled\n\u2714 ProcessGroups are all in ready condition\n\u2714 Pods are all running and available\nChecking cluster: dc1/fdb-cluster-1 with auto-fix: false\n\u2716 Process: dc1-storage-10 with address: 10.113.237.132:4501 error: storage_server_lagging type: , time: 1970-01-01 00:00:00 +0000 UTC\n\u2716 Process: dc1-storage-9 with address: 10.113.237.139:4501 error: storage_server_lagging type: , time: 1970-01-01 00:00:00 +0000 UTC\n\u2716 Process: dc1-storage-16 with address: 10.113.237.137:4501 error: storage_server_lagging type: , time: 1970-01-01 00:00:00 +0000 UTC\n\u2716 Process: dc1-storage-12 with address: 10.113.237.147:4501 error: storage_server_lagging type: , time: 1970-01-01 00:00:00 +0000 UTC\n\u2716 Process: dc1-storage-8 with address: 10.113.237.144:4503 error: storage_server_lagging type: , time: 1970-01-01 00:00:00 +0000 UTC\n\u2716 Process: dc1-storage-6 with address: 10.113.237.142:4503 error: storage_server_lagging type: , time: 1970-01-01 00:00:00 +0000 UTC\n\u2716 Process: dc1-storage-1 with address: 10.113.237.135:4503 error: storage_server_lagging type: , time: 1970-01-01 00:00:00 +0000 UTC\n\u2716 Process: dc1-storage-11 with address: 10.113.237.148:4503 error: storage_server_lagging type: , time: 1970-01-01 00:00:00 +0000 UTC\n\u2716 Process: dc1-storage-17 with address: 10.113.237.143:4503 error: storage_server_lagging type: , time: 1970-01-01 00:00:00 +0000 UTC\n\u2716 Process: dc1-storage-7 with address: 10.113.237.136:4501 error: storage_server_lagging type: , time: 1970-01-01 00:00:00 +0000 UTC\n\u2716 Process: dc1-storage-2 with address: 10.113.237.133:4503 error: storage_server_lagging type: , time: 1970-01-01 00:00:00 +0000 UTC\n\u2716 Process: dc1-storage-14 with address: 10.113.237.141:4501 error: storage_server_lagging type: , time: 1970-01-01 00:00:00 +0000 UTC\n\u2716 Process: dc1-storage-11 with address: 10.113.237.148:4501 error: storage_server_lagging type: , time: 1970-01-01 00:00:00 +0000 UTC\n\u2716 Process: dc1-storage-10 with address: 10.113.237.132:4503 error: storage_server_lagging type: , time: 1970-01-01 00:00:00 +0000 UTC\n\u2716 Process: dc1-storage-4 with address: 10.113.237.150:4503 error: storage_server_lagging type: , time: 1970-01-01 00:00:00 +0000 UTC\n\u2716 Process: dc1-storage-8 with address: 10.113.237.144:4501 error: storage_server_lagging type: , time: 1970-01-01 00:00:00 +0000 UTC\n\u2716 Process: dc1-storage-12 with address: 10.113.237.147:4503 error: storage_server_lagging type: , time: 1970-01-01 00:00:00 +0000 UTC\n\u2716 Process: dc1-storage-17 with address: 10.113.237.143:4501 error: storage_server_lagging type: , time: 1970-01-01 00:00:00 +0000 UTC\n\u2716 Process: dc1-storage-1 with address: 10.113.237.135:4501 error: storage_server_lagging type: , time: 1970-01-01 00:00:00 +0000 UTC\n\u2716 Process: dc1-storage-6 with address: 10.113.237.142:4501 error: storage_server_lagging type: , time: 1970-01-01 00:00:00 +0000 UTC\n\u2716 Process: dc1-storage-5 with address: 10.113.237.140:4501 error: storage_server_lagging type: , time: 1970-01-01 00:00:00 +0000 UTC\n\u2716 Process: dc1-storage-5 with address: 10.113.237.140:4503 error: storage_server_lagging type: , time: 1970-01-01 00:00:00 +0000 UTC\n\u2716 Process: dc1-storage-15 with address: 10.113.237.138:4501 error: storage_server_lagging type: , time: 1970-01-01 00:00:00 +0000 UTC\n\u2716 Process: dc1-storage-15 with address: 10.113.237.138:4503 error: storage_server_lagging type: , time: 1970-01-01 00:00:00 +0000 UTC\n\u2716 Process: dc1-storage-3 with address: 10.113.237.146:4503 error: storage_server_lagging type: , time: 1970-01-01 00:00:00 +0000 UTC\n\u2716 Process: dc1-storage-9 with address: 10.113.237.139:4503 error: storage_server_lagging type: , time: 1970-01-01 00:00:00 +0000 UTC\n\u2716 Process: dc1-storage-7 with address: 10.113.237.136:4503 error: storage_server_lagging type: , time: 1970-01-01 00:00:00 +0000 UTC\n\u2716 Process: dc1-storage-13 with address: 10.113.237.145:4501 error: storage_server_lagging type: , time: 1970-01-01 00:00:00 +0000 UTC\n\u2716 Process: dc1-storage-4 with address: 10.113.237.150:4501 error: storage_server_lagging type: , time: 1970-01-01 00:00:00 +0000 UTC\n\u2716 Process: dc1-storage-3 with address: 10.113.237.146:4501 error: storage_server_lagging type: , time: 1970-01-01 00:00:00 +0000 UTC\n\u2716 Process: dc1-storage-2 with address: 10.113.237.133:4501 error: storage_server_lagging type: , time: 1970-01-01 00:00:00 +0000 UTC\n\u2716 Process: dc1-storage-13 with address: 10.113.237.145:4503 error: storage_server_lagging type: , time: 1970-01-01 00:00:00 +0000 UTC\n\u2716 Process: dc1-storage-16 with address: 10.113.237.137:4503 error: storage_server_lagging type: , time: 1970-01-01 00:00:00 +0000 UTC\n\u2716 Process: dc1-storage-14 with address: 10.113.237.141:4503 error: storage_server_lagging type: , time: 1970-01-01 00:00:00 +0000 UTC\nError: \nfound issues in status json for cluster fdb-cluster-1. Please check them\n</code></pre>",
        "post_number": 10,
        "post_type": 1,
        "posts_count": 17,
        "updated_at": "2023-09-26T15:43:42.758Z",
        "reply_count": 0,
        "reply_to_post_number": 9,
        "quote_count": 0,
        "incoming_link_count": 0,
        "reads": 24,
        "readers_count": 23,
        "score": 4.8,
        "yours": false,
        "topic_id": 4156,
        "topic_slug": "multi-dc-replication-fails-during-dr-test",
        "display_username": null,
        "primary_group_name": null,
        "flair_name": null,
        "flair_url": null,
        "flair_bg_color": null,
        "flair_color": null,
        "flair_group_id": null,
        "badges_granted": [],
        "version": 1,
        "can_edit": false,
        "can_delete": false,
        "can_recover": false,
        "can_see_hidden_post": false,
        "can_wiki": false,
        "read": true,
        "user_title": null,
        "reply_to_user": {
          "id": 849,
          "username": "johscheuer",
          "name": "Johannes Scheuermann",
          "avatar_template": "https://avatars.discourse-cdn.com/v4/letter/j/f475e1/{size}.png"
        },
        "bookmarked": false,
        "actions_summary": [],
        "moderator": false,
        "admin": false,
        "staff": false,
        "user_id": 1320,
        "hidden": false,
        "trust_level": 1,
        "deleted_at": null,
        "user_deleted": false,
        "edit_reason": null,
        "can_view_edit_history": true,
        "wiki": false,
        "post_url": "/t/multi-dc-replication-fails-during-dr-test/4156/10",
        "can_accept_answer": false,
        "can_unaccept_answer": false,
        "accepted_answer": false,
        "topic_accepted_answer": null
      },
      {
        "id": 13341,
        "name": null,
        "username": "stefanvasilic4",
        "avatar_template": "https://avatars.discourse-cdn.com/v4/letter/s/a8b319/{size}.png",
        "created_at": "2023-09-28T18:28:56.108Z",
        "cooked": "<p>Hi,  can you please validate my multi_dc design. I am basically following <a href=\"https://github.com/FoundationDB/fdb-kubernetes-operator/tree/main/config/tests/multi_dc\" rel=\"noopener nofollow ugc\">https://github.com/FoundationDB/fdb-kubernetes-operator/tree/main/config/tests/multi_dc</a> , with:</p>\n<ul>\n<li>1 k8s cluster</li>\n<li>3 fdb running in 3 separate ns, each fdb is controlled by an operator pod.</li>\n</ul>\n<p>Q: Would it be better to deploy all fdb instances in 1 ns and let 1 operator pod manage all 3 , because anyway the pods get scheduled on different AZ nodes ?</p>",
        "post_number": 11,
        "post_type": 1,
        "posts_count": 17,
        "updated_at": "2023-09-28T18:28:56.108Z",
        "reply_count": 0,
        "reply_to_post_number": null,
        "quote_count": 0,
        "incoming_link_count": 2,
        "reads": 24,
        "readers_count": 23,
        "score": 14.8,
        "yours": false,
        "topic_id": 4156,
        "topic_slug": "multi-dc-replication-fails-during-dr-test",
        "display_username": null,
        "primary_group_name": null,
        "flair_name": null,
        "flair_url": null,
        "flair_bg_color": null,
        "flair_color": null,
        "flair_group_id": null,
        "badges_granted": [],
        "version": 1,
        "can_edit": false,
        "can_delete": false,
        "can_recover": false,
        "can_see_hidden_post": false,
        "can_wiki": false,
        "link_counts": [
          {
            "url": "https://github.com/FoundationDB/fdb-kubernetes-operator/tree/main/config/tests/multi_dc",
            "internal": false,
            "reflection": false,
            "clicks": 3
          }
        ],
        "read": true,
        "user_title": null,
        "bookmarked": false,
        "actions_summary": [],
        "moderator": false,
        "admin": false,
        "staff": false,
        "user_id": 1320,
        "hidden": false,
        "trust_level": 1,
        "deleted_at": null,
        "user_deleted": false,
        "edit_reason": null,
        "can_view_edit_history": true,
        "wiki": false,
        "post_url": "/t/multi-dc-replication-fails-during-dr-test/4156/11",
        "can_accept_answer": false,
        "can_unaccept_answer": false,
        "accepted_answer": false,
        "topic_accepted_answer": null
      },
      {
        "id": 13359,
        "name": null,
        "username": "stefanvasilic4",
        "avatar_template": "https://avatars.discourse-cdn.com/v4/letter/s/a8b319/{size}.png",
        "created_at": "2023-10-06T03:00:05.841Z",
        "cooked": "<p><a class=\"mention\" href=\"/u/johscheuer\">@johscheuer</a> the fix for my problem was adding <code>killProcesses: true</code> which allows operator to bounce fdbserver processes. The question is how safe is to employ this feature in a production system for day to day operations ? Thanks</p>",
        "post_number": 12,
        "post_type": 1,
        "posts_count": 17,
        "updated_at": "2023-10-06T03:00:05.841Z",
        "reply_count": 1,
        "reply_to_post_number": 7,
        "quote_count": 0,
        "incoming_link_count": 0,
        "reads": 23,
        "readers_count": 22,
        "score": 9.6,
        "yours": false,
        "topic_id": 4156,
        "topic_slug": "multi-dc-replication-fails-during-dr-test",
        "display_username": null,
        "primary_group_name": null,
        "flair_name": null,
        "flair_url": null,
        "flair_bg_color": null,
        "flair_color": null,
        "flair_group_id": null,
        "badges_granted": [],
        "version": 1,
        "can_edit": false,
        "can_delete": false,
        "can_recover": false,
        "can_see_hidden_post": false,
        "can_wiki": false,
        "read": true,
        "user_title": null,
        "reply_to_user": {
          "id": 849,
          "username": "johscheuer",
          "name": "Johannes Scheuermann",
          "avatar_template": "https://avatars.discourse-cdn.com/v4/letter/j/f475e1/{size}.png"
        },
        "bookmarked": false,
        "actions_summary": [],
        "moderator": false,
        "admin": false,
        "staff": false,
        "user_id": 1320,
        "hidden": false,
        "trust_level": 1,
        "deleted_at": null,
        "user_deleted": false,
        "edit_reason": null,
        "can_view_edit_history": true,
        "wiki": false,
        "post_url": "/t/multi-dc-replication-fails-during-dr-test/4156/12",
        "can_accept_answer": false,
        "can_unaccept_answer": false,
        "accepted_answer": false,
        "topic_accepted_answer": null
      },
      {
        "id": 13360,
        "name": "Johannes Scheuermann",
        "username": "johscheuer",
        "avatar_template": "https://avatars.discourse-cdn.com/v4/letter/j/f475e1/{size}.png",
        "created_at": "2023-10-06T14:43:11.081Z",
        "cooked": "<blockquote>\n<p><a class=\"mention\" href=\"/u/johscheuer\">@johscheuer</a> the fix for my problem was adding <code>killProcesses: true</code> which allows operator to bounce fdbserver processes. The question is how safe is to employ this feature in a production system for day to day operations ? Thanks</p>\n</blockquote>\n<p>That setting can be considered safe and is enabled per default. If this setting is set to false the operator is not able to perform any upgrades on the FDB cluster and is not able to rollout any new knobs.</p>",
        "post_number": 13,
        "post_type": 1,
        "posts_count": 17,
        "updated_at": "2023-10-06T14:43:11.081Z",
        "reply_count": 0,
        "reply_to_post_number": 12,
        "quote_count": 0,
        "incoming_link_count": 0,
        "reads": 23,
        "readers_count": 22,
        "score": 4.6,
        "yours": false,
        "topic_id": 4156,
        "topic_slug": "multi-dc-replication-fails-during-dr-test",
        "display_username": "Johannes Scheuermann",
        "primary_group_name": null,
        "flair_name": null,
        "flair_url": null,
        "flair_bg_color": null,
        "flair_color": null,
        "flair_group_id": null,
        "badges_granted": [],
        "version": 1,
        "can_edit": false,
        "can_delete": false,
        "can_recover": false,
        "can_see_hidden_post": false,
        "can_wiki": false,
        "read": true,
        "user_title": "",
        "reply_to_user": {
          "id": 1320,
          "username": "stefanvasilic4",
          "name": null,
          "avatar_template": "https://avatars.discourse-cdn.com/v4/letter/s/a8b319/{size}.png"
        },
        "bookmarked": false,
        "actions_summary": [],
        "moderator": false,
        "admin": false,
        "staff": false,
        "user_id": 849,
        "hidden": false,
        "trust_level": 2,
        "deleted_at": null,
        "user_deleted": false,
        "edit_reason": null,
        "can_view_edit_history": true,
        "wiki": false,
        "post_url": "/t/multi-dc-replication-fails-during-dr-test/4156/13",
        "can_accept_answer": false,
        "can_unaccept_answer": false,
        "accepted_answer": false,
        "topic_accepted_answer": null
      },
      {
        "id": 14071,
        "name": null,
        "username": "stefanvasilic4",
        "avatar_template": "https://avatars.discourse-cdn.com/v4/letter/s/a8b319/{size}.png",
        "created_at": "2024-05-21T16:15:48.920Z",
        "cooked": "<p>The issues is back ! Similar setup, when i fail dc1 and dc3 becomes primary, data distributor is stuck. DB itself is operational, but not sure how to get rid of these errors.</p>\n<pre><code class=\"lang-auto\">fdb&gt; status details\n\nWARNING: Long delay (Ctrl-C to interrupt)\n\nUsing cluster file `/var/dynamic-conf/fdb.cluster'.\n\nCould not communicate with all of the coordination servers.\n  The database will remain operational as long as we\n  can connect to a quorum of servers, however the fault\n  tolerance of the system is reduced as long as the\n  servers remain disconnected.\n\n  10.113.181.133:4500:tls  (reachable)\n  10.113.181.134:4500:tls  (reachable)\n  10.113.181.135:4500:tls  (reachable)\n  10.113.181.137:4506:tls  (unreachable)\n  10.113.181.143:4512:tls  (unreachable)\n  10.113.181.148:4508:tls  (unreachable)\n  10.113.181.162:4506:tls  (reachable)\n  10.113.181.186:4500:tls  (reachable)\n  10.113.181.189:4506:tls  (reachable)\n\nUnable to start batch priority transaction after 5 seconds.\n\n105 client(s) reported: Cluster file contents do not match current cluster connection string. Verify the cluster file and its parent directory are writable and that the cluster file has not been overwritten externally.\n  10.113.181.70:45960\n  10.113.181.73:60212\n  10.113.181.74:58594\n  10.113.181.74:58616\n  ...\n\nConfiguration:\n  Redundancy mode        - triple\n  Storage engine         - ssd-redwood-1-experimental\n  Coordinators           - 9\n  Desired Commit Proxies - 6\n  Desired GRV Proxies    - 6\n  Desired Resolvers      - 1\n  Desired Logs           - 12\n  Desired Remote Logs    - -1\n  Desired Log Routers    - -1\n  Usable Regions         - 2\n  Regions: \n    Remote -\n        Datacenter                    - dc1\n        Satellite datacenters         - dc2, dc3\n        Satellite Redundancy Mode     - one_satellite_triple\n        Satellite Logs                - 3\n    Primary -\n        Datacenter                    - dc3\n        Satellite datacenters         - dc2, dc1\n        Satellite Redundancy Mode     - one_satellite_triple\n        Satellite Logs                - 3\n\nCluster:\n  FoundationDB processes - 135\n  Zones                  - 36\n  Machines               - 36\n  Memory availability    - 5.8 GB per process on machine with least available\n  Retransmissions rate   - 753 Hz\n  Fault Tolerance        - -1 machines\n\n  Warning: the database may have data loss and availability loss. Please restart following tlog interfaces, otherwise storage servers may never be able to catch up.\n  Old log epoch: 74 begin: 38874972420 end: 38994907062, missing log interfaces(id,address): 71335d2656850118,10.113.181.140:4504:tls 7f0fa163889b3e00, c3b211c348b085c4,10.113.181.140:4508:tls 9c0d9c63a6f092b5,10.113.181.152:4504:tls d7fd29f2559b7049, adc93d4fab98c806,10.113.181.152:4508:tls 57e0f3a0e00d2d10, ed123c246aa9cb12,10.113.181.140:4500:tls 7bab49aa66bc049a,10.113.181.140:4506:tls bc0118120edcce82,10.113.181.152:4502:tls 6116d2ca14060926, 75b5a139a3fa4571,10.113.181.152:4510:tls \n  Old log epoch: 71 begin: 38759330507 end: 38874972420, missing log interfaces(id,address): 71e712ddab78ff3a, 9a5e2eaaf838e1ee, cb39710dba26c2b5,10.113.181.152:4504:tls 24a88d75574553da, a1775ea3a4e65898,10.113.181.140:4502:tls e706bb456fbb358f, 865e548b416bf57c,10.113.181.140:4500:tls 3400e4833e512637, 0a31a2b25ce98081, 4001e2d5c0182fac,10.113.181.152:4510:tls 930a36b80f4daa62, 2559e06c8e8b70d5,10.113.181.140:4510:tls \n  Old log epoch: 68 begin: 38657521349 end: 38759330507, missing log interfaces(id,address): ed301cb66419898d, ec100e44aac75fe4, 0780f861bfb5bb77,10.113.181.140:4508:tls 39a9d64b24719a0c,10.113.181.152:4508:tls f91e5b8fbbfa5480, 6abc4eaf50905f6c, 3514be4e186985fe, fbbf7813c128e9cb,10.113.181.152:4502:tls 5cf3d8f449817cec, aeff656124c157a0, 5dd3274195146095, 793b8499f0e77246,10.113.181.140:4510:tls \n  Old log epoch: 64 begin: 38547485201 end: 38657521349, missing log interfaces(id,address): a26b6fc942e654dd, 30e160a7c612cd9c, 00168df61b4310f4,10.113.181.152:4512:tls 0c79121e8fb675c3,10.113.181.152:4506:tls ae01d56975be4178, 731de2c70562f2ad, 0380336b2d93d9a4,10.113.181.140:4506:tls ca69af6fd8a24635, 455ecb2874a31da6, 219bea2df920c7e8, 29965f9b060c10bf,10.113.181.140:4510:tls 27d9c3d2a84949b6, \n  Old log epoch: 62 begin: 38437398767 end: 38547485201, missing log interfaces(id,address): cd735a2edbd0915e, 9eb2f20f30b5c10d,10.113.181.140:4504:tls 203c7fa35261f1bf, c2bdce2f6ad30cfd,10.113.181.140:4512:tls afd50f34d42b3e33, 0380dbc2f92e6054, 4d191f730b681eac, d5ff43efcd0cbacb, db0fcc67bf4d9ba3, b76187797292a3ee,10.113.181.152:4502:tls 8fc59a925b7f4324, b609db2119fb4bc2, \n  Old log epoch: 58 begin: 38319854028 end: 38437398767, missing log interfaces(id,address): 05eb1b2b107845ea, 6e780dfeb94c9568, 35c38dda8db5374a,10.113.181.140:4508:tls 47b4390d6c070bf5, bfb3f5ea346c1633, 9fffb1ea8707c974, caf3389b790921a9, c18f79c615067707,10.113.181.140:4506:tls 9d44d19e8275536c, 03ae3212a5a2d1d4,10.113.181.152:4502:tls 55e6aa8e1ddcb76d, 4cf64ddffedd039d, \n  Old log epoch: 56 begin: 38203476708 end: 38319854028, missing log interfaces(id,address): 53a6bc5f8c5c3b3b, 49b33abba501770a,10.113.181.140:4504:tls 4d81f8137f0cc950, 3291b1ed30a811bd, ce211606b7bdd22c, 441741e98ee6250f, ddaa7f74d2f461c9, bb24ff7197041205, 806e6749a64041d8, 011e267e31727dae,10.113.181.152:4510:tls 52d4acba46e95479, 02957ee5ab13e727,10.113.181.140:4510:tls \n  Old log epoch: 54 begin: 38086066158 end: 38203476708, missing log interfaces(id,address): 3a7de37e7b7f0737, c4c4ab4ca437e297,10.113.181.152:4512:tls 5bd9dfc1cfc1cb3a, 1f7a31df652dbaa1, ea9173de13454aba, 60af4818c0462dc0,10.113.181.140:4502:tls be5d1bc8756d88d6, 92e3071dc4a887d5, 9d2f36841ffc5e0b, 966346dcdd75471f, 0ee6673b39c47f9c, fb6e4dd817a1ae00, \n  Old log epoch: 52 begin: 37970818507 end: 38086066158, missing log interfaces(id,address): 5278e37d48583a0f, 8a5948fcf1e832d6,10.113.181.140:4504:tls 27ad26fe80c5f36e, b5b700ec92444f4e, 13ded6ffe4fe8181, 2cf01597eabdc204, e00111808f94a8e8, 08cc6c1fba28e915, c2978afdfe3e032d, 4d3da7fd129d2521, b015a1306d3dad07, e37ca16b22f367fd, \n  Old log epoch: 49 begin: 37853757189 end: 37970818507, missing log interfaces(id,address): bd4004c3c562946c, 3bac3402b5e52fa0, 8ba9861df9511d7e, 1a0cfa8455e6d25d, e3d7c8680103efcc, ef9434cf7bd31a27, e73b7e98abcd4110, 3e6f13fb299fc22a, 0242830cbd9cc752, 8e61b95207e9d897,10.113.181.140:4510:tls 6fe6714d14906dc6, 0a94aafd3e05a15e, \n  Old log epoch: 46 begin: 37753602931 end: 37853757189, missing log interfaces(id,address): 766bf3a4c45549a6, 83801643eaeaa682, 6ec6e0fc3832481c,10.113.181.140:4508:tls 24dbfc38339f9654, 94cd143fa262beb9, 9c69a531f4b16207, baeafd7c130855e7, 84f23b4dd1e94613, ccd1512c952c9b01, ed1753d9adf76d29, 46ce8e83291c5a96, 70227e0d4a5b0719, \n  Old log epoch: 44 begin: 37639144151 end: 37753602931, missing log interfaces(id,address): 5763961e16e81da2, 8f25b5b3272473b2, 82de555ec4269fbd,10.113.181.140:4508:tls fc5bcb92201e3fe1, 8ee1a2dccc41e13e, c26794966bc8d46f, 3d9d649144fef4ba, 09b729bf9cd8efec, f9a5baa71b8d9806, 0e29836c9e792c30, 463c4c8c7527c86c, 5f92865a6ec0f7f5, \n  Old log epoch: 42 begin: 37513640716 end: 37639144151, missing log interfaces(id,address): d65510220b4be792, b36e2490e306e6d4, e9083b342281d112, 8cf3d37a8e2d2ccb, d34a14b6c88618ca, 799e3bae96a17241, 7dbe611e2282ac53, bc824e43a51c8445, 2a1eeab3e15694dd, 16a92180a3f9117d, 953d7efe36c21fb0, 47f8aec863759814, \n  Old log epoch: 39 begin: 37399909539 end: 37513640716, missing log interfaces(id,address): c3bc61b3684a39a8, ca869aa2bf6a86d3, d0c5345c5db884fc, 99ab6955d6890575, e3b57fb3db1aa6b9, b3464b5bb7fb1963, f98ed9d852de8b36, d2e3e1f57b5c9ac3, 7b521424256e70aa, a1d52f3b534883d3, 8eb1b2f70a80b19d, 9537003560d4af05, \n  Old log epoch: 36 begin: 37282570409 end: 37399909539, missing log interfaces(id,address): a97764d71df46cdf, 0886383d2d74662e, e37cc349278ef55d, 18a11496cb987f7c, fc53489f6c06c88f, 04506b4ab793a501, c270ba1afe3db622, e200e61a40becb79, 66722cf88ef8effa, c7fe0835c8a9f18d, c3f6af36a5fb6540, 8b123d48e6dd5d54, \n  Old log epoch: 34 begin: 37168705147 end: 37282570409, missing log interfaces(id,address): f503b989587d17d3, 0fadce5d18eb3861, 142cd478ad1e8f6d, 61ece9e71989949a, 81d46d4560a5a6ef, ec011a005decd4b3, 905af2a165b0fcc4, d7ac355ff88e14ef, f5c5aa3c06edd52d, 1f9f714cb87ed50f, a1c981818d6896c5, 7e88e526b78d2813, \n  Old log epoch: 32 begin: 37049090218 end: 37168705147, missing log interfaces(id,address): 1b058ce66a9c3a20, 3743ee1675075486, 27b435d9b78dee86, ffb88be7a9b7f347, eca5816ef1b0d711, 136de7fb91eb55f1, e7d5de4e6f72fed4, 1eae9db3c7798cb9, 75d98918317600b6, 34a98307057f398c, 7ac50e0faba07ba4, 6900ef39b80c4401, \n  Old log epoch: 30 begin: 36928933015 end: 37049090218, missing log interfaces(id,address): 7a0c664d36e63e09, 0a7983f242d979c9, 8b14658f7ea1846b, 90990fe9b80a6ba3, c8b0d1c5d1061c3e, 8333e49b48a86d9a, 59e214294ae73c5b, bd382390dfdb9d11, 4406ee34dbecb0e3, 357bd9522941aadb, 2267908b9a3011d0, 82b84e8c6c569867, \n  Old log epoch: 28 begin: 36808487925 end: 36928933015, missing log interfaces(id,address): 37a67f6865d0ab92, 744ebbb5e9188080, 0f12e31ebf7d2946, ec97c0912ee481dd, 6fa0acf88b05f74e, ff7323430aa35115, 791dc5ce76d8b15c, 9d0775d6ad644c7b, 72fc511441a04379, a70671158aad8adb, d3ccbe19d0995fcf, 5f3f17a08538d0a2, \n  Old log epoch: 26 begin: 36688408186 end: 36808487925, missing log interfaces(id,address): 85558b8735300770, 262135ed05a89419, c1ae2b5f0ca07b0e, 54df9f7206b70411, 5052a642c26b3331, c58ac6c3b2a93982, df6bd8fa3396cc9f, 601bf024a19418b9, c61cc8ab5c0c38b6, 33c08a7cfb98dae0, 9150fdd4ca49235e, a1bc3b75d8443669, \n  Old log epoch: 24 begin: 36567450619 end: 36688408186, missing log interfaces(id,address): 43a41e0c7e477e28, e2f4b9546a7eb502, 9075d6b9c2bcbf95, b94c6eee865e4b3f, 3a1ac6c2910ff4f6, f5f708a957db5836, f9520838c5c8c621, 5c29d8faf70683af, cc719760f454a957, 68cd6ac40879ba82, c2698ae510b65c44, 58f1b060203d8f38, \n  Old log epoch: 22 begin: 36446461954 end: 36567450619, missing log interfaces(id,address): 0f585d18b10f93ad, 9f25ee184f987179, e754e03e9a153bcb, 9b34d536d238919a, 5a2cc2a8f1aa22d6, f9aecd3db82672ec, be9c51c0b36f2d6d, 24877de37d59b139, 6d0f19dfc29ff6d5, 4aa6b0ec8beb4a82, 41f8fbcc0717b2a4, 387cea7717c33b9d, \n  Old log epoch: 20 begin: 36331579736 end: 36446461954, missing log interfaces(id,address): b34bbe757e1eb960, 9ab29bdaf049ebaa, 08e831dca4c3c89c, dac5c5d56ec4e470, adb9142b7aa54186, d7aa2db83b88a9b8, 0f0154e07929b766, 0b6d277c18f31e64, 17fece7b35d9f561, a6b847b5084a25d6, 51a39c808bae5c79, 47918044bf6bd13d, \n  Old log epoch: 18 begin: 36211817247 end: 36331579736, missing log interfaces(id,address): d84134d0c850ab33, dbd5296490a10c40, 530c48db7fa32273, e7c9a66f8c6e75d6, 17801f8907265aab, c70f80ace49b91a9, 3c9d0acf7c44ebe5, ecd339ace265a7d4, 04c10668a6b42574, 8eafc872aeda059c, cda96e2a2e56e8b0, 8c78e5dc7a1e5f79, \n  Old log epoch: 16 begin: 36089151863 end: 36211817247, missing log interfaces(id,address): b219dba859020dfb, e301a35693f2f369, aa3a1a9713859a4a, 128e3915f60b3ecd, 24f91b9556f70761, 632019f989957983, 309d4cad6535ac4f, a6a4e923503c5b30, 4c75abdb4b9ee74e, f160414f80e52c3f, 27f4b71b2bba1f27, 229573f9bc951605, \n  Old log epoch: 14 begin: 35966709485 end: 36089151863, missing log interfaces(id,address): 1023eb6c9a5d75b9, 03fa35250f0bd1c7, 7865bb56320fc903, f1a452941f9d4e40, 5c0f3b5db35f2c58, 0f7c6a6e2a317ed6, 3fb6d2c5b91623fc, f525f31a91cb7f48, bc116c1f4f0a805a, bbb1b45bbc9550ed, 304cd8e9cbc24af5, d58ac0f37e343103, \n  Old log epoch: 12 begin: 35850783780 end: 35966709485, missing log interfaces(id,address): 72d599c0fb3633fc, 21328ec9671b1edc, b699f8aa8b1b5d1e, 2191653427b609d8, 52799373235ffcb4, 8622332cd7a2adbb, 384297d43d067b54, 85d69debe728882f, b408de57c37bf600, 45990919c3449ec5, 527f08ab48ed9095, 79e89e09f179d489, \n  Old log epoch: 10 begin: 579171909 end: 35850783780, missing log interfaces(id,address): fd16724cfb1b1508, c6345ef9b64f15df, 6eb0c16f75b402b5, 968e586fce45f37d, 94d56e879689af20, d229b5c24a764068, f04f3b83b57f137c, 0bd478a569dd5406, dcc95c4cd4c772e5, bbb61ced3513fb3a, f0e7c3fa2d9e3478, 4f641f4baa4b6b77, \n\n  Server time            - 05/21/24 15:24:44\n\nData:\n  Replication health     - (Re)initializing automatic data distribution\n  Moving data            - unknown (initializing)\n  Sum of key-value sizes - unknown\n  Disk space used        - 5.393 TB\n\nOperating space:\n  Storage server         - 1441.9 GB free on most full server\n  Log server             - 824.7 GB free on most full server\n\nWorkload:\n  Read rate              - 384707 Hz\n  Write rate             - 34087 Hz\n  Transactions started   - 3864 Hz\n  Transactions committed - 3756 Hz\n  Conflict rate          - 4 Hz\n\nBackup and DR:\n  Running backups        - 0\n  Running DRs            - 0\n</code></pre>",
        "post_number": 14,
        "post_type": 1,
        "posts_count": 17,
        "updated_at": "2024-05-21T16:15:48.920Z",
        "reply_count": 1,
        "reply_to_post_number": null,
        "quote_count": 0,
        "incoming_link_count": 2,
        "reads": 18,
        "readers_count": 17,
        "score": 18.6,
        "yours": false,
        "topic_id": 4156,
        "topic_slug": "multi-dc-replication-fails-during-dr-test",
        "display_username": null,
        "primary_group_name": null,
        "flair_name": null,
        "flair_url": null,
        "flair_bg_color": null,
        "flair_color": null,
        "flair_group_id": null,
        "badges_granted": [],
        "version": 1,
        "can_edit": false,
        "can_delete": false,
        "can_recover": false,
        "can_see_hidden_post": false,
        "can_wiki": false,
        "read": true,
        "user_title": null,
        "bookmarked": false,
        "actions_summary": [],
        "moderator": false,
        "admin": false,
        "staff": false,
        "user_id": 1320,
        "hidden": false,
        "trust_level": 1,
        "deleted_at": null,
        "user_deleted": false,
        "edit_reason": null,
        "can_view_edit_history": true,
        "wiki": false,
        "post_url": "/t/multi-dc-replication-fails-during-dr-test/4156/14",
        "can_accept_answer": false,
        "can_unaccept_answer": false,
        "accepted_answer": false,
        "topic_accepted_answer": null
      },
      {
        "id": 14074,
        "name": "Johannes Scheuermann",
        "username": "johscheuer",
        "avatar_template": "https://avatars.discourse-cdn.com/v4/letter/j/f475e1/{size}.png",
        "created_at": "2024-05-23T14:57:20.930Z",
        "cooked": "<p>I\u2019m able to reproduce this with a test cluster that uses the triplet configuration. I don\u2019t think that this is an operator issue, but maybe something misreporting. <a class=\"mention\" href=\"/u/jzhou\">@jzhou</a> do you know why this messages could come up in a triplet configuration? I used a similar configuration (I used <code>one_satellite_double</code> instead of <code>one_satellite_triple</code> and the <code>ssd-2</code> storage engine). This can be reproduced reliable with FDB version 7.1.57.</p>",
        "post_number": 15,
        "post_type": 1,
        "posts_count": 17,
        "updated_at": "2024-05-23T14:57:20.930Z",
        "reply_count": 1,
        "reply_to_post_number": 14,
        "quote_count": 0,
        "incoming_link_count": 2,
        "reads": 18,
        "readers_count": 17,
        "score": 18.6,
        "yours": false,
        "topic_id": 4156,
        "topic_slug": "multi-dc-replication-fails-during-dr-test",
        "display_username": "Johannes Scheuermann",
        "primary_group_name": null,
        "flair_name": null,
        "flair_url": null,
        "flair_bg_color": null,
        "flair_color": null,
        "flair_group_id": null,
        "badges_granted": [],
        "version": 1,
        "can_edit": false,
        "can_delete": false,
        "can_recover": false,
        "can_see_hidden_post": false,
        "can_wiki": false,
        "read": true,
        "user_title": "",
        "reply_to_user": {
          "id": 1320,
          "username": "stefanvasilic4",
          "name": null,
          "avatar_template": "https://avatars.discourse-cdn.com/v4/letter/s/a8b319/{size}.png"
        },
        "bookmarked": false,
        "actions_summary": [],
        "moderator": false,
        "admin": false,
        "staff": false,
        "user_id": 849,
        "hidden": false,
        "trust_level": 2,
        "deleted_at": null,
        "user_deleted": false,
        "edit_reason": null,
        "can_view_edit_history": true,
        "wiki": false,
        "post_url": "/t/multi-dc-replication-fails-during-dr-test/4156/15",
        "can_accept_answer": false,
        "can_unaccept_answer": false,
        "accepted_answer": false,
        "topic_accepted_answer": null
      },
      {
        "id": 14090,
        "name": "Jingyu Zhou",
        "username": "jzhou",
        "avatar_template": "/user_avatar/forums.foundationdb.org/jzhou/{size}/445_2.png",
        "created_at": "2024-05-28T23:10:58.132Z",
        "cooked": "<p>As you may be aware, we no longer use DR feature. So fixing the issue is low on our list. If this is reproducible in simulation, it might have a better chance to be fixed.</p>",
        "post_number": 16,
        "post_type": 1,
        "posts_count": 17,
        "updated_at": "2024-05-28T23:10:58.132Z",
        "reply_count": 0,
        "reply_to_post_number": 15,
        "quote_count": 0,
        "incoming_link_count": 2,
        "reads": 15,
        "readers_count": 14,
        "score": 13.0,
        "yours": false,
        "topic_id": 4156,
        "topic_slug": "multi-dc-replication-fails-during-dr-test",
        "display_username": "Jingyu Zhou",
        "primary_group_name": null,
        "flair_name": null,
        "flair_url": null,
        "flair_bg_color": null,
        "flair_color": null,
        "flair_group_id": null,
        "badges_granted": [],
        "version": 1,
        "can_edit": false,
        "can_delete": false,
        "can_recover": false,
        "can_see_hidden_post": false,
        "can_wiki": false,
        "read": true,
        "user_title": null,
        "reply_to_user": {
          "id": 849,
          "username": "johscheuer",
          "name": "Johannes Scheuermann",
          "avatar_template": "https://avatars.discourse-cdn.com/v4/letter/j/f475e1/{size}.png"
        },
        "bookmarked": false,
        "actions_summary": [],
        "moderator": true,
        "admin": true,
        "staff": true,
        "user_id": 454,
        "hidden": false,
        "trust_level": 2,
        "deleted_at": null,
        "user_deleted": false,
        "edit_reason": null,
        "can_view_edit_history": true,
        "wiki": false,
        "post_url": "/t/multi-dc-replication-fails-during-dr-test/4156/16",
        "can_accept_answer": false,
        "can_unaccept_answer": false,
        "accepted_answer": false,
        "topic_accepted_answer": null
      },
      {
        "id": 14092,
        "name": "Aravind",
        "username": "arsriram",
        "avatar_template": "/user_avatar/forums.foundationdb.org/arsriram/{size}/1837_2.png",
        "created_at": "2024-05-29T18:47:26.608Z",
        "cooked": "<p><a class=\"mention\" href=\"/u/jzhou\">@jzhou</a> - To clarify, the above issue was encountered when running the multi-region configuration with one_satellite_triple (and not the older DR configuration).</p>",
        "post_number": 17,
        "post_type": 1,
        "posts_count": 17,
        "updated_at": "2024-05-29T18:47:26.608Z",
        "reply_count": 0,
        "reply_to_post_number": null,
        "quote_count": 0,
        "incoming_link_count": 0,
        "reads": 15,
        "readers_count": 14,
        "score": 3.0,
        "yours": false,
        "topic_id": 4156,
        "topic_slug": "multi-dc-replication-fails-during-dr-test",
        "display_username": "Aravind",
        "primary_group_name": null,
        "flair_name": null,
        "flair_url": null,
        "flair_bg_color": null,
        "flair_color": null,
        "flair_group_id": null,
        "badges_granted": [],
        "version": 1,
        "can_edit": false,
        "can_delete": false,
        "can_recover": false,
        "can_see_hidden_post": false,
        "can_wiki": false,
        "read": true,
        "user_title": null,
        "bookmarked": false,
        "actions_summary": [],
        "moderator": false,
        "admin": false,
        "staff": false,
        "user_id": 1213,
        "hidden": false,
        "trust_level": 2,
        "deleted_at": null,
        "user_deleted": false,
        "edit_reason": null,
        "can_view_edit_history": true,
        "wiki": false,
        "post_url": "/t/multi-dc-replication-fails-during-dr-test/4156/17",
        "can_accept_answer": false,
        "can_unaccept_answer": false,
        "accepted_answer": false,
        "topic_accepted_answer": null
      }
    ],
    "stream": [
      13291,
      13297,
      13301,
      13302,
      13304,
      13319,
      13324,
      13329,
      13331,
      13336,
      13341,
      13359,
      13360,
      14071,
      14074,
      14090,
      14092
    ]
  },
  "timeline_lookup": [
    [
      1,
      763
    ],
    [
      3,
      762
    ],
    [
      6,
      761
    ],
    [
      7,
      758
    ],
    [
      8,
      757
    ],
    [
      10,
      756
    ],
    [
      11,
      754
    ],
    [
      12,
      747
    ],
    [
      13,
      746
    ],
    [
      14,
      518
    ],
    [
      15,
      516
    ],
    [
      16,
      511
    ],
    [
      17,
      510
    ]
  ],
  "suggested_topics": [],
  "tags": [
    "operator"
  ],
  "tags_descriptions": {},
  "fancy_title": "Multi DC replication fails during DR test",
  "id": 4156,
  "title": "Multi DC replication fails during DR test",
  "posts_count": 17,
  "created_at": "2023-09-19T21:03:38.114Z",
  "views": 608,
  "reply_count": 10,
  "like_count": 0,
  "last_posted_at": "2024-05-29T18:47:26.608Z",
  "visible": true,
  "closed": false,
  "archived": false,
  "has_summary": false,
  "archetype": "regular",
  "slug": "multi-dc-replication-fails-during-dr-test",
  "category_id": 16,
  "word_count": 11567,
  "deleted_at": null,
  "user_id": 1320,
  "featured_link": null,
  "pinned_globally": false,
  "pinned_at": null,
  "pinned_until": null,
  "image_url": null,
  "slow_mode_seconds": 0,
  "draft": null,
  "draft_key": "topic_4156",
  "draft_sequence": null,
  "unpinned": null,
  "pinned": false,
  "current_post_number": 1,
  "highest_post_number": 17,
  "deleted_by": null,
  "actions_summary": [
    {
      "id": 4,
      "count": 0,
      "hidden": false,
      "can_act": false
    },
    {
      "id": 8,
      "count": 0,
      "hidden": false,
      "can_act": false
    },
    {
      "id": 10,
      "count": 0,
      "hidden": false,
      "can_act": false
    },
    {
      "id": 7,
      "count": 0,
      "hidden": false,
      "can_act": false
    }
  ],
  "chunk_size": 20,
  "bookmarked": false,
  "topic_timer": null,
  "message_bus_last_id": 0,
  "participant_count": 4,
  "show_read_indicator": false,
  "thumbnails": null,
  "slow_mode_enabled_until": null,
  "tags_disable_ads": false,
  "related_topics": [
    {
      "fancy_title": "6.0.18 Reporting incorrect Fault Tolerance via fdbcli with triple redundancy mode?",
      "id": 1282,
      "title": "6.0.18 Reporting incorrect Fault Tolerance via fdbcli with triple redundancy mode?",
      "slug": "6-0-18-reporting-incorrect-fault-tolerance-via-fdbcli-with-triple-redundancy-mode",
      "posts_count": 15,
      "reply_count": 8,
      "highest_post_number": 16,
      "image_url": null,
      "created_at": "2019-04-04T19:04:42.341Z",
      "last_posted_at": "2019-04-06T00:41:42.940Z",
      "bumped": true,
      "bumped_at": "2019-04-06T00:41:42.940Z",
      "archetype": "regular",
      "unseen": false,
      "pinned": false,
      "unpinned": null,
      "visible": true,
      "closed": false,
      "archived": false,
      "bookmarked": null,
      "liked": null,
      "tags": [],
      "tags_descriptions": {},
      "like_count": 2,
      "views": 1976,
      "category_id": 7,
      "featured_link": null,
      "has_accepted_answer": false,
      "posters": [
        {
          "extras": null,
          "description": "Original Poster",
          "user": {
            "id": 490,
            "username": "rjenkins",
            "name": "Ray Jenkins",
            "avatar_template": "/user_avatar/forums.foundationdb.org/rjenkins/{size}/487_2.png",
            "trust_level": 2
          }
        },
        {
          "extras": null,
          "description": "Frequent Poster",
          "user": {
            "id": 12,
            "username": "ajbeamon",
            "name": "A.J. Beamon",
            "avatar_template": "/user_avatar/forums.foundationdb.org/ajbeamon/{size}/13_2.png",
            "admin": true,
            "trust_level": 4
          }
        },
        {
          "extras": null,
          "description": "Frequent Poster",
          "user": {
            "id": 13,
            "username": "alexmiller",
            "name": "Alex Miller",
            "avatar_template": "/user_avatar/forums.foundationdb.org/alexmiller/{size}/326_2.png",
            "trust_level": 4
          }
        },
        {
          "extras": null,
          "description": "Frequent Poster",
          "user": {
            "id": 81,
            "username": "ryanworl",
            "name": "Ryan Worl",
            "avatar_template": "/user_avatar/forums.foundationdb.org/ryanworl/{size}/440_2.png",
            "trust_level": 3
          }
        },
        {
          "extras": "latest",
          "description": "Most Recent Poster",
          "user": {
            "id": 54,
            "username": "Evan",
            "name": "Evan Tschannen",
            "avatar_template": "/user_avatar/forums.foundationdb.org/evan/{size}/104_2.png",
            "moderator": true,
            "trust_level": 1
          }
        }
      ]
    },
    {
      "fancy_title": "Run FoundationDB cluster on multi Kuberbetes clusters",
      "id": 3741,
      "title": "Run FoundationDB cluster on multi Kuberbetes clusters",
      "slug": "run-foundationdb-cluster-on-multi-kuberbetes-clusters",
      "posts_count": 21,
      "reply_count": 17,
      "highest_post_number": 22,
      "image_url": null,
      "created_at": "2023-01-17T15:19:19.604Z",
      "last_posted_at": "2023-02-06T09:43:57.894Z",
      "bumped": true,
      "bumped_at": "2023-02-06T09:53:51.968Z",
      "archetype": "regular",
      "unseen": false,
      "pinned": false,
      "unpinned": null,
      "visible": true,
      "closed": false,
      "archived": false,
      "bookmarked": null,
      "liked": null,
      "tags": [],
      "tags_descriptions": {},
      "like_count": 0,
      "views": 1906,
      "category_id": 16,
      "featured_link": null,
      "has_accepted_answer": false,
      "posters": [
        {
          "extras": "latest",
          "description": "Original Poster, Most Recent Poster",
          "user": {
            "id": 970,
            "username": "mason",
            "name": "mason",
            "avatar_template": "/user_avatar/forums.foundationdb.org/mason/{size}/1145_2.png",
            "trust_level": 2
          }
        },
        {
          "extras": null,
          "description": "Frequent Poster",
          "user": {
            "id": 337,
            "username": "mengxu",
            "name": "Meng Xu",
            "avatar_template": "/user_avatar/forums.foundationdb.org/mengxu/{size}/893_2.png",
            "trust_level": 2
          }
        },
        {
          "extras": null,
          "description": "Frequent Poster",
          "user": {
            "id": 849,
            "username": "johscheuer",
            "name": "Johannes Scheuermann",
            "avatar_template": "https://avatars.discourse-cdn.com/v4/letter/j/f475e1/{size}.png",
            "trust_level": 2
          }
        }
      ]
    },
    {
      "fancy_title": "When configure three_datacenter_fallback,the cluster Replication health remains in (Re)initializing automatic data distribution",
      "id": 3943,
      "title": "When configure three_datacenter_fallback,the cluster Replication health remains in (Re)initializing automatic data distribution",
      "slug": "when-configure-three-datacenter-fallback-the-cluster-replication-health-remains-in-re-initializing-automatic-data-distribution",
      "posts_count": 1,
      "reply_count": 0,
      "highest_post_number": 1,
      "image_url": null,
      "created_at": "2023-05-05T09:19:34.357Z",
      "last_posted_at": "2023-05-05T09:19:34.453Z",
      "bumped": true,
      "bumped_at": "2023-05-05T09:53:12.338Z",
      "archetype": "regular",
      "unseen": false,
      "pinned": false,
      "unpinned": null,
      "visible": true,
      "closed": false,
      "archived": false,
      "bookmarked": null,
      "liked": null,
      "tags": [
        "operator"
      ],
      "tags_descriptions": {},
      "like_count": 0,
      "views": 348,
      "category_id": 7,
      "featured_link": null,
      "has_accepted_answer": false,
      "posters": [
        {
          "extras": "latest single",
          "description": "Original Poster, Most Recent Poster",
          "user": {
            "id": 1175,
            "username": "libo-sober",
            "name": "BoLee",
            "avatar_template": "/user_avatar/forums.foundationdb.org/libo-sober/{size}/1447_2.png",
            "trust_level": 1
          }
        }
      ]
    },
    {
      "fancy_title": "Fdb cluster is unavailable after delete a disk",
      "id": 2232,
      "title": "Fdb cluster is unavailable after delete a disk",
      "slug": "fdb-cluster-is-unavailable-after-delete-a-disk",
      "posts_count": 4,
      "reply_count": 1,
      "highest_post_number": 4,
      "image_url": null,
      "created_at": "2020-07-07T09:35:29.720Z",
      "last_posted_at": "2020-07-09T08:38:11.028Z",
      "bumped": true,
      "bumped_at": "2020-07-09T09:28:06.173Z",
      "archetype": "regular",
      "unseen": false,
      "pinned": false,
      "unpinned": null,
      "visible": true,
      "closed": false,
      "archived": false,
      "bookmarked": null,
      "liked": null,
      "tags": [],
      "tags_descriptions": {},
      "like_count": 0,
      "views": 1154,
      "category_id": 7,
      "featured_link": null,
      "has_accepted_answer": false,
      "posters": [
        {
          "extras": "latest",
          "description": "Original Poster, Most Recent Poster",
          "user": {
            "id": 585,
            "username": "ssb",
            "name": "Shunbo Shi",
            "avatar_template": "/user_avatar/forums.foundationdb.org/ssb/{size}/656_2.png",
            "trust_level": 1
          }
        },
        {
          "extras": null,
          "description": "Frequent Poster",
          "user": {
            "id": 166,
            "username": "gaurav",
            "name": "gaurav",
            "avatar_template": "https://avatars.discourse-cdn.com/v4/letter/g/b487fb/{size}.png",
            "trust_level": 3
          }
        }
      ]
    },
    {
      "fancy_title": "Failure / Recovery scenario",
      "id": 2384,
      "title": "Failure / Recovery scenario",
      "slug": "failure-recovery-scenario",
      "posts_count": 2,
      "reply_count": 0,
      "highest_post_number": 2,
      "image_url": null,
      "created_at": "2020-10-10T01:06:26.706Z",
      "last_posted_at": "2020-10-12T13:36:11.016Z",
      "bumped": true,
      "bumped_at": "2020-10-12T13:36:11.016Z",
      "archetype": "regular",
      "unseen": false,
      "pinned": false,
      "unpinned": null,
      "visible": true,
      "closed": false,
      "archived": false,
      "bookmarked": null,
      "liked": null,
      "tags": [],
      "tags_descriptions": {},
      "like_count": 0,
      "views": 695,
      "category_id": 16,
      "featured_link": null,
      "has_accepted_answer": false,
      "posters": [
        {
          "extras": null,
          "description": "Original Poster",
          "user": {
            "id": 819,
            "username": "mbuleandra",
            "name": "Marius",
            "avatar_template": "/user_avatar/forums.foundationdb.org/mbuleandra/{size}/977_2.png",
            "trust_level": 1
          }
        },
        {
          "extras": "latest",
          "description": "Most Recent Poster",
          "user": {
            "id": 3,
            "username": "john_brownlee",
            "name": "John Brownlee",
            "avatar_template": "/user_avatar/forums.foundationdb.org/john_brownlee/{size}/22_2.png",
            "admin": true,
            "trust_level": 4
          }
        }
      ]
    }
  ],
  "summarizable": false,
  "can_vote": false,
  "vote_count": 0,
  "user_voted": false,
  "discourse_zendesk_plugin_zendesk_id": null,
  "discourse_zendesk_plugin_zendesk_url": "https://your-url.zendesk.com/agent/tickets/",
  "details": {
    "can_edit": false,
    "notification_level": 1,
    "participants": [
      {
        "id": 1320,
        "username": "stefanvasilic4",
        "name": null,
        "avatar_template": "https://avatars.discourse-cdn.com/v4/letter/s/a8b319/{size}.png",
        "post_count": 9,
        "primary_group_name": null,
        "flair_name": null,
        "flair_url": null,
        "flair_color": null,
        "flair_bg_color": null,
        "flair_group_id": null,
        "trust_level": 1
      },
      {
        "id": 849,
        "username": "johscheuer",
        "name": "Johannes Scheuermann",
        "avatar_template": "https://avatars.discourse-cdn.com/v4/letter/j/f475e1/{size}.png",
        "post_count": 6,
        "primary_group_name": null,
        "flair_name": null,
        "flair_url": null,
        "flair_color": null,
        "flair_bg_color": null,
        "flair_group_id": null,
        "trust_level": 2
      },
      {
        "id": 1213,
        "username": "arsriram",
        "name": "Aravind",
        "avatar_template": "/user_avatar/forums.foundationdb.org/arsriram/{size}/1837_2.png",
        "post_count": 1,
        "primary_group_name": null,
        "flair_name": null,
        "flair_url": null,
        "flair_color": null,
        "flair_bg_color": null,
        "flair_group_id": null,
        "trust_level": 2
      },
      {
        "id": 454,
        "username": "jzhou",
        "name": "Jingyu Zhou",
        "avatar_template": "/user_avatar/forums.foundationdb.org/jzhou/{size}/445_2.png",
        "post_count": 1,
        "primary_group_name": null,
        "flair_name": null,
        "flair_url": null,
        "flair_color": null,
        "flair_bg_color": null,
        "flair_group_id": null,
        "admin": true,
        "moderator": true,
        "trust_level": 2
      }
    ],
    "created_by": {
      "id": 1320,
      "username": "stefanvasilic4",
      "name": null,
      "avatar_template": "https://avatars.discourse-cdn.com/v4/letter/s/a8b319/{size}.png"
    },
    "last_poster": {
      "id": 1213,
      "username": "arsriram",
      "name": "Aravind",
      "avatar_template": "/user_avatar/forums.foundationdb.org/arsriram/{size}/1837_2.png"
    },
    "links": [
      {
        "url": "https://github.com/FoundationDB/fdb-kubernetes-operator/tree/main/config/tests/multi_dc",
        "title": null,
        "internal": false,
        "attachment": false,
        "reflection": false,
        "clicks": 3,
        "user_id": 1320,
        "domain": "github.com",
        "root_domain": "github.com"
      }
    ]
  },
  "bookmarks": []
}