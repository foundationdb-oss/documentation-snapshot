{
  "post_stream": {
    "posts": [
      {
        "id": 1365,
        "name": "Viacheslav Biriukov",
        "username": "brk0v",
        "avatar_template": "/user_avatar/forums.foundationdb.org/brk0v/{size}/173_2.png",
        "created_at": "2018-05-31T15:34:28.287Z",
        "cooked": "<p>Version 5.1.7 custom build with TSL plugin commit:</p>\n<pre><code class=\"lang-auto\">commit 9ad8d02386d4a6a5efecf898df80f2747695c627 (HEAD, tag: 5.1.7)\n</code></pre>\n<p><strong>Configuration</strong></p>\n<ul>\n<li>3 node cluster with double ssd configuration.</li>\n</ul>\n<pre><code class=\"lang-auto\">/usr/sbin/fdbserver --cluster_file /etc/foundationdb/fdb.cluster --datadir /var/lib/foundationdb/data/4500 --listen_address public --logdir /var/log/foundationdb --public_address auto:4500 --tls_certificate_file /etc/foundationdb/fdb.pem --tls_key_file /etc/foundationdb/fdb-key.pem --tls_plugin /usr/lib/foundationdb/plugins/libFDBLibTLS.so\n</code></pre>\n<p><strong>Application</strong></p>\n<ul>\n<li>Golang application.</li>\n</ul>\n<p><strong>Cluster</strong></p>\n<p>Worked for about 10h under almost write load (30% CPU and 4GB memory). And suddenly failed with OOM errors in the logs (but there is a lot free memory). Started restarting infinitely without success:</p>\n<pre><code class=\"lang-auto\">...\n&lt;Event Severity=\"10\" Time=\"1527763249.658725\" Type=\"GenerationRegReadRequest\" Machine=\"192.168.1.1:4500\" ID=\"0000000000000000\" From=\"192.168.1.2:4500:tls\" K=\"fdb_test_cluster:6KSAuefFw2PtTjwhomsLUdG4wQPeV123\" logGroup=\"default\"/&gt;\n...\n&lt;Event Severity=\"40\" Time=\"1527763249.937558\" Type=\"OutOfMemory\" Machine=\"192.168.1.1:4500\" ID=\"0000000000000000\" Message=\"Out of memory\" logGroup=\"default\" Backtrace=\"addr2line -e fdbserver.debug -p -C -f -i 0x136d55c 0x136c54a 0x1357019 0x135705c 0x13570d9 0x13239f5 0x13243b1 0x130a555 0x1307ee7 0x85ba6a 0x928187 0x9282db 0x930a52 0x629807 0x62b01f 0x6307e7 0x53fa52 0x53cf39 0x12b43f6 0x7fca32bbd000\"/&gt;\n</code></pre>\n<p><strong>Strerr out</strong></p>\n<pre><code class=\"lang-auto\">FDBD joined cluster.\nERROR: Out of memory\n</code></pre>\n<p><strong>Stack traces</strong></p>\n<ol>\n<li>\n</li>\n</ol>\n<pre><code class=\"lang-auto\">$ addr2line -e fdbserver.debug -p -C -f -i 0x136d55c 0x136c54a 0x1357019 0x135705c 0x13570d9 0x13239f5 0x13243b1 0x130a555 0x1307ee7 0x85ba6a 0x928187 0x9282db 0\nx928410 0x92b4e6 0x92b576 0x9312e3 0x6288dc 0x62afed 0x6307e7 0x53fa52 0x53cf39 0x12b43f6 0x7fbd26b27000\n</code></pre>\n<pre><code class=\"lang-auto\">operator+&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; at /usr/include/c++/4.9/bits/basic_string.h:2424\n (inlined by) TraceEvent::backtrace(std::string) at /tmp/foundationdb/tmp/build/foundationdb/flow/Trace.cpp:871\nstd::string::_M_rep() const at /usr/include/c++/4.9/bits/basic_string.h:301\n (inlined by) ~basic_string at /usr/include/c++/4.9/bits/basic_string.h:547\n (inlined by) TraceEvent::~TraceEvent() at /tmp/foundationdb/tmp/build/foundationdb/flow/Trace.cpp:905\ncriticalError at /tmp/foundationdb/tmp/build/foundationdb/flow/Platform.cpp:2310\nplatform::outOfMemory() at /tmp/foundationdb/tmp/build/foundationdb/flow/Platform.cpp:2295\nallocate(unsigned long, bool) at /tmp/foundationdb/tmp/build/foundationdb/flow/Platform.cpp:1511\nFastAllocator&lt;4096&gt;::getMagazine() at /tmp/foundationdb/tmp/build/foundationdb/flow/FastAlloc.cpp:366\nFastAllocator&lt;4096&gt;::allocate() at /tmp/foundationdb/tmp/build/foundationdb/flow/FastAlloc.cpp:221\nEvictablePageCache::allocate(EvictablePage*) at /tmp/foundationdb/tmp/build/foundationdb/fdbrpc/AsyncFileCached.actor.h:72\n (inlined by) AFCPage::AFCPage(AsyncFileCached*, long) at /tmp/foundationdb/tmp/build/foundationdb/fdbrpc/AsyncFileCached.actor.h:448\ninsert&lt;std::pair&lt;long int, AFCPage*&gt;, void&gt; at /usr/include/c++/4.9/bits/hashtable_policy.h:911 (discriminator 3)\n (inlined by) insert&lt;std::pair&lt;long int, AFCPage*&gt;, void&gt; at /usr/include/c++/4.9/bits/unordered_map.h:400 (discriminator 3)\n (inlined by) AsyncFileCached::readZeroCopy(void**, int*, long) at /tmp/foundationdb/tmp/build/foundationdb/fdbrpc/AsyncFileCached.actor.cpp:153 (discriminator 3)\nasyncReadZeroCopy at /tmp/foundationdb/tmp/build/foundationdb/fdbserver/VFSAsync.cpp:137\nreadDbPage at /tmp/foundationdb/tmp/build/foundationdb/fdbserver/sqlite/sqlite3.amalgamation.c:31950\nsqlite3PagerAcquire at /tmp/foundationdb/tmp/build/foundationdb/fdbserver/sqlite/sqlite3.amalgamation.c:34179\nbtreeGetPage at /tmp/foundationdb/tmp/build/foundationdb/fdbserver/sqlite/btree.c:1567\ngetAndInitPage at /tmp/foundationdb/tmp/build/foundationdb/fdbserver/sqlite/btree.c:1620\nmoveToChild at /tmp/foundationdb/tmp/build/foundationdb/fdbserver/sqlite/btree.c:4188\nsqlite3BtreeMovetoUnpacked at /tmp/foundationdb/tmp/build/foundationdb/fdbserver/sqlite/btree.c:4709\nRawCursor::moveTo(StringRef, bool) at /tmp/foundationdb/tmp/build/foundationdb/fdbserver/KeyValueStoreSQLite.actor.cpp:1168\nRawCursor::getRange(KeyRangeRef, int, int) at /tmp/foundationdb/tmp/build/foundationdb/fdbserver/KeyValueStoreSQLite.actor.cpp:1089\nKeyValueStoreSQLite::Reader::action(KeyValueStoreSQLite::Reader::ReadRangeAction&amp;) at /tmp/foundationdb/tmp/build/foundationdb/fdbserver/KeyValueStoreSQLite.actor.cpp:1546\n (inlined by) TypedAction&lt;KeyValueStoreSQLite::Reader, KeyValueStoreSQLite::Reader::ReadRangeAction&gt;::operator()(IThreadPoolReceiver*) at /tmp/foundationdb/tmp/build/foundationdb/./flow/IThreadPool.h:74\nyield at /tmp/foundationdb/tmp/build/foundationdb/./flow/flow.h:948\n (inlined by) WorkPool&lt;Coroutine, ThreadUnsafeSpinLock, true&gt;::Worker::run() at /tmp/foundationdb/tmp/build/foundationdb/fdbserver/CoroFlow.actor.cpp:150\nCoroutine::entry(void*) at /tmp/foundationdb/tmp/build/foundationdb/fdbserver/CoroFlow.actor.cpp:107\nCoro_StartWithArg at /tmp/foundationdb/tmp/build/foundationdb/fdbrpc/libcoroutine/Coro.c:288\n?? ??:0\n</code></pre>\n<ol start=\"2\">\n<li>\n</li>\n</ol>\n<pre><code class=\"lang-auto\">addr2line -e fdbserver.debug -p -C -f -i 0x136d55c 0x136c54a 0x1357019 0x135705c 0x13570d9 0x1320f25 0x13218b1 0x4715a5 0x4777ba 0x136d233 0x136d58b 0x136c54a 0x1357019 0x135705c 0x13570d9 0x1320f25 0x13218b1 0x4715a5 0x4777ba 0x136d233 0x136d58b 0x136c54a 0x1357019 0x135705c 0x13570d9 0x1320f25 0x13218b1 0x4715a5 0x4777ba 0x136d233 0x136d58b 0x136c54a 0x1357019 0x135705c 0x13570d9 0x1320f25 0x13218b1 0x4715a5 0x5b3750 0x123f162 0x81859d 0x81a305 0x47a9e8 0xa2b925 0xa2ba62 0xa28558 0xa27c18\n</code></pre>\n<pre><code class=\"lang-auto\">operator+&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; at /usr/include/c++/4.9/bits/basic_string.h:2424\n (inlined by) TraceEvent::backtrace(std::string) at /tmp/foundationdb/tmp/build/foundationdb/flow/Trace.cpp:871\nstd::string::_M_rep() const at /usr/include/c++/4.9/bits/basic_string.h:301\n (inlined by) ~basic_string at /usr/include/c++/4.9/bits/basic_string.h:547\n (inlined by) TraceEvent::~TraceEvent() at /tmp/foundationdb/tmp/build/foundationdb/flow/Trace.cpp:905\ncriticalError at /tmp/foundationdb/tmp/build/foundationdb/flow/Platform.cpp:2310\nplatform::outOfMemory() at /tmp/foundationdb/tmp/build/foundationdb/flow/Platform.cpp:2295\nallocate(unsigned long, bool) at /tmp/foundationdb/tmp/build/foundationdb/flow/Platform.cpp:1511\nFastAllocator&lt;512&gt;::getMagazine() at /tmp/foundationdb/tmp/build/foundationdb/flow/FastAlloc.cpp:366\nFastAllocator&lt;512&gt;::allocate() at /tmp/foundationdb/tmp/build/foundationdb/flow/FastAlloc.cpp:221\nArenaBlock::create(int, Reference&lt;ArenaBlock&gt;&amp;) at /tmp/foundationdb/tmp/build/foundationdb/./flow/Arena.h:227 (discriminator 1)\nArena at /tmp/foundationdb/tmp/build/foundationdb/./flow/Arena.h:288\n (inlined by) Standalone&lt;StringRef&gt;::Standalone(StringRef const&amp;) at /tmp/foundationdb/tmp/build/foundationdb/./flow/Arena.h:339\nTraceEvent::detail(char const*, char const*) at /tmp/foundationdb/tmp/build/foundationdb/flow/Trace.cpp:721\nstd::string::_M_rep() const at /usr/include/c++/4.9/bits/basic_string.h:301\n (inlined by) ~basic_string at /usr/include/c++/4.9/bits/basic_string.h:547\n (inlined by) TraceEvent::backtrace(std::string) at /tmp/foundationdb/tmp/build/foundationdb/flow/Trace.cpp:871\nstd::string::_M_rep() const at /usr/include/c++/4.9/bits/basic_string.h:301\n (inlined by) ~basic_string at /usr/include/c++/4.9/bits/basic_string.h:547\n (inlined by) TraceEvent::~TraceEvent() at /tmp/foundationdb/tmp/build/foundationdb/flow/Trace.cpp:905\ncriticalError at /tmp/foundationdb/tmp/build/foundationdb/flow/Platform.cpp:2310\nplatform::outOfMemory() at /tmp/foundationdb/tmp/build/foundationdb/flow/Platform.cpp:2295\nallocate(unsigned long, bool) at /tmp/foundationdb/tmp/build/foundationdb/flow/Platform.cpp:1511\nFastAllocator&lt;512&gt;::getMagazine() at /tmp/foundationdb/tmp/build/foundationdb/flow/FastAlloc.cpp:366\nFastAllocator&lt;512&gt;::allocate() at /tmp/foundationdb/tmp/build/foundationdb/flow/FastAlloc.cpp:221\nArenaBlock::create(int, Reference&lt;ArenaBlock&gt;&amp;) at /tmp/foundationdb/tmp/build/foundationdb/./flow/Arena.h:227 (discriminator 1)\nArena at /tmp/foundationdb/tmp/build/foundationdb/./flow/Arena.h:288\n (inlined by) Standalone&lt;StringRef&gt;::Standalone(StringRef const&amp;) at /tmp/foundationdb/tmp/build/foundationdb/./flow/Arena.h:339\nTraceEvent::detail(char const*, char const*) at /tmp/foundationdb/tmp/build/foundationdb/flow/Trace.cpp:721\nstd::string::_M_rep() const at /usr/include/c++/4.9/bits/basic_string.h:301\n (inlined by) ~basic_string at /usr/include/c++/4.9/bits/basic_string.h:547\n (inlined by) TraceEvent::backtrace(std::string) at /tmp/foundationdb/tmp/build/foundationdb/flow/Trace.cpp:871\nstd::string::_M_rep() const at /usr/include/c++/4.9/bits/basic_string.h:301\n (inlined by) ~basic_string at /usr/include/c++/4.9/bits/basic_string.h:547\n (inlined by) TraceEvent::~TraceEvent() at /tmp/foundationdb/tmp/build/foundationdb/flow/Trace.cpp:905\ncriticalError at /tmp/foundationdb/tmp/build/foundationdb/flow/Platform.cpp:2310\nplatform::outOfMemory() at /tmp/foundationdb/tmp/build/foundationdb/flow/Platform.cpp:2295\nallocate(unsigned long, bool) at /tmp/foundationdb/tmp/build/foundationdb/flow/Platform.cpp:1511\nFastAllocator&lt;512&gt;::getMagazine() at /tmp/foundationdb/tmp/build/foundationdb/flow/FastAlloc.cpp:366\nFastAllocator&lt;512&gt;::allocate() at /tmp/foundationdb/tmp/build/foundationdb/flow/FastAlloc.cpp:221\nArenaBlock::create(int, Reference&lt;ArenaBlock&gt;&amp;) at /tmp/foundationdb/tmp/build/foundationdb/./flow/Arena.h:227 (discriminator 1)\nArena at /tmp/foundationdb/tmp/build/foundationdb/./flow/Arena.h:288\n (inlined by) Standalone&lt;StringRef&gt;::Standalone(StringRef const&amp;) at /tmp/foundationdb/tmp/build/foundationdb/./flow/Arena.h:339\nTraceEvent::detail(char const*, char const*) at /tmp/foundationdb/tmp/build/foundationdb/flow/Trace.cpp:721\nstd::string::_M_rep() const at /usr/include/c++/4.9/bits/basic_string.h:301\n (inlined by) ~basic_string at /usr/include/c++/4.9/bits/basic_string.h:547\n (inlined by) TraceEvent::backtrace(std::string) at /tmp/foundationdb/tmp/build/foundationdb/flow/Trace.cpp:871\nstd::string::_M_rep() const at /usr/include/c++/4.9/bits/basic_string.h:301\n (inlined by) ~basic_string at /usr/include/c++/4.9/bits/basic_string.h:547\n (inlined by) TraceEvent::~TraceEvent() at /tmp/foundationdb/tmp/build/foundationdb/flow/Trace.cpp:905\ncriticalError at /tmp/foundationdb/tmp/build/foundationdb/flow/Platform.cpp:2310\nplatform::outOfMemory() at /tmp/foundationdb/tmp/build/foundationdb/flow/Platform.cpp:2295\nallocate(unsigned long, bool) at /tmp/foundationdb/tmp/build/foundationdb/flow/Platform.cpp:1511\nFastAllocator&lt;512&gt;::getMagazine() at /tmp/foundationdb/tmp/build/foundationdb/flow/FastAlloc.cpp:366\nFastAllocator&lt;512&gt;::allocate() at /tmp/foundationdb/tmp/build/foundationdb/flow/FastAlloc.cpp:221\nArenaBlock::create(int, Reference&lt;ArenaBlock&gt;&amp;) at /tmp/foundationdb/tmp/build/foundationdb/./flow/Arena.h:227 (discriminator 1)\nArena::Arena(unsigned long) at /tmp/foundationdb/tmp/build/foundationdb/./flow/Arena.h:289\noperator new [] at /tmp/foundationdb/tmp/build/foundationdb/./flow/Arena.h:312\n (inlined by) StringRef at /tmp/foundationdb/tmp/build/foundationdb/./flow/Arena.h:397\n (inlined by) Standalone at /tmp/foundationdb/tmp/build/foundationdb/./flow/Arena.h:339\n (inlined by) sendPacket at /tmp/foundationdb/tmp/build/foundationdb/fdbrpc/FlowTransport.actor.cpp:829\ngetReply&lt;TLogRejoinRequest&gt; at /tmp/foundationdb/tmp/build/foundationdb/./fdbrpc/fdbrpc.h:237\n (inlined by) a_body1loopBody1cont1 at /tmp/foundationdb/tmp/build/foundationdb/fdbserver/TLogServer.actor.cpp:1126\n (inlined by) a_body1loopBody1 at /tmp/foundationdb/tmp/build/foundationdb/fdbserver/TLogServer.actor.g.cpp:5850\na_body1loopHead1 at /tmp/foundationdb/tmp/build/foundationdb/fdbserver/TLogServer.actor.g.cpp:5805\n (inlined by) a_body1loopBody1cont6 at /tmp/foundationdb/tmp/build/foundationdb/fdbserver/TLogServer.actor.g.cpp:5975\n (inlined by) a_body1loopBody1cont7 at /tmp/foundationdb/tmp/build/foundationdb/fdbserver/TLogServer.actor.g.cpp:5981\n (inlined by) a_body1loopBody1cont8 at /tmp/foundationdb/tmp/build/foundationdb/fdbserver/TLogServer.actor.g.cpp:5987\n (inlined by) a_body1loopBody1cont1when2 at /tmp/foundationdb/tmp/build/foundationdb/fdbserver/TLogServer.actor.g.cpp:6007\n (inlined by) a_callback_fire at /tmp/foundationdb/tmp/build/foundationdb/fdbserver/TLogServer.actor.g.cpp:6048\n (inlined by) fire at /tmp/foundationdb/tmp/build/foundationdb/./flow/flow.h:928\nvoid SAV&lt;Void&gt;::send&lt;Void&gt;(Void&amp;&amp;) at /tmp/foundationdb/tmp/build/foundationdb/./flow/flow.h:381\n~Promise at /tmp/foundationdb/tmp/build/foundationdb/./flow/flow.h:720\n (inlined by) AsyncVar&lt;ServerDBInfo&gt;::setUnconditional(ServerDBInfo const&amp;) at /tmp/foundationdb/tmp/build/foundationdb/flow/genericactors.actor.h:657\n (inlined by) AsyncVar&lt;ServerDBInfo&gt;::set(ServerDBInfo const&amp;) at /tmp/foundationdb/tmp/build/foundationdb/flow/genericactors.actor.h:651\n (inlined by) a_body1loopBody1when1 at /tmp/foundationdb/tmp/build/foundationdb/fdbserver/worker.actor.cpp:471\nfire at /tmp/foundationdb/tmp/build/foundationdb/./flow/flow.h:928 (discriminator 2)\nSAV&lt;ServerDBInfo&gt;::finishSendAndDelPromiseRef() at /tmp/foundationdb/tmp/build/foundationdb/./flow/flow.h:413\n (inlined by) a_body1cont2 at /tmp/foundationdb/tmp/build/foundationdb/flow/genericactors.actor.g.h:10023\n (inlined by) a_body1when1 at /tmp/foundationdb/tmp/build/foundationdb/flow/genericactors.actor.g.h:10030\n (inlined by) a_callback_fire at /tmp/foundationdb/tmp/build/foundationdb/flow/genericactors.actor.g.h:10044\n (inlined by) fire at /tmp/foundationdb/tmp/build/foundationdb/./flow/flow.h:928\nSAV&lt;ServerDBInfo&gt;::finishSendAndDelPromiseRef() at /tmp/foundationdb/tmp/build/foundationdb/./flow/flow.h:413\n (inlined by) a_body1cont2 at /tmp/foundationdb/tmp/build/foundationdb/fdbrpc/genericactors.actor.g.h:864\n (inlined by) a_body1when1 at /tmp/foundationdb/tmp/build/foundationdb/fdbrpc/genericactors.actor.g.h:871\n (inlined by) a_callback_fire at /tmp/foundationdb/tmp/build/foundationdb/fdbrpc/genericactors.actor.g.h:885\n (inlined by) fire at /tmp/foundationdb/tmp/build/foundationdb/./flow/flow.h:928\n</code></pre>",
        "post_number": 1,
        "post_type": 1,
        "posts_count": 17,
        "updated_at": "2018-05-31T15:36:54.066Z",
        "reply_count": 0,
        "reply_to_post_number": null,
        "quote_count": 0,
        "incoming_link_count": 577,
        "reads": 104,
        "readers_count": 103,
        "score": 2952.8,
        "yours": false,
        "topic_id": 483,
        "topic_slug": "segmentation-fault-error-and-broken-cluster",
        "display_username": "Viacheslav Biriukov",
        "primary_group_name": null,
        "flair_name": null,
        "flair_url": null,
        "flair_bg_color": null,
        "flair_color": null,
        "flair_group_id": null,
        "badges_granted": [],
        "version": 1,
        "can_edit": false,
        "can_delete": false,
        "can_recover": false,
        "can_see_hidden_post": false,
        "can_wiki": false,
        "read": true,
        "user_title": null,
        "bookmarked": false,
        "actions_summary": [
          {
            "id": 2,
            "count": 1
          }
        ],
        "moderator": false,
        "admin": false,
        "staff": false,
        "user_id": 211,
        "hidden": false,
        "trust_level": 1,
        "deleted_at": null,
        "user_deleted": false,
        "edit_reason": null,
        "can_view_edit_history": true,
        "wiki": false,
        "post_url": "/t/segmentation-fault-error-and-broken-cluster/483/1",
        "can_accept_answer": false,
        "can_unaccept_answer": false,
        "accepted_answer": false,
        "topic_accepted_answer": null,
        "can_vote": false
      },
      {
        "id": 1368,
        "name": "Viacheslav Biriukov",
        "username": "brk0v",
        "avatar_template": "/user_avatar/forums.foundationdb.org/brk0v/{size}/173_2.png",
        "created_at": "2018-06-01T12:48:05.536Z",
        "cooked": "<p>I\u2019ve got the same with version 5.2.2:</p>\n<pre><code class=\"lang-auto\">commit b6b6b882af2f8ed3f921b52deb72afa58b4f2ce6 (HEAD, tag: 5.2.2)\n</code></pre>\n<p>Maybe I\u2019m doing something wrong in my application code, but it definitely should not lead to totally broken clusters and segmentation faults.</p>\n<p>Trace:</p>\n<pre><code class=\"lang-auto\">addr2line -e fdbserver.debug -p -C -f -i 0x13c7f0c 0x13c6e9a 0x13b1629 0x13b166c 0x13b16e9 0x137e005 0x137e9c1 0x13ac33f 0x13ac41b 0x4e9ad1 0x4f6ee1 0x4fbe5f 0x4fc286 0x1298014 0x45c136 0x43c478 0x43c738 0x43c9f5 0x47b398 0x49edd5 0x443021 0x44c00e 0x4e3289 0x12988d0 0x1298b58 0x47b398 0x1399e13 0x42a627 0x7efd131872e1\n</code></pre>\n<pre><code class=\"lang-auto\">TraceEvent::backtrace(std::string) at /usr/include/c++/4.9/bits/basic_string.h:2424\n (inlined by) TraceEvent::backtrace(std::string) at /tmp/foundationdb/tmp/build/foundationdb/flow/Trace.cpp:874\nTraceEvent::~TraceEvent() at /usr/include/c++/4.9/bits/basic_string.h:301\n (inlined by) ?? at /usr/include/c++/4.9/bits/basic_string.h:547\n (inlined by) TraceEvent::~TraceEvent() at /tmp/foundationdb/tmp/build/foundationdb/flow/Trace.cpp:908\ncriticalError at /tmp/foundationdb/tmp/build/foundationdb/flow/Platform.cpp:2310\nplatform::outOfMemory() at /tmp/foundationdb/tmp/build/foundationdb/flow/Platform.cpp:2295\nallocate(unsigned long, bool) at /tmp/foundationdb/tmp/build/foundationdb/flow/Platform.cpp:1511\nFastAllocator&lt;4096&gt;::getMagazine() at /tmp/foundationdb/tmp/build/foundationdb/flow/FastAlloc.cpp:366\nFastAllocator&lt;4096&gt;::allocate() at /tmp/foundationdb/tmp/build/foundationdb/flow/FastAlloc.cpp:221\nPacketWriter::nextBuffer() at /tmp/foundationdb/tmp/build/foundationdb/flow/serialize.h:565\n (inlined by) PacketWriter::nextBuffer() at /tmp/foundationdb/tmp/build/foundationdb/flow/Net2Packet.cpp:59\nPacketWriter::serializeBytesAcrossBoundary(void const*, int) at /tmp/foundationdb/tmp/build/foundationdb/flow/Net2Packet.cpp:45\nvoid save&lt;PacketWriter, ReplyPromise&lt;Void&gt; &gt;(PacketWriter&amp;, RequestStream&lt;ReplyPromise&lt;Void&gt; &gt; const&amp;) at /tmp/foundationdb/tmp/build/foundationdb/./flow/network.h:95\n (inlined by) void save&lt;PacketWriter, ReplyPromise&lt;Void&gt; &gt;(PacketWriter&amp;, RequestStream&lt;ReplyPromise&lt;Void&gt; &gt; const&amp;) at /tmp/foundationdb/tmp/build/foundationdb/./fdbrpc/fdbrpc.h:355\noperator&amp;&lt;PacketWriter, RequestStream&lt;ReplyPromise&lt;Void&gt; &gt; &gt; at /tmp/foundationdb/tmp/build/foundationdb/./flow/serialize.h:66\n (inlined by) ?? at /tmp/foundationdb/tmp/build/foundationdb/fdbserver/TLogInterface.h:65\n (inlined by) ?? at /tmp/foundationdb/tmp/build/foundationdb/./flow/serialize.h:80\n (inlined by) save&lt;PacketWriter, TLogInterface&gt; at /tmp/foundationdb/tmp/build/foundationdb/./flow/serialize.h:87\n (inlined by) operator&amp;&lt;PacketWriter, TLogInterface&gt; at /tmp/foundationdb/tmp/build/foundationdb/./flow/serialize.h:66\n (inlined by) ?? at /tmp/foundationdb/tmp/build/foundationdb/./flow/flow.h:170\n (inlined by) ?? at /tmp/foundationdb/tmp/build/foundationdb/./flow/serialize.h:80\n (inlined by) save&lt;PacketWriter, Optional&lt;TLogInterface&gt; &gt; at /tmp/foundationdb/tmp/build/foundationdb/./flow/serialize.h:87\n (inlined by) operator&amp;&lt;PacketWriter, Optional&lt;TLogInterface&gt; &gt; at /tmp/foundationdb/tmp/build/foundationdb/./flow/serialize.h:66\n (inlined by) ?? at /tmp/foundationdb/tmp/build/foundationdb/fdbserver/LogSystemConfig.h:48\n (inlined by) ?? at /tmp/foundationdb/tmp/build/foundationdb/./flow/serialize.h:80\n (inlined by) save&lt;PacketWriter, OptionalInterface&lt;TLogInterface&gt; &gt; at /tmp/foundationdb/tmp/build/foundationdb/./flow/serialize.h:87\n (inlined by) operator&lt;&lt; &lt;PacketWriter, OptionalInterface&lt;TLogInterface&gt; &gt; at /tmp/foundationdb/tmp/build/foundationdb/./flow/serialize.h:54\n (inlined by) void save&lt;PacketWriter, OptionalInterface&lt;TLogInterface&gt; &gt;(PacketWriter&amp;, std::vector&lt;OptionalInterface&lt;TLogInterface&gt;, std::allocator&lt;OptionalInterface&lt;TLogInterface&gt; &gt; &gt; const&amp;) at /tmp/foundationdb/tmp/build/foundationdb/./flow/serialize.h:131\nvoid ServerDBInfo::serialize&lt;PacketWriter&gt;(PacketWriter&amp;) at /tmp/foundationdb/tmp/build/foundationdb/./flow/serialize.h:607\n (inlined by) ?? at /tmp/foundationdb/tmp/build/foundationdb/./flow/serialize.h:115\n (inlined by) save&lt;PacketWriter, int&gt; at /tmp/foundationdb/tmp/build/foundationdb/./flow/serialize.h:87\n (inlined by) operator&amp;&lt;PacketWriter, int&gt; at /tmp/foundationdb/tmp/build/foundationdb/./flow/serialize.h:66\n (inlined by) ?? at /tmp/foundationdb/tmp/build/foundationdb/fdbserver/LogSystemConfig.h:103\n (inlined by) ?? at /tmp/foundationdb/tmp/build/foundationdb/./flow/serialize.h:80\n (inlined by) save&lt;PacketWriter, OldTLogConf&gt; at /tmp/foundationdb/tmp/build/foundationdb/./flow/serialize.h:87\n (inlined by) operator&lt;&lt; &lt;PacketWriter, OldTLogConf&gt; at /tmp/foundationdb/tmp/build/foundationdb/./flow/serialize.h:54\n (inlined by) save&lt;PacketWriter, OldTLogConf&gt; at /tmp/foundationdb/tmp/build/foundationdb/./flow/serialize.h:131\n (inlined by) operator&amp;&lt;PacketWriter, std::vector&lt;OldTLogConf&gt; &gt; at /tmp/foundationdb/tmp/build/foundationdb/./flow/serialize.h:66\n (inlined by) ?? at /tmp/foundationdb/tmp/build/foundationdb/fdbserver/LogSystemConfig.h:205\n (inlined by) ?? at /tmp/foundationdb/tmp/build/foundationdb/./flow/serialize.h:80\n (inlined by) save&lt;PacketWriter, LogSystemConfig&gt; at /tmp/foundationdb/tmp/build/foundationdb/./flow/serialize.h:87\n (inlined by) operator&amp;&lt;PacketWriter, LogSystemConfig&gt; at /tmp/foundationdb/tmp/build/foundationdb/./flow/serialize.h:66\n (inlined by) void ServerDBInfo::serialize&lt;PacketWriter&gt;(PacketWriter&amp;) at /tmp/foundationdb/tmp/build/foundationdb/fdbserver/ServerDBInfo.h:55\nMakeSerializeSource&lt;SerializeBoolAnd&lt;ServerDBInfo&gt; &gt;::serializePacketWriter(PacketWriter&amp;) const at /tmp/foundationdb/tmp/build/foundationdb/./flow/serialize.h:81\n (inlined by) save&lt;PacketWriter, ServerDBInfo&gt; at /tmp/foundationdb/tmp/build/foundationdb/./flow/serialize.h:87\n (inlined by) operator&lt;&lt; &lt;PacketWriter, ServerDBInfo&gt; at /tmp/foundationdb/tmp/build/foundationdb/./flow/serialize.h:54\n (inlined by) ?? at /tmp/foundationdb/tmp/build/foundationdb/./flow/serialize.h:643\n (inlined by) MakeSerializeSource&lt;SerializeBoolAnd&lt;ServerDBInfo&gt; &gt;::serializePacketWriter(PacketWriter&amp;) const at /tmp/foundationdb/tmp/build/foundationdb/./flow/serialize.h:627\nsendPacket(TransportData*, ISerializeSource const&amp;, Endpoint const&amp;, bool) at /tmp/foundationdb/tmp/build/foundationdb/fdbrpc/FlowTransport.actor.cpp:877\nActorCallback&lt;(anonymous namespace)::NetworkSenderActor&lt;ServerDBInfo&gt;, 0, ServerDBInfo&gt;::fire(ServerDBInfo const&amp;) at /tmp/foundationdb/tmp/build/foundationdb/./flow/flow.h:636\n (inlined by) ?? at /tmp/foundationdb/tmp/build/foundationdb/fdbrpc/genericactors.actor.h:96\n (inlined by) ?? at /tmp/foundationdb/tmp/build/foundationdb/fdbrpc/genericactors.actor.h:96\n (inlined by) ?? at /tmp/foundationdb/tmp/build/foundationdb/fdbrpc/genericactors.actor.h:96\n (inlined by) ?? at /tmp/foundationdb/tmp/build/foundationdb/fdbrpc/genericactors.actor.g.h:1013\n (inlined by) ?? at /tmp/foundationdb/tmp/build/foundationdb/fdbrpc/genericactors.actor.g.h:1085\n (inlined by) ?? at /tmp/foundationdb/tmp/build/foundationdb/fdbrpc/genericactors.actor.g.h:1040\n (inlined by) ?? at /tmp/foundationdb/tmp/build/foundationdb/fdbrpc/genericactors.actor.g.h:1046\n (inlined by) ?? at /tmp/foundationdb/tmp/build/foundationdb/fdbrpc/genericactors.actor.g.h:1060\n (inlined by) fire at /tmp/foundationdb/tmp/build/foundationdb/./flow/flow.h:928\n(anonymous namespace)::ClusterGetServerInfoActorState&lt;(anonymous namespace)::ClusterGetServerInfoActor&gt;::a_body1break1(int) [clone .isra.1670] at /tmp/foundationdb/tmp/build/foundationdb/./flow/flow.h:381\n (inlined by) ?? at /tmp/foundationdb/tmp/build/foundationdb/./fdbrpc/fdbrpc.h:99\n (inlined by) ?? at /tmp/foundationdb/tmp/build/foundationdb/fdbserver/ClusterController.actor.cpp:943\n (inlined by) ?? at /tmp/foundationdb/tmp/build/foundationdb/fdbserver/ClusterController.actor.g.cpp:2149\n(anonymous namespace)::ClusterGetServerInfoActorState&lt;(anonymous namespace)::ClusterGetServerInfoActor&gt;::a_body1loopBody1(int) at /tmp/foundationdb/tmp/build/foundationdb/fdbserver/ClusterController.actor.g.cpp:2145\nActorCallback&lt;(anonymous namespace)::ClusterGetServerInfoActor, 0, Void&gt;::fire(Void const&amp;) at /tmp/foundationdb/tmp/build/foundationdb/fdbserver/ClusterController.actor.g.cpp:2114\n (inlined by) ?? at /tmp/foundationdb/tmp/build/foundationdb/fdbserver/ClusterController.actor.g.cpp:2161\n (inlined by) ?? at /tmp/foundationdb/tmp/build/foundationdb/fdbserver/ClusterController.actor.g.cpp:2167\n (inlined by) ?? at /tmp/foundationdb/tmp/build/foundationdb/fdbserver/ClusterController.actor.g.cpp:2188\n (inlined by) fire at /tmp/foundationdb/tmp/build/foundationdb/./flow/flow.h:928\nvoid SAV&lt;Void&gt;::send&lt;Void&gt;(Void&amp;&amp;) at /tmp/foundationdb/tmp/build/foundationdb/./flow/flow.h:381\nAsyncVar&lt;ServerDBInfo&gt;::set(ServerDBInfo const&amp;) at /tmp/foundationdb/tmp/build/foundationdb/./flow/flow.h:720\n (inlined by) ?? at /tmp/foundationdb/tmp/build/foundationdb/flow/genericactors.actor.h:657\n (inlined by) AsyncVar&lt;ServerDBInfo&gt;::set(ServerDBInfo const&amp;) at /tmp/foundationdb/tmp/build/foundationdb/flow/genericactors.actor.h:651\nclusterRegisterMaster(ClusterControllerData*, RegisterMasterRequest const&amp;) at /tmp/foundationdb/tmp/build/foundationdb/fdbserver/ClusterController.actor.cpp:1360\nActorSingleCallback&lt;(anonymous namespace)::ClusterControllerCoreActor, 8, RegisterMasterRequest&gt;::fire(RegisterMasterRequest const&amp;) at /tmp/foundationdb/tmp/build/foundationdb/fdbserver/ClusterController.actor.cpp:1749\n (inlined by) ?? at /tmp/foundationdb/tmp/build/foundationdb/fdbserver/ClusterController.actor.g.cpp:7198\n (inlined by) fire at /tmp/foundationdb/tmp/build/foundationdb/./flow/flow.h:938\nNetNotifiedQueue&lt;RegisterMasterRequest&gt;::receive(ArenaReader&amp;) at /tmp/foundationdb/tmp/build/foundationdb/./flow/flow.h:532\n (inlined by) NetNotifiedQueue&lt;RegisterMasterRequest&gt;::receive(ArenaReader&amp;) at /tmp/foundationdb/tmp/build/foundationdb/./fdbrpc/fdbrpc.h:204\n(anonymous namespace)::DeliverActorState&lt;(anonymous namespace)::DeliverActor&gt;::a_body1cont1(int) [clone .isra.330] at /tmp/foundationdb/tmp/build/foundationdb/fdbrpc/FlowTransport.actor.cpp:443\nActorCallback&lt;(anonymous namespace)::DeliverActor, 0, Void&gt;::fire(Void const&amp;) at /tmp/foundationdb/tmp/build/foundationdb/./flow/flow.h:929\nvoid SAV&lt;Void&gt;::send&lt;Void&gt;(Void&amp;&amp;) at /tmp/foundationdb/tmp/build/foundationdb/./flow/flow.h:381\nN2::Net2::run() at /tmp/foundationdb/tmp/build/foundationdb/flow/flow.h:720\n (inlined by) ?? at /tmp/foundationdb/tmp/build/foundationdb/flow/Net2.actor.cpp:467\n (inlined by) ?? at /tmp/foundationdb/tmp/build/foundationdb/flow/Net2.actor.cpp:474\n (inlined by) N2::Net2::run() at /tmp/foundationdb/tmp/build/foundationdb/flow/Net2.actor.cpp:628\nmain at /tmp/foundationdb/tmp/build/foundationdb/fdbserver/fdbserver.actor.cpp:1617 (discriminator 2)\n?? ??:0\n</code></pre>",
        "post_number": 2,
        "post_type": 1,
        "posts_count": 17,
        "updated_at": "2018-06-01T12:48:05.536Z",
        "reply_count": 0,
        "reply_to_post_number": null,
        "quote_count": 0,
        "incoming_link_count": 5,
        "reads": 87,
        "readers_count": 86,
        "score": 57.4,
        "yours": false,
        "topic_id": 483,
        "topic_slug": "segmentation-fault-error-and-broken-cluster",
        "display_username": "Viacheslav Biriukov",
        "primary_group_name": null,
        "flair_name": null,
        "flair_url": null,
        "flair_bg_color": null,
        "flair_color": null,
        "flair_group_id": null,
        "badges_granted": [],
        "version": 1,
        "can_edit": false,
        "can_delete": false,
        "can_recover": false,
        "can_see_hidden_post": false,
        "can_wiki": false,
        "read": true,
        "user_title": null,
        "bookmarked": false,
        "actions_summary": [
          {
            "id": 2,
            "count": 1
          }
        ],
        "moderator": false,
        "admin": false,
        "staff": false,
        "user_id": 211,
        "hidden": false,
        "trust_level": 1,
        "deleted_at": null,
        "user_deleted": false,
        "edit_reason": null,
        "can_view_edit_history": true,
        "wiki": false,
        "post_url": "/t/segmentation-fault-error-and-broken-cluster/483/2",
        "can_accept_answer": false,
        "can_unaccept_answer": false,
        "accepted_answer": false,
        "topic_accepted_answer": null
      },
      {
        "id": 1369,
        "name": "A.J. Beamon",
        "username": "ajbeamon",
        "avatar_template": "/user_avatar/forums.foundationdb.org/ajbeamon/{size}/13_2.png",
        "created_at": "2018-06-01T15:33:09.690Z",
        "cooked": "<p>To be clear, the errors posted above are not segfaults but rather the process intentionally shutting itself down when it reaches its memory limit (default 8 GB). So the question then is why are the processes using so much memory?</p>\n<p>Based on the command you pasted that you\u2019re using to run <code>fdbserver</code>, it looks like you are using the default memory limit, but do let me know if that\u2019s not the case.</p>\n<p>I am currently aware of a couple different ways that currently exist to run a server process out of memory (both of which are issues we are tracking). Do either of these match your situation?</p>\n<ol>\n<li>\n<p>Repeatedly creating database objects (e.g. using one of the <a href=\"https://godoc.org/github.com/apple/foundationdb/bindings/go/src/fdb#MustOpen\"><code>Open</code></a> variants in Golang) leaks memory on the coordinators. For example, if you are opening a new database for each transaction, you will eventually run some of your server processes out of memory. See <a href=\"https://github.com/apple/foundationdb/issues/321\">https://github.com/apple/foundationdb/issues/321</a>.</p>\n</li>\n<li>\n<p>Aggressively high write loads can run the proxies out of memory. This is particularly likely if a heavy load is turned on suddenly, but I think may also be possible if you are trying to write with unbounded parallelism (i.e. if your writers aren\u2019t waiting for the result of one write before starting another). It\u2019s reasonable to have multiple clients writing simultaneously, but if your writers are never waiting for commits to complete, then there could end up being lots of commits in flight. If you are writing heavy volumes, you could try turning down the rate at which you try to write (and/or bounding your parallelism) to see if that helps. Note that if your load is saturating the cluster, you\u2019ll be able to do this without sacrificing throughput. See <a href=\"https://github.com/apple/foundationdb/issues/370\">https://github.com/apple/foundationdb/issues/370</a> for the issue regarding this memory problem.</p>\n</li>\n</ol>\n<p>It is also of course possible that you\u2019ve encountered some other way to run the processes out of memory. If neither of the above seem relevant to you, we should try to investigate what\u2019s going on. A good starting point would be a more detailed description of what kind of workload you are running, and it may be helpful to see the trace logs from the failing processes as well.</p>",
        "post_number": 3,
        "post_type": 1,
        "posts_count": 17,
        "updated_at": "2018-06-01T15:33:09.690Z",
        "reply_count": 1,
        "reply_to_post_number": null,
        "quote_count": 0,
        "incoming_link_count": 4,
        "reads": 83,
        "readers_count": 82,
        "score": 41.6,
        "yours": false,
        "topic_id": 483,
        "topic_slug": "segmentation-fault-error-and-broken-cluster",
        "display_username": "A.J. Beamon",
        "primary_group_name": null,
        "flair_name": null,
        "flair_url": null,
        "flair_bg_color": null,
        "flair_color": null,
        "flair_group_id": null,
        "badges_granted": [],
        "version": 1,
        "can_edit": false,
        "can_delete": false,
        "can_recover": false,
        "can_see_hidden_post": false,
        "can_wiki": false,
        "link_counts": [
          {
            "url": "https://github.com/apple/foundationdb/issues/321",
            "internal": false,
            "reflection": false,
            "title": "Database object creation leaks memory on coordinators \u00b7 Issue #321 \u00b7 apple/foundationdb \u00b7 GitHub",
            "clicks": 11
          },
          {
            "url": "https://github.com/apple/foundationdb/issues/370",
            "internal": false,
            "reflection": false,
            "title": "Aggressive writes can run the proxy out of memory \u00b7 Issue #370 \u00b7 apple/foundationdb \u00b7 GitHub",
            "clicks": 6
          },
          {
            "url": "https://godoc.org/github.com/apple/foundationdb/bindings/go/src/fdb#MustOpen",
            "internal": false,
            "reflection": false,
            "title": "fdb - GoDoc",
            "clicks": 2
          }
        ],
        "read": true,
        "user_title": null,
        "bookmarked": false,
        "actions_summary": [],
        "moderator": false,
        "admin": true,
        "staff": true,
        "user_id": 12,
        "hidden": false,
        "trust_level": 4,
        "deleted_at": null,
        "user_deleted": false,
        "edit_reason": null,
        "can_view_edit_history": true,
        "wiki": false,
        "post_url": "/t/segmentation-fault-error-and-broken-cluster/483/3",
        "can_accept_answer": false,
        "can_unaccept_answer": false,
        "accepted_answer": false,
        "topic_accepted_answer": null
      },
      {
        "id": 1371,
        "name": "Viacheslav Biriukov",
        "username": "brk0v",
        "avatar_template": "/user_avatar/forums.foundationdb.org/brk0v/{size}/173_2.png",
        "created_at": "2018-06-04T10:21:31.809Z",
        "cooked": "<p>Thank you for answer,</p>\n<aside class=\"quote no-group\" data-username=\"ajbeamon\" data-post=\"3\" data-topic=\"483\">\n<div class=\"title\">\n<div class=\"quote-controls\"></div>\n<img loading=\"lazy\" alt=\"\" width=\"24\" height=\"24\" src=\"https://sea1.discourse-cdn.com/foundationdb/user_avatar/forums.foundationdb.org/ajbeamon/48/13_2.png\" class=\"avatar\"> ajbeamon:</div>\n<blockquote>\n<p>To be clear, the errors posted above are not segfaults but rather the process intentionally shutting itself down when it reaches its memory limit (default 8 GB). So the question then is why are the processes using so much memory?</p>\n</blockquote>\n</aside>\n<p>It crashes near 4GB of memory.</p>\n<aside class=\"quote no-group\" data-username=\"ajbeamon\" data-post=\"3\" data-topic=\"483\">\n<div class=\"title\">\n<div class=\"quote-controls\"></div>\n<img loading=\"lazy\" alt=\"\" width=\"24\" height=\"24\" src=\"https://sea1.discourse-cdn.com/foundationdb/user_avatar/forums.foundationdb.org/ajbeamon/48/13_2.png\" class=\"avatar\"> ajbeamon:</div>\n<blockquote>\n<p>Based on the command you pasted that you\u2019re using to run <code>fdbserver</code> , it looks like you are using the default memory limit, but do let me know if that\u2019s not the case.</p>\n</blockquote>\n</aside>\n<p>Yes, default settings for memory.</p>\n<aside class=\"quote no-group\" data-username=\"ajbeamon\" data-post=\"3\" data-topic=\"483\">\n<div class=\"title\">\n<div class=\"quote-controls\"></div>\n<img loading=\"lazy\" alt=\"\" width=\"24\" height=\"24\" src=\"https://sea1.discourse-cdn.com/foundationdb/user_avatar/forums.foundationdb.org/ajbeamon/48/13_2.png\" class=\"avatar\"> ajbeamon:</div>\n<blockquote>\n<p>Repeatedly creating database objects (e.g. using one of the <a href=\"https://godoc.org/github.com/apple/foundationdb/bindings/go/src/fdb#MustOpen\" rel=\"noopener nofollow ugc\"> <code>Open</code> </a> variants in Golang) leaks memory on the coordinators. For example, if you are opening a new database for each transaction, you will eventually run some of your server processes out of memory. See <a href=\"https://github.com/apple/foundationdb/issues/321\" rel=\"noopener nofollow ugc\">https://github.com/apple/foundationdb/issues/321 </a>.</p>\n</blockquote>\n</aside>\n<p>No, I open database only once.</p>\n<aside class=\"quote no-group\" data-username=\"ajbeamon\" data-post=\"3\" data-topic=\"483\">\n<div class=\"title\">\n<div class=\"quote-controls\"></div>\n<img loading=\"lazy\" alt=\"\" width=\"24\" height=\"24\" src=\"https://sea1.discourse-cdn.com/foundationdb/user_avatar/forums.foundationdb.org/ajbeamon/48/13_2.png\" class=\"avatar\"> ajbeamon:</div>\n<blockquote>\n<ol>\n<li>Aggressively high write loads can run the proxies out of memory. This is particularly likely if a heavy load is turned on suddenly, but I think may also be possible if you are trying to write with unbounded parallelism (i.e. if your writers aren\u2019t waiting for the result of one write before starting another). It\u2019s reasonable to have multiple clients writing simultaneously, but if your writers are never waiting for commits to complete, then there could end up being lots of commits in flight. If you are writing heavy volumes, you could try turning down the rate at which you try to write (and/or bounding your parallelism) to see if that helps. Note that if your load is saturating the cluster, you\u2019ll be able to do this without sacrificing throughput. See <a href=\"https://github.com/apple/foundationdb/issues/370\" rel=\"noopener nofollow ugc\">https://github.com/apple/foundationdb/issues/370 </a> for the issue regarding this memory problem.</li>\n</ol>\n</blockquote>\n</aside>\n<p>In my case I use 1 goroutine (thread) for writes with a lock. But this one makes a lot of writes.</p>\n<aside class=\"quote no-group\" data-username=\"ajbeamon\" data-post=\"3\" data-topic=\"483\">\n<div class=\"title\">\n<div class=\"quote-controls\"></div>\n<img loading=\"lazy\" alt=\"\" width=\"24\" height=\"24\" src=\"https://sea1.discourse-cdn.com/foundationdb/user_avatar/forums.foundationdb.org/ajbeamon/48/13_2.png\" class=\"avatar\"> ajbeamon:</div>\n<blockquote>\n<p>It is also of course possible that you\u2019ve encountered some other way to run the processes out of memory. If neither of the above seem relevant to you, we should try to investigate what\u2019s going on. A good starting point would be a more detailed description of what kind of workload you are running, and it may be helpful to see the trace logs from the failing processes as well.</p>\n</blockquote>\n</aside>\n<p>As I mentioned above, I make writes using only <strong>one</strong> goroutine and wait for a commit. I have small writes about 10KB. Rate is around 10 writes per second. But my SSDs are not fancy new and a bit slow. So I see a some retryable errors: 1007, 1021 and 1009. Memory usage was near 4GB per process. Don\u2019t use any options for transactions.</p>\n<p>My main concern is that after OOM (or memory leak or segfault), cluster can\u2019t heal itself and I got a fully broken storage, can\u2019t even access my data. It\u2019s trying to restart processes without luck near 4GB of RAM.</p>\n<p>Full log of a process with the OOM: <a href=\"https://raw.githubusercontent.com/brk0v/logs/master/trace.192.168.001.100.4501.1528107868.HvCax5.6.xml\" rel=\"noopener nofollow ugc\">https://raw.githubusercontent.com/brk0v/logs/master/trace.192.168.001.100.4501.1528107868.HvCax5.6.xml</a></p>\n<p>I\u2019ll grep and send you more logs if you need ones.</p>\n<p>Thank you!</p>",
        "post_number": 4,
        "post_type": 1,
        "posts_count": 17,
        "updated_at": "2018-06-04T12:18:19.121Z",
        "reply_count": 2,
        "reply_to_post_number": 3,
        "quote_count": 1,
        "incoming_link_count": 2,
        "reads": 84,
        "readers_count": 83,
        "score": 36.8,
        "yours": false,
        "topic_id": 483,
        "topic_slug": "segmentation-fault-error-and-broken-cluster",
        "display_username": "Viacheslav Biriukov",
        "primary_group_name": null,
        "flair_name": null,
        "flair_url": null,
        "flair_bg_color": null,
        "flair_color": null,
        "flair_group_id": null,
        "badges_granted": [],
        "version": 2,
        "can_edit": false,
        "can_delete": false,
        "can_recover": false,
        "can_see_hidden_post": false,
        "can_wiki": false,
        "link_counts": [
          {
            "url": "https://raw.githubusercontent.com/brk0v/logs/master/trace.192.168.001.100.4501.1528107868.HvCax5.6.xml",
            "internal": false,
            "reflection": false,
            "clicks": 3
          }
        ],
        "read": true,
        "user_title": null,
        "bookmarked": false,
        "actions_summary": [],
        "moderator": false,
        "admin": false,
        "staff": false,
        "user_id": 211,
        "hidden": false,
        "trust_level": 1,
        "deleted_at": null,
        "user_deleted": false,
        "edit_reason": null,
        "can_view_edit_history": true,
        "wiki": false,
        "post_url": "/t/segmentation-fault-error-and-broken-cluster/483/4",
        "can_accept_answer": false,
        "can_unaccept_answer": false,
        "accepted_answer": false,
        "topic_accepted_answer": null
      },
      {
        "id": 1372,
        "name": "Viacheslav Biriukov",
        "username": "brk0v",
        "avatar_template": "/user_avatar/forums.foundationdb.org/brk0v/{size}/173_2.png",
        "created_at": "2018-06-04T14:45:52.831Z",
        "cooked": "<p>I added memory for each cluster node.</p>\n<p>So now I have:</p>\n<pre><code class=\"lang-auto\">/usr/sbin/fdbserver --cluster_file /etc/foundationdb/fdb.cluster --datadir /var/lib/foundationdb/data/4500 --listen_address public --logdir /var/log/foundationdb --memory 10GiB --public_address auto:4500 --storage_memory 2GiB --tls_certificate_file /etc/foundationdb/fdb.pem --tls_key_file /etc/foundationdb/fdb-key.pem --tls_plugin /usr/lib/foundationdb/plugins/libFDBLibTLS.so\n</code></pre>\n<p>Restart my 3 node cluster and it has been recovering for 2 hours consuming memory and CPU but I can\u2019t see any progress\u2026</p>\n<p>Memory usage:</p>\n<pre><code class=\"lang-auto\"> 5383 foundat+  20   0 9762960 5.228g  21052 R  99.7  4.2 106:10.76 fdbserver\n 5382 foundat+  20   0 8476424 4.051g  20900 S  56.3  3.2  91:55.13 fdbserver\n</code></pre>\n<p>I have 2 instances on each of servers with ports 4500 and 4501.</p>\n<p>$ fdbcli:</p>\n<pre><code class=\"lang-auto\">fdb&gt; status details\n\nWARNING: Long delay (Ctrl-C to interrupt)\n\nUsing cluster file `/etc/foundationdb/fdb.cluster'.\n\nInitializing new transaction servers and recovering transaction logs.\n\nThe cluster has some unreachable processes.\n</code></pre>\n<p>$ cat /etc/foundationdb/fdb.cluster</p>\n<pre><code class=\"lang-auto\"># DO NOT EDIT!\n# This file is auto-generated, it is not to be edited by hand\ntest_cluster:6KSAuefFw2PtTjwhomsLUdG4wQPeVLmY@192.168.1.29:4500:tls,192.168.1.76:4500:tls,192.168.1.78:4500:tls\n</code></pre>",
        "post_number": 5,
        "post_type": 1,
        "posts_count": 17,
        "updated_at": "2018-06-04T14:45:52.831Z",
        "reply_count": 1,
        "reply_to_post_number": 4,
        "quote_count": 0,
        "incoming_link_count": 7,
        "reads": 79,
        "readers_count": 78,
        "score": 55.8,
        "yours": false,
        "topic_id": 483,
        "topic_slug": "segmentation-fault-error-and-broken-cluster",
        "display_username": "Viacheslav Biriukov",
        "primary_group_name": null,
        "flair_name": null,
        "flair_url": null,
        "flair_bg_color": null,
        "flair_color": null,
        "flair_group_id": null,
        "badges_granted": [],
        "version": 1,
        "can_edit": false,
        "can_delete": false,
        "can_recover": false,
        "can_see_hidden_post": false,
        "can_wiki": false,
        "read": true,
        "user_title": null,
        "reply_to_user": {
          "id": 211,
          "username": "brk0v",
          "name": "Viacheslav Biriukov",
          "avatar_template": "/user_avatar/forums.foundationdb.org/brk0v/{size}/173_2.png"
        },
        "bookmarked": false,
        "actions_summary": [],
        "moderator": false,
        "admin": false,
        "staff": false,
        "user_id": 211,
        "hidden": false,
        "trust_level": 1,
        "deleted_at": null,
        "user_deleted": false,
        "edit_reason": null,
        "can_view_edit_history": true,
        "wiki": false,
        "post_url": "/t/segmentation-fault-error-and-broken-cluster/483/5",
        "can_accept_answer": false,
        "can_unaccept_answer": false,
        "accepted_answer": false,
        "topic_accepted_answer": null
      },
      {
        "id": 1373,
        "name": "Viacheslav Biriukov",
        "username": "brk0v",
        "avatar_template": "/user_avatar/forums.foundationdb.org/brk0v/{size}/173_2.png",
        "created_at": "2018-06-04T15:44:03.248Z",
        "cooked": "<p>Found an interesting log error:</p>\n<pre><code class=\"lang-auto\">&lt;Event Severity=\"40\" Time=\"1528068636.898064\" Type=\"SharedTLogFailed\" Machine=\"192.168.1.100:4501\" ID=\"87e809b0ea61cee3\" Reason=\"Error\" Error=\"io_error\" ErrorDescription=\"Disk i/o operation failed\" ErrorCode=\"1510\" logGroup=\"default\" Backtrace=\"addr2line -e fdbserver.debug -p -C -f -i 0x13c7f0c 0x13c6e9a 0xa26332 0xa26c86 0xa26e64 0xa182b3 0xa1ddc6 0xa343fb 0xa34bb7 0x4e2875 0x12988d0 0x1298b58 0x47b398 0x1399e13 0x42a627 0x7fe958ccb2e1\"/&gt;\n</code></pre>\n<pre><code class=\"lang-auto\">TraceEvent::backtrace(std::string) at /usr/include/c++/4.9/bits/basic_string.h:2424\n (inlined by) TraceEvent::backtrace(std::string) at /tmp/foundationdb/tmp/build/foundationdb/flow/Trace.cpp:874\nTraceEvent::~TraceEvent() at /usr/include/c++/4.9/bits/basic_string.h:301\n (inlined by) ?? at /usr/include/c++/4.9/bits/basic_string.h:547\n (inlined by) TraceEvent::~TraceEvent() at /tmp/foundationdb/tmp/build/foundationdb/flow/Trace.cpp:908\nendRole(UID, std::string, std::string, bool, Error) at /usr/include/c++/4.9/bits/basic_string.h:301\n (inlined by) ?? at /usr/include/c++/4.9/bits/basic_string.h:547\n (inlined by) endRole(UID, std::string, std::string, bool, Error) at /tmp/foundationdb/tmp/build/foundationdb/fdbserver/worker.actor.cpp:424\n(anonymous namespace)::WorkerHandleErrorsActorState&lt;(anonymous namespace)::WorkerHandleErrorsActor&gt;::a_body1loopBody1when1(ErrorInfo const&amp;, int) at /usr/include/c++/4.9/bits/basic_string.h:301\n (inlined by) ?? at /usr/include/c++/4.9/bits/basic_string.h:547\n (inlined by) a_body1loopBody1when1 at /tmp/foundationdb/tmp/build/foundationdb/fdbserver/worker.actor.cpp:145\nActorSingleCallback&lt;(anonymous namespace)::WorkerHandleErrorsActor, 0, ErrorInfo&gt;::fire(ErrorInfo const&amp;) at /tmp/foundationdb/tmp/build/foundationdb/./flow/flow.h:939\n(anonymous namespace)::ForwardErrorActorState&lt;(anonymous namespace)::ForwardErrorActor&gt;::a_body1Catch2(Error const&amp;, int) [clone .isra.1119] at /tmp/foundationdb/tmp/build/foundationdb/./flow/flow.h:532\n (inlined by) ?? at /tmp/foundationdb/tmp/build/foundationdb/./flow/flow.h:837\n (inlined by) ?? at /tmp/foundationdb/tmp/build/foundationdb/fdbserver/worker.actor.cpp:108\nforwardError(PromiseStream&lt;ErrorInfo&gt; const&amp;, char const* const&amp;, UID const&amp;, Future&lt;Void&gt; const&amp;) at /tmp/foundationdb/tmp/build/foundationdb/./flow/flow.h:636\n (inlined by) ?? at /tmp/foundationdb/tmp/build/foundationdb/./flow/flow.h:693\n (inlined by) ?? at /tmp/foundationdb/tmp/build/foundationdb/fdbserver/worker.actor.g.cpp:410\n (inlined by) forwardError(PromiseStream&lt;ErrorInfo&gt; const&amp;, char const* const&amp;, UID const&amp;, Future&lt;Void&gt; const&amp;) at /tmp/foundationdb/tmp/build/foundationdb/fdbserver/worker.actor.cpp:99\n(anonymous namespace)::WorkerServerActorState&lt;(anonymous namespace)::WorkerServerActor&gt;::a_body1cont12cont3loopBody1when4(InitializeTLogRequest const&amp;, int) at /tmp/foundationdb/tmp/build/foundationdb/./flow/flow.h:837 (discriminator 2)\n (inlined by) ?? at /tmp/foundationdb/tmp/build/foundationdb/./flow/ActorCollection.h:61 (discriminator 2)\n (inlined by) a_body1cont12cont3loopBody1when4 at /tmp/foundationdb/tmp/build/foundationdb/fdbserver/worker.actor.cpp:729 (discriminator 2)\nActorSingleCallback&lt;(anonymous namespace)::WorkerServerActor, 10, InitializeTLogRequest&gt;::fire(InitializeTLogRequest const&amp;) at /tmp/foundationdb/tmp/build/foundationdb/./fdbrpc/fdbrpc.h:110\n (inlined by) ?? at /tmp/foundationdb/tmp/build/foundationdb/fdbserver/WorkerInterface.h:69\n (inlined by) fire at /tmp/foundationdb/tmp/build/foundationdb/./flow/flow.h:938\nNetNotifiedQueue&lt;InitializeTLogRequest&gt;::receive(ArenaReader&amp;) at /tmp/foundationdb/tmp/build/foundationdb/./flow/flow.h:532\n (inlined by) NetNotifiedQueue&lt;InitializeTLogRequest&gt;::receive(ArenaReader&amp;) at /tmp/foundationdb/tmp/build/foundationdb/./fdbrpc/fdbrpc.h:204\n(anonymous namespace)::DeliverActorState&lt;(anonymous namespace)::DeliverActor&gt;::a_body1cont1(int) [clone .isra.330] at /tmp/foundationdb/tmp/build/foundationdb/fdbrpc/FlowTransport.actor.cpp:443\nActorCallback&lt;(anonymous namespace)::DeliverActor, 0, Void&gt;::fire(Void const&amp;) at /tmp/foundationdb/tmp/build/foundationdb/./flow/flow.h:929\nvoid SAV&lt;Void&gt;::send&lt;Void&gt;(Void&amp;&amp;) at /tmp/foundationdb/tmp/build/foundationdb/./flow/flow.h:381\nN2::Net2::run() at /tmp/foundationdb/tmp/build/foundationdb/flow/flow.h:720\n (inlined by) ?? at /tmp/foundationdb/tmp/build/foundationdb/flow/Net2.actor.cpp:467\n (inlined by) ?? at /tmp/foundationdb/tmp/build/foundationdb/flow/Net2.actor.cpp:474\n (inlined by) N2::Net2::run() at /tmp/foundationdb/tmp/build/foundationdb/flow/Net2.actor.cpp:628\nmain at /tmp/foundationdb/tmp/build/foundationdb/fdbserver/fdbserver.actor.cpp:1617 (discriminator 2)\"/&gt;\n.\n</code></pre>",
        "post_number": 6,
        "post_type": 1,
        "posts_count": 17,
        "updated_at": "2018-06-04T15:44:03.248Z",
        "reply_count": 2,
        "reply_to_post_number": 5,
        "quote_count": 0,
        "incoming_link_count": 2,
        "reads": 83,
        "readers_count": 82,
        "score": 36.6,
        "yours": false,
        "topic_id": 483,
        "topic_slug": "segmentation-fault-error-and-broken-cluster",
        "display_username": "Viacheslav Biriukov",
        "primary_group_name": null,
        "flair_name": null,
        "flair_url": null,
        "flair_bg_color": null,
        "flair_color": null,
        "flair_group_id": null,
        "badges_granted": [],
        "version": 1,
        "can_edit": false,
        "can_delete": false,
        "can_recover": false,
        "can_see_hidden_post": false,
        "can_wiki": false,
        "read": true,
        "user_title": null,
        "reply_to_user": {
          "id": 211,
          "username": "brk0v",
          "name": "Viacheslav Biriukov",
          "avatar_template": "/user_avatar/forums.foundationdb.org/brk0v/{size}/173_2.png"
        },
        "bookmarked": false,
        "actions_summary": [],
        "moderator": false,
        "admin": false,
        "staff": false,
        "user_id": 211,
        "hidden": false,
        "trust_level": 1,
        "deleted_at": null,
        "user_deleted": false,
        "edit_reason": null,
        "can_view_edit_history": true,
        "wiki": false,
        "post_url": "/t/segmentation-fault-error-and-broken-cluster/483/6",
        "can_accept_answer": false,
        "can_unaccept_answer": false,
        "accepted_answer": false,
        "topic_accepted_answer": null
      },
      {
        "id": 1374,
        "name": "Viacheslav Biriukov",
        "username": "brk0v",
        "avatar_template": "/user_avatar/forums.foundationdb.org/brk0v/{size}/173_2.png",
        "created_at": "2018-06-04T16:01:13.007Z",
        "cooked": "<p>Other strange thing is a size of data dir. My data should be around 40GB but, on disk I have log file with 113 GB:</p>\n<pre><code class=\"lang-auto\">drwxr-xr-x 2 foundationdb foundationdb 4.0K Jun  1 01:21 .\ndrwxr-xr-x 4 foundationdb foundationdb   30 May 31 14:31 ..\n-rw---S--- 1 foundationdb foundationdb 9.7M Jun  4 15:57 coordination-0.fdq\n-rw---S--- 1 foundationdb foundationdb  15M Jun  4 15:57 coordination-1.fdq\n-rw---S--- 1 foundationdb foundationdb 113G Jun  4 15:57 log-435dc58687efd6f096a1b9a63a37da1b.sqlite &lt;--------- 113 GB\n-rw---S--- 1 foundationdb foundationdb 117M Jun  4 15:57 log-435dc58687efd6f096a1b9a63a37da1b.sqlite-wal\n-rw---S--- 1 foundationdb foundationdb 1.6G Jun  4 15:57 logqueue-435dc58687efd6f096a1b9a63a37da1b-0.fdq\n-rw---S--- 1 foundationdb foundationdb 1.6G Jun  4 11:38 logqueue-435dc58687efd6f096a1b9a63a37da1b-1.fdq\n-rw---S--- 1 foundationdb foundationdb 4.0K May 31 14:27 processId\n-rw---S--- 1 foundationdb foundationdb  12G Jun  4 15:59 storage-ca2be1f34b74669e2a00a347290db311.sqlite\n-rw---S--- 1 foundationdb foundationdb  28M Jun  4 15:59 storage-ca2be1f34b74669e2a00a347290db311.sqlite-wal\n</code></pre>",
        "post_number": 7,
        "post_type": 1,
        "posts_count": 17,
        "updated_at": "2018-06-04T16:01:26.693Z",
        "reply_count": 1,
        "reply_to_post_number": 6,
        "quote_count": 0,
        "incoming_link_count": 0,
        "reads": 80,
        "readers_count": 79,
        "score": 21.0,
        "yours": false,
        "topic_id": 483,
        "topic_slug": "segmentation-fault-error-and-broken-cluster",
        "display_username": "Viacheslav Biriukov",
        "primary_group_name": null,
        "flair_name": null,
        "flair_url": null,
        "flair_bg_color": null,
        "flair_color": null,
        "flair_group_id": null,
        "badges_granted": [],
        "version": 1,
        "can_edit": false,
        "can_delete": false,
        "can_recover": false,
        "can_see_hidden_post": false,
        "can_wiki": false,
        "read": true,
        "user_title": null,
        "reply_to_user": {
          "id": 211,
          "username": "brk0v",
          "name": "Viacheslav Biriukov",
          "avatar_template": "/user_avatar/forums.foundationdb.org/brk0v/{size}/173_2.png"
        },
        "bookmarked": false,
        "actions_summary": [],
        "moderator": false,
        "admin": false,
        "staff": false,
        "user_id": 211,
        "hidden": false,
        "trust_level": 1,
        "deleted_at": null,
        "user_deleted": false,
        "edit_reason": null,
        "can_view_edit_history": true,
        "wiki": false,
        "post_url": "/t/segmentation-fault-error-and-broken-cluster/483/7",
        "can_accept_answer": false,
        "can_unaccept_answer": false,
        "accepted_answer": false,
        "topic_accepted_answer": null
      },
      {
        "id": 1376,
        "name": "A.J. Beamon",
        "username": "ajbeamon",
        "avatar_template": "/user_avatar/forums.foundationdb.org/ajbeamon/{size}/13_2.png",
        "created_at": "2018-06-04T16:30:36.343Z",
        "cooked": "<aside class=\"quote no-group\" data-username=\"brk0v\" data-post=\"4\" data-topic=\"483\">\n<div class=\"title\">\n<div class=\"quote-controls\"></div>\n<img loading=\"lazy\" alt=\"\" width=\"24\" height=\"24\" src=\"https://sea1.discourse-cdn.com/foundationdb/user_avatar/forums.foundationdb.org/brk0v/48/173_2.png\" class=\"avatar\"> brk0v:</div>\n<blockquote>\n<p>It crashes near 4GB of memory.</p>\n</blockquote>\n</aside>\n<p>It looks like the resident memory is about 4GB, but the virtual memory for the process (which is the number being limited) is 8GB. See this event from your log file just before the process died:</p>\n<pre><code class=\"lang-auto\">... Type=\"ProcessMetrics\" ... Memory=\"8589721600\" ResidentMemory=\"4228780032\" ...\n</code></pre>\n<aside class=\"quote no-group quote-modified\" data-username=\"brk0v\" data-post=\"6\" data-topic=\"483\">\n<div class=\"title\">\n<div class=\"quote-controls\"></div>\n<img loading=\"lazy\" alt=\"\" width=\"24\" height=\"24\" src=\"https://sea1.discourse-cdn.com/foundationdb/user_avatar/forums.foundationdb.org/brk0v/48/173_2.png\" class=\"avatar\"> brk0v:</div>\n<blockquote>\n<pre><code class=\"lang-auto\">... Error=\"io_error\" ...\n</code></pre>\n</blockquote>\n</aside>\n<p>Is the disk that your server processes are using functioning correctly? An error like this usually indicates some problem using the disk.</p>\n<aside class=\"quote no-group\" data-username=\"brk0v\" data-post=\"4\" data-topic=\"483\">\n<div class=\"title\">\n<div class=\"quote-controls\"></div>\n<img loading=\"lazy\" alt=\"\" width=\"24\" height=\"24\" src=\"https://sea1.discourse-cdn.com/foundationdb/user_avatar/forums.foundationdb.org/brk0v/48/173_2.png\" class=\"avatar\"> brk0v:</div>\n<blockquote>\n<p>My main concern is that after OOM (or memory leak or segfault), cluster can\u2019t heal itself and I got a fully broken storage, can\u2019t even access my data. It\u2019s trying to restart processes without luck near 4GB of RAM.</p>\n</blockquote>\n</aside>\n<p>A correctly configured cluster should be able to keep running with the loss of any process in the cluster. More generally, in double replication you should be able to set it up so that you could lose any set of processes in the same fault domain (e.g. you could lose one machine, or one rack, etc. depending on your configuration). I don\u2019t see anything immediately wrong with your configuration from the details you\u2019ve posted, so something may be going wrong with the recovery process.</p>\n<p>How many of your processes are running out of memory and/or having problems with IO errors? Is this happening on more than one node? If you are having memory problems on more than one process, can you check whether this large memory usage lines up with the large log-* files you reported?</p>\n<aside class=\"quote no-group\" data-username=\"brk0v\" data-post=\"7\" data-topic=\"483\">\n<div class=\"title\">\n<div class=\"quote-controls\"></div>\n<img loading=\"lazy\" alt=\"\" width=\"24\" height=\"24\" src=\"https://sea1.discourse-cdn.com/foundationdb/user_avatar/forums.foundationdb.org/brk0v/48/173_2.png\" class=\"avatar\"> brk0v:</div>\n<blockquote>\n<p>Other strange thing is a size of data dir. My data should be around 40GB but, on disk I have log file with 113 GB:</p>\n</blockquote>\n</aside>\n<p>The files that are large here are the transaction log\u2019s files. These can get large if there is some storage server in the cluster that either gets disconnected from the cluster or is not able to keep up with the write rate. In these cases, the transaction log has to store all of your mutations on disk until the storage server can fetch them and make them durable. If the storage server is completely dead, this data should get deleted once it\u2019s been replicated elsewhere. If the storage server is alive but falling behind, then I think this file can grow indefinitely if one storage server is having a harder time keeping up than others.</p>\n<p>If you are in fact saturating the cluster (you can tell by running <code>status</code> in <code>fdbcli</code> and looking to see if there is a  \u2018Performance limited by\u2019 section), I\u2019d recommend turning down your write rate to avoid doing so. As mentioned before, if the cluster is saturated, then you\u2019ll be able to reduce your write rate to some extent without affecting throughput.</p>",
        "post_number": 8,
        "post_type": 1,
        "posts_count": 17,
        "updated_at": "2018-06-04T16:30:36.343Z",
        "reply_count": 1,
        "reply_to_post_number": 4,
        "quote_count": 3,
        "incoming_link_count": 1,
        "reads": 79,
        "readers_count": 78,
        "score": 25.8,
        "yours": false,
        "topic_id": 483,
        "topic_slug": "segmentation-fault-error-and-broken-cluster",
        "display_username": "A.J. Beamon",
        "primary_group_name": null,
        "flair_name": null,
        "flair_url": null,
        "flair_bg_color": null,
        "flair_color": null,
        "flair_group_id": null,
        "badges_granted": [],
        "version": 1,
        "can_edit": false,
        "can_delete": false,
        "can_recover": false,
        "can_see_hidden_post": false,
        "can_wiki": false,
        "read": true,
        "user_title": null,
        "bookmarked": false,
        "actions_summary": [],
        "moderator": false,
        "admin": true,
        "staff": true,
        "user_id": 12,
        "hidden": false,
        "trust_level": 4,
        "deleted_at": null,
        "user_deleted": false,
        "edit_reason": null,
        "can_view_edit_history": true,
        "wiki": false,
        "post_url": "/t/segmentation-fault-error-and-broken-cluster/483/8",
        "can_accept_answer": false,
        "can_unaccept_answer": false,
        "accepted_answer": false,
        "topic_accepted_answer": null
      },
      {
        "id": 1377,
        "name": "Viacheslav Biriukov",
        "username": "brk0v",
        "avatar_template": "/user_avatar/forums.foundationdb.org/brk0v/{size}/173_2.png",
        "created_at": "2018-06-04T17:33:12.266Z",
        "cooked": "<aside class=\"quote no-group\" data-username=\"ajbeamon\" data-post=\"8\" data-topic=\"483\">\n<div class=\"title\">\n<div class=\"quote-controls\"></div>\n<img loading=\"lazy\" alt=\"\" width=\"24\" height=\"24\" src=\"https://sea1.discourse-cdn.com/foundationdb/user_avatar/forums.foundationdb.org/ajbeamon/48/13_2.png\" class=\"avatar\"> ajbeamon:</div>\n<blockquote>\n<p>How many of your processes are running out of memory and/or having problems with IO errors? Is this happening on more than one node? If you are having memory problems on more than one process, can you check whether this large memory usage lines up with the large log-* files you reported?</p>\n</blockquote>\n</aside>\n<p>I have 2 process on each node, and with default settings I saw OOMs in the logs on all instances.</p>\n<aside class=\"quote no-group\" data-username=\"ajbeamon\" data-post=\"8\" data-topic=\"483\">\n<div class=\"title\">\n<div class=\"quote-controls\"></div>\n<img loading=\"lazy\" alt=\"\" width=\"24\" height=\"24\" src=\"https://sea1.discourse-cdn.com/foundationdb/user_avatar/forums.foundationdb.org/ajbeamon/48/13_2.png\" class=\"avatar\"> ajbeamon:</div>\n<blockquote>\n<p>These can get large if there is some storage server in the cluster that either gets disconnected from the cluster or is not able to keep up with the write rate.</p>\n</blockquote>\n</aside>\n<p>So this file is a WAL for a storage server, isn\u2019t it? And all writes go through this file (append?), and then apply to the main sqllite db?</p>\n<aside class=\"quote no-group\" data-username=\"ajbeamon\" data-post=\"8\" data-topic=\"483\">\n<div class=\"title\">\n<div class=\"quote-controls\"></div>\n<img loading=\"lazy\" alt=\"\" width=\"24\" height=\"24\" src=\"https://sea1.discourse-cdn.com/foundationdb/user_avatar/forums.foundationdb.org/ajbeamon/48/13_2.png\" class=\"avatar\"> ajbeamon:</div>\n<blockquote>\n<p>If you are in fact saturating the cluster (you can tell by running <code>status</code> in <code>fdbcli</code> and looking to see if there is a \u2018Performance limited by\u2019 section), I\u2019d recommend turning down your write rate to avoid doing so. As mentioned before, if the cluster is saturated, then you\u2019ll be able to reduce your write rate to some extent without affecting throughput.</p>\n</blockquote>\n</aside>\n<p>Yes, but the thing is I have a limited time window, so I need to import data as fast as I can.<br>\nAnd for doing this I need to start over with a bigger memory limit and smaller number of fdbserver processes for saving disk space for transaction logs, if I understand right how fdb works with data.</p>",
        "post_number": 9,
        "post_type": 1,
        "posts_count": 17,
        "updated_at": "2018-06-04T17:33:12.266Z",
        "reply_count": 1,
        "reply_to_post_number": 8,
        "quote_count": 1,
        "incoming_link_count": 0,
        "reads": 73,
        "readers_count": 72,
        "score": 19.6,
        "yours": false,
        "topic_id": 483,
        "topic_slug": "segmentation-fault-error-and-broken-cluster",
        "display_username": "Viacheslav Biriukov",
        "primary_group_name": null,
        "flair_name": null,
        "flair_url": null,
        "flair_bg_color": null,
        "flair_color": null,
        "flair_group_id": null,
        "badges_granted": [],
        "version": 1,
        "can_edit": false,
        "can_delete": false,
        "can_recover": false,
        "can_see_hidden_post": false,
        "can_wiki": false,
        "read": true,
        "user_title": null,
        "bookmarked": false,
        "actions_summary": [],
        "moderator": false,
        "admin": false,
        "staff": false,
        "user_id": 211,
        "hidden": false,
        "trust_level": 1,
        "deleted_at": null,
        "user_deleted": false,
        "edit_reason": null,
        "can_view_edit_history": true,
        "wiki": false,
        "post_url": "/t/segmentation-fault-error-and-broken-cluster/483/9",
        "can_accept_answer": false,
        "can_unaccept_answer": false,
        "accepted_answer": false,
        "topic_accepted_answer": null
      },
      {
        "id": 1380,
        "name": "A.J. Beamon",
        "username": "ajbeamon",
        "avatar_template": "/user_avatar/forums.foundationdb.org/ajbeamon/{size}/13_2.png",
        "created_at": "2018-06-04T18:30:25.556Z",
        "cooked": "<aside class=\"quote no-group\" data-username=\"brk0v\" data-post=\"9\" data-topic=\"483\">\n<div class=\"title\">\n<div class=\"quote-controls\"></div>\n<img loading=\"lazy\" alt=\"\" width=\"24\" height=\"24\" src=\"https://sea1.discourse-cdn.com/foundationdb/user_avatar/forums.foundationdb.org/brk0v/48/173_2.png\" class=\"avatar\"> brk0v:</div>\n<blockquote>\n<p>I have 2 process on each node, and with default settings I saw OOMs in the logs on all instances.</p>\n</blockquote>\n</aside>\n<p>On all 6 instances? Are there some of these instances that don\u2019t have large <code>log-*</code> files? Also, I\u2019d like more details about the disk errors you are encountering.</p>\n<aside class=\"quote no-group\" data-username=\"brk0v\" data-post=\"9\" data-topic=\"483\">\n<div class=\"title\">\n<div class=\"quote-controls\"></div>\n<img loading=\"lazy\" alt=\"\" width=\"24\" height=\"24\" src=\"https://sea1.discourse-cdn.com/foundationdb/user_avatar/forums.foundationdb.org/brk0v/48/173_2.png\" class=\"avatar\"> brk0v:</div>\n<blockquote>\n<p>So this file is a WAL for a storage server, isn\u2019t it? And all writes go through this file (append?), and then apply to the main sqllite db?</p>\n</blockquote>\n</aside>\n<p>Not exactly. The storage servers do actually have a WAL in the <code>ssd</code> storage engine (e.g. see your file <code>storage-ca2be1f34b74669e2a00a347290db311.sqlite-wal</code>). The transaction logs are part of the cluster\u2019s transaction authority and are the component that make data durable during a commit. They do typically write data to an append-only log, and there is an asynchronous process that moves data from the logs to the storage servers. The logs typically serve data to the storage servers from memory rather than the disk files, however, and the <code>logqueue-*</code> files on disk are only used for recovery. There is also no particular relation in the counts of logs and storage servers in a cluster.</p>\n<p>The files that are getting large in your case are not the append-only files, though. Instead, when a log has lots of data that hasn\u2019t been read by some storage server(s), it eventually must flush it from memory into another on disk data structure (in this case, a B-tree).</p>\n<aside class=\"quote no-group\" data-username=\"brk0v\" data-post=\"9\" data-topic=\"483\">\n<div class=\"title\">\n<div class=\"quote-controls\"></div>\n<img loading=\"lazy\" alt=\"\" width=\"24\" height=\"24\" src=\"https://sea1.discourse-cdn.com/foundationdb/user_avatar/forums.foundationdb.org/brk0v/48/173_2.png\" class=\"avatar\"> brk0v:</div>\n<blockquote>\n<p>Yes, but the thing is I have a limited time window, so I need to import data as fast as I can.</p>\n</blockquote>\n</aside>\n<p>If you are saturating the cluster (i.e. trying to write more than its max throughput), then you can turn down the write rate without impacting actual throughput. For example, if the cluster is only able to take 10MB/s of writes and you are trying to write 20MB/s, then the actual throughput is only going to be 10MB/s. You can reduce how much you are trying to write to 10MB/s and you\u2019ll still be writing 10MB/s, but now you\u2019ll also improve your latencies and potentially reduce the stress being applied to various parts of the cluster. Normally, we would recommend running a cluster below a saturating level, though I can understand wanting to get maximum throughput for a bulk-load situation when the cluster is not otherwise in use.</p>\n<aside class=\"quote no-group\" data-username=\"brk0v\" data-post=\"9\" data-topic=\"483\">\n<div class=\"title\">\n<div class=\"quote-controls\"></div>\n<img loading=\"lazy\" alt=\"\" width=\"24\" height=\"24\" src=\"https://sea1.discourse-cdn.com/foundationdb/user_avatar/forums.foundationdb.org/brk0v/48/173_2.png\" class=\"avatar\"> brk0v:</div>\n<blockquote>\n<p>And for doing this I need to start over with a bigger memory limit and smaller number of fdbserver processes for saving disk space for transaction logs, if I understand right how fdb works with data.</p>\n</blockquote>\n</aside>\n<p>Normally you shouldn\u2019t need a bigger memory limit. Without knowing why the processes are failing, it\u2019s hard for me to say whether or not that will help. It\u2019s not clear yet why the process is using so much memory and how much it\u2019s actually going to use. However, if it is using excessive memory that sounds like a bug and it\u2019s something we\u2019ll want to address.</p>\n<p>EDIT: Sorry, I got interrupted before I could finish this thought.</p>\n<p>You shouldn\u2019t need to reduce the number of storage processes in your cluster. The total storage space used by the storage servers shouldn\u2019t really change much with the number of storage instances, and if you are saturating and reduce your write rate, it can reduce the amount of disk space used by the logs. One thing you can do (and that we recommend for production deployments) is to separate the logs and storage servers onto separate disks. You would do this by setting up some processes in your cluster to run on separate disks and configure their process class (e.g. by setting <code>class=transaction</code> in <code>foundationdb.conf</code>). This is primarily beneficial not for space reasons, but for performance. The log processes fsync frequently, and this can impact the performance of reads from the storage servers. Granted this matters less while you are running a write-only workload, but it\u2019s good general advice.</p>",
        "post_number": 10,
        "post_type": 1,
        "posts_count": 17,
        "updated_at": "2018-06-04T19:25:31.044Z",
        "reply_count": 1,
        "reply_to_post_number": 9,
        "quote_count": 1,
        "incoming_link_count": 1,
        "reads": 74,
        "readers_count": 73,
        "score": 24.8,
        "yours": false,
        "topic_id": 483,
        "topic_slug": "segmentation-fault-error-and-broken-cluster",
        "display_username": "A.J. Beamon",
        "primary_group_name": null,
        "flair_name": null,
        "flair_url": null,
        "flair_bg_color": null,
        "flair_color": null,
        "flair_group_id": null,
        "badges_granted": [],
        "version": 2,
        "can_edit": false,
        "can_delete": false,
        "can_recover": false,
        "can_see_hidden_post": false,
        "can_wiki": false,
        "read": true,
        "user_title": null,
        "bookmarked": false,
        "actions_summary": [],
        "moderator": false,
        "admin": true,
        "staff": true,
        "user_id": 12,
        "hidden": false,
        "trust_level": 4,
        "deleted_at": null,
        "user_deleted": false,
        "edit_reason": null,
        "can_view_edit_history": true,
        "wiki": false,
        "post_url": "/t/segmentation-fault-error-and-broken-cluster/483/10",
        "can_accept_answer": false,
        "can_unaccept_answer": false,
        "accepted_answer": false,
        "topic_accepted_answer": null
      },
      {
        "id": 1387,
        "name": "Viacheslav Biriukov",
        "username": "brk0v",
        "avatar_template": "/user_avatar/forums.foundationdb.org/brk0v/{size}/173_2.png",
        "created_at": "2018-06-05T10:49:48.853Z",
        "cooked": "<aside class=\"quote no-group\" data-username=\"ajbeamon\" data-post=\"10\" data-topic=\"483\">\n<div class=\"title\">\n<div class=\"quote-controls\"></div>\n<img loading=\"lazy\" alt=\"\" width=\"24\" height=\"24\" src=\"https://sea1.discourse-cdn.com/foundationdb/user_avatar/forums.foundationdb.org/ajbeamon/48/13_2.png\" class=\"avatar\"> ajbeamon:</div>\n<blockquote>\n<p>On all 6 instances? Are there some of these instances that don\u2019t have large <code>log-*</code> files? Also, I\u2019d like more details about the disk errors you are encountering.</p>\n</blockquote>\n</aside>\n<p>2 machines have OutOfMemory errors in the logs for each port (in my case 4500 and 4501). And by the way I see these errors in today\u2019s logs.<br>\n1 server doesn\u2019t have OOM errors in logs, but today it\u2019s run out of disk space <strong>without any write load</strong>. Other strange thing is a directory list for this server data dir:</p>\n<pre><code class=\"lang-auto\">$ ls -la /var/lib/foundationdb/data/4501\n</code></pre>\n<aside class=\"onebox githubgist\" data-onebox-src=\"https://gist.github.com/brk0v/e97bf5650503c1924618ffeefea2dd39\">\n  <header class=\"source\">\n\n      <a href=\"https://gist.github.com/brk0v/e97bf5650503c1924618ffeefea2dd39\" target=\"_blank\" rel=\"noopener nofollow ugc\">gist.github.com</a>\n  </header>\n\n  <article class=\"onebox-body\">\n    <h4><a href=\"https://gist.github.com/brk0v/e97bf5650503c1924618ffeefea2dd39\" target=\"_blank\" rel=\"noopener nofollow ugc\">https://gist.github.com/brk0v/e97bf5650503c1924618ffeefea2dd39</a></h4>\n\n  <h5>gistfile1.txt</h5>\n  <pre><code class=\"Text\">drwxr-xr-x 2 foundationdb foundationdb        20480 Jun  5 00:00 .\ndrwxr-xr-x 3 foundationdb foundationdb           18 Jun  5 09:53 ..\n-rw---S--- 1 foundationdb foundationdb            0 Jun  1 23:59 log-074eb3bb8df2a50c5cd3a5befe331450.sqlite-wal\n-rw---S--- 1 foundationdb foundationdb            0 Jun  1 23:59 log-074eb3bb8df2a50c5cd3a5befe331450.sqlite.part\n-rw---S--- 1 foundationdb foundationdb            0 Jun  3 23:58 log-0dbd471df97919da08e201247c1009d2.sqlite-wal\n-rw---S--- 1 foundationdb foundationdb            0 Jun  3 23:58 log-0dbd471df97919da08e201247c1009d2.sqlite.part\n-rw---S--- 1 foundationdb foundationdb 134043140096 Jun  5 09:47 log-148afbbca8e140c6d1ed3e70bd19dc20.sqlite\n-rw---S--- 1 foundationdb foundationdb     49188864 Jun  4 20:18 log-148afbbca8e140c6d1ed3e70bd19dc20.sqlite-wal\n-rw---S--- 1 foundationdb foundationdb     24322048 Jun  5 09:47 log-15a1c8a2bd7bce72d7eb369aa122e8f5.sqlite\n-rw---S--- 1 foundationdb foundationdb      4632576 Jun  4 10:25 log-15a1c8a2bd7bce72d7eb369aa122e8f5.sqlite-wal</code></pre>\n    This file has been truncated. <a href=\"https://gist.github.com/brk0v/e97bf5650503c1924618ffeefea2dd39\" target=\"_blank\" rel=\"noopener nofollow ugc\">show original</a>\n\n<p>\n</p>\n\n  </article>\n\n  <div class=\"onebox-metadata\">\n    \n    \n  </div>\n\n  <div style=\"clear: both\"></div>\n</aside>\n\n<p>A lot of 0 size files and second big log file.</p>\n<aside class=\"quote no-group\" data-username=\"ajbeamon\" data-post=\"10\" data-topic=\"483\">\n<div class=\"title\">\n<div class=\"quote-controls\"></div>\n<img loading=\"lazy\" alt=\"\" width=\"24\" height=\"24\" src=\"https://sea1.discourse-cdn.com/foundationdb/user_avatar/forums.foundationdb.org/ajbeamon/48/13_2.png\" class=\"avatar\"> ajbeamon:</div>\n<blockquote>\n<p>The files that are getting large in your case are not the append-only files, though. Instead, when a log has lots of data that hasn\u2019t been read by some storage server(s), it eventually must flush it from memory into another on disk data structure (in this case, a B-tree).</p>\n</blockquote>\n</aside>\n<p>Is this B-tree file used for answering to requests? If I send get command, will I get a value for key from this log-file-data-structure?</p>\n<aside class=\"quote no-group\" data-username=\"ajbeamon\" data-post=\"10\" data-topic=\"483\">\n<div class=\"title\">\n<div class=\"quote-controls\"></div>\n<img loading=\"lazy\" alt=\"\" width=\"24\" height=\"24\" src=\"https://sea1.discourse-cdn.com/foundationdb/user_avatar/forums.foundationdb.org/ajbeamon/48/13_2.png\" class=\"avatar\"> ajbeamon:</div>\n<blockquote>\n<p>Normally, we would recommend running a cluster below a saturating level, though I can understand wanting to get maximum throughput for a bulk-load situation when the cluster is not otherwise in use.</p>\n</blockquote>\n</aside>\n<p>For getting my saturating level I should use status in fdbcli and read the status of the storage, right? There is no other benchmark tools?<br>\nFrom golang program I don\u2019t see any ways to understand whether my cluster is already saturated or not.</p>\n<p>UPDATE: found a key for reading status: <code>\\xff\\xff/status/json</code></p>\n<aside class=\"quote no-group\" data-username=\"ajbeamon\" data-post=\"10\" data-topic=\"483\">\n<div class=\"title\">\n<div class=\"quote-controls\"></div>\n<img loading=\"lazy\" alt=\"\" width=\"24\" height=\"24\" src=\"https://sea1.discourse-cdn.com/foundationdb/user_avatar/forums.foundationdb.org/ajbeamon/48/13_2.png\" class=\"avatar\"> ajbeamon:</div>\n<blockquote>\n<p>However, if it is using excessive memory that sounds like a bug and it\u2019s something we\u2019ll want to address.</p>\n</blockquote>\n</aside>\n<p>Yes, from my point of view there is a bug. Looks like FoundationDB has a memory leak in saturated<br>\ncircumstances.</p>\n<p>Other thing that I want to emphasise is that API lets you set data with a bigger rate, that it could handle. From producer\u2019s side I successfully set all my keys/values. But after a while I realized that cluster is saturated, can\u2019t rebalance data and <strong>infinitely restarting</strong> with internal OOM breaking things and using additional disk space.</p>\n<aside class=\"quote no-group\" data-username=\"ajbeamon\" data-post=\"10\" data-topic=\"483\">\n<div class=\"title\">\n<div class=\"quote-controls\"></div>\n<img loading=\"lazy\" alt=\"\" width=\"24\" height=\"24\" src=\"https://sea1.discourse-cdn.com/foundationdb/user_avatar/forums.foundationdb.org/ajbeamon/48/13_2.png\" class=\"avatar\"> ajbeamon:</div>\n<blockquote>\n<p>One thing you can do (and that we recommend for production deployments) is to separate the logs and storage servers onto separate disks. You would do this by setting up some processes in your cluster to run on separate disks and configure their process class (e.g. by setting <code>class=transaction</code> in <code>foundationdb.conf</code> ).</p>\n</blockquote>\n</aside>\n<p>But anyway I need storage server on this server, right? It\u2019s not clear this sentence  about classes. How many of them should I use in a case of 3 node cluster and double ssd storage?</p>",
        "post_number": 11,
        "post_type": 1,
        "posts_count": 17,
        "updated_at": "2018-06-05T13:07:39.298Z",
        "reply_count": 1,
        "reply_to_post_number": 10,
        "quote_count": 1,
        "incoming_link_count": 1,
        "reads": 72,
        "readers_count": 71,
        "score": 24.4,
        "yours": false,
        "topic_id": 483,
        "topic_slug": "segmentation-fault-error-and-broken-cluster",
        "display_username": "Viacheslav Biriukov",
        "primary_group_name": null,
        "flair_name": null,
        "flair_url": null,
        "flair_bg_color": null,
        "flair_color": null,
        "flair_group_id": null,
        "badges_granted": [],
        "version": 3,
        "can_edit": false,
        "can_delete": false,
        "can_recover": false,
        "can_see_hidden_post": false,
        "can_wiki": false,
        "link_counts": [
          {
            "url": "https://gist.github.com/brk0v/e97bf5650503c1924618ffeefea2dd39",
            "internal": false,
            "reflection": false,
            "title": "log \u00b7 GitHub",
            "clicks": 2
          }
        ],
        "read": true,
        "user_title": null,
        "bookmarked": false,
        "actions_summary": [],
        "moderator": false,
        "admin": false,
        "staff": false,
        "user_id": 211,
        "hidden": false,
        "trust_level": 1,
        "deleted_at": null,
        "user_deleted": false,
        "edit_reason": null,
        "can_view_edit_history": true,
        "wiki": false,
        "post_url": "/t/segmentation-fault-error-and-broken-cluster/483/11",
        "can_accept_answer": false,
        "can_unaccept_answer": false,
        "accepted_answer": false,
        "topic_accepted_answer": null
      },
      {
        "id": 1390,
        "name": "A.J. Beamon",
        "username": "ajbeamon",
        "avatar_template": "/user_avatar/forums.foundationdb.org/ajbeamon/{size}/13_2.png",
        "created_at": "2018-06-05T16:06:44.873Z",
        "cooked": "<aside class=\"quote no-group\" data-username=\"brk0v\" data-post=\"11\" data-topic=\"483\">\n<div class=\"title\">\n<div class=\"quote-controls\"></div>\n<img loading=\"lazy\" alt=\"\" width=\"24\" height=\"24\" src=\"https://sea1.discourse-cdn.com/foundationdb/user_avatar/forums.foundationdb.org/brk0v/48/173_2.png\" class=\"avatar\"> brk0v:</div>\n<blockquote>\n<p>2 machines have OutOfMemory errors in the logs for each port (in my case 4500 and 4501). And by the way I see these errors in today\u2019s logs.</p>\n</blockquote>\n</aside>\n<p>What about the disk IO errors? I\u2019d like to get an idea what the IO errors were to form a more complete picture of what happened.</p>\n<aside class=\"quote no-group\" data-username=\"brk0v\" data-post=\"11\" data-topic=\"483\">\n<div class=\"title\">\n<div class=\"quote-controls\"></div>\n<img loading=\"lazy\" alt=\"\" width=\"24\" height=\"24\" src=\"https://sea1.discourse-cdn.com/foundationdb/user_avatar/forums.foundationdb.org/brk0v/48/173_2.png\" class=\"avatar\"> brk0v:</div>\n<blockquote>\n<p>1 server doesn\u2019t have OOM errors in logs, but today it\u2019s run out of disk space <strong>without any write load</strong> . Other strange thing is a directory list for this server data dir:</p>\n</blockquote>\n</aside>\n<p>Are there any <code>Severity=\"40\"</code> events in this process\u2019s logs? The space is probably being used trying to recover the cluster, not because it\u2019s taking writes, so we\u2019d want to figure out why recovery is failing. You say this host isn\u2019t having memory issues, is it having disk issues?</p>\n<aside class=\"quote no-group\" data-username=\"brk0v\" data-post=\"11\" data-topic=\"483\">\n<div class=\"title\">\n<div class=\"quote-controls\"></div>\n<img loading=\"lazy\" alt=\"\" width=\"24\" height=\"24\" src=\"https://sea1.discourse-cdn.com/foundationdb/user_avatar/forums.foundationdb.org/brk0v/48/173_2.png\" class=\"avatar\"> brk0v:</div>\n<blockquote>\n<p>Is this B-tree file used for answering to requests? If I send get command, will I get a value for key from this log-file-data-structure?</p>\n</blockquote>\n</aside>\n<p>No, reads are done from the storage servers. The storage servers get their data from the logs, and typically this data is served straight out of memory. If we have to spill some data from memory onto disk (into this B-tree for the <code>ssd</code> storage engine), then the log will serve the data out of the B-tree instead.</p>\n<aside class=\"quote no-group\" data-username=\"brk0v\" data-post=\"11\" data-topic=\"483\">\n<div class=\"title\">\n<div class=\"quote-controls\"></div>\n<img loading=\"lazy\" alt=\"\" width=\"24\" height=\"24\" src=\"https://sea1.discourse-cdn.com/foundationdb/user_avatar/forums.foundationdb.org/brk0v/48/173_2.png\" class=\"avatar\"> brk0v:</div>\n<blockquote>\n<p>For getting my saturating level I should use status in fdbcli and read the status of the storage, right? There is no other benchmark tools?<br>\nFrom golang program I don\u2019t see any ways to understand whether my cluster is already saturated or not.</p>\n<p>UPDATE: found a key for reading status: <code>\\xff\\xff/status/json</code></p>\n</blockquote>\n</aside>\n<p>At the moment, my recommendation is to test your cluster and measure empirically how much it\u2019s able to get done running your workload. You can do this either measuring how much work you are doing in your client or by looking at some of the status metrics. Once you have a good idea of this, I would then run at some level below the saturation point (for a bulk-write scenario where no one else is using the database, maybe a high percentage of saturation, like 80%, and in other cases maybe 50% or less). If you instead your goal is to achieve a certain amount of throughput, then you can increase the size of your cluster (and/or configure more logs, proxies, or resolvers) until that throughput can be comfortably achieved. I think trying to read the status output in your program and adapt your workload to it might prove a bit tricky to make work well in general.</p>\n<p>There is a proposed feature that will make it easier to set up what we call batch workloads to run at higher rates. These run at a lower priority and the goal is to make them automatically shut off at a point lower than saturation. See <a href=\"https://github.com/apple/foundationdb/issues/377\" class=\"inline-onebox\">Batch priority enhancements \u00b7 Issue #377 \u00b7 apple/foundationdb \u00b7 GitHub</a>.</p>\n<aside class=\"quote no-group\" data-username=\"brk0v\" data-post=\"11\" data-topic=\"483\">\n<div class=\"title\">\n<div class=\"quote-controls\"></div>\n<img loading=\"lazy\" alt=\"\" width=\"24\" height=\"24\" src=\"https://sea1.discourse-cdn.com/foundationdb/user_avatar/forums.foundationdb.org/brk0v/48/173_2.png\" class=\"avatar\"> brk0v:</div>\n<blockquote>\n<p>Yes, from my point of view there is a bug. Looks like FoundationDB has a memory leak in saturated<br>\ncircumstances.</p>\n</blockquote>\n</aside>\n<p>It\u2019s not clear exactly what the problem is here. For example, rather than a memory leak, it may be that it takes a lot of memory to recover from large log files. It\u2019s also not yet clear if the disk IO errors factor into this at all. At any rate, as I mentioned, this is not the intended behavior.</p>\n<aside class=\"quote no-group\" data-username=\"brk0v\" data-post=\"11\" data-topic=\"483\">\n<div class=\"title\">\n<div class=\"quote-controls\"></div>\n<img loading=\"lazy\" alt=\"\" width=\"24\" height=\"24\" src=\"https://sea1.discourse-cdn.com/foundationdb/user_avatar/forums.foundationdb.org/brk0v/48/173_2.png\" class=\"avatar\"> brk0v:</div>\n<blockquote>\n<p>Other thing that I want to emphasise is that API lets you set data with a bigger rate, that it could handle.</p>\n</blockquote>\n</aside>\n<p>The cluster uses something we call Ratekeeper to limit how much work you are doing, and it does so by introducing latency at the start of a transaction (specifically, when getting a read version). There are some ways you can saturate the cluster that Ratekeeper isn\u2019t aware of (e.g. by having too much work for the proxies), and there are also some ways in which Ratekeeper tries to balance multiple goals.</p>\n<p>For example, we allow the storage servers in one fault domain to fall arbitrarily far behind if they can\u2019t keep up. Ratekeeper could choose to reduce the number of transactions it is willing to start to prevent these storage servers from falling behind, but then we could run into problems with a single slow storage server impacting the performance of an entire cluster. Normally, we\u2019ve seen the current behavior work pretty well because of the way load gets balanced in the cluster. However, it may be that in very small clusters some processes can experience significantly more load than others and then be allowed to fall behind, requiring more disk space on the logs.</p>\n<aside class=\"quote no-group\" data-username=\"brk0v\" data-post=\"11\" data-topic=\"483\">\n<div class=\"title\">\n<div class=\"quote-controls\"></div>\n<img loading=\"lazy\" alt=\"\" width=\"24\" height=\"24\" src=\"https://sea1.discourse-cdn.com/foundationdb/user_avatar/forums.foundationdb.org/brk0v/48/173_2.png\" class=\"avatar\"> brk0v:</div>\n<blockquote>\n<p>can\u2019t rebalance data and <strong>infinitely restarting</strong> with internal OOM breaking things and using additional disk space</p>\n</blockquote>\n</aside>\n<p>We\u2019ve established that there is likely some bug here that causes high memory usage in some scenario that we haven\u2019t quite identified, so I\u2019m not sure I would describe this as the API letting you do this so much as it being a situation where things aren\u2019t working as intended.</p>\n<aside class=\"quote no-group\" data-username=\"brk0v\" data-post=\"11\" data-topic=\"483\">\n<div class=\"title\">\n<div class=\"quote-controls\"></div>\n<img loading=\"lazy\" alt=\"\" width=\"24\" height=\"24\" src=\"https://sea1.discourse-cdn.com/foundationdb/user_avatar/forums.foundationdb.org/brk0v/48/173_2.png\" class=\"avatar\"> brk0v:</div>\n<blockquote>\n<p>But anyway I need storage server on this server, right? It\u2019s not clear this sentence about classes. How many of them should I use in a case of 3 node cluster and double ssd storage?</p>\n</blockquote>\n</aside>\n<p>It is not required to have storage servers on every node. By default, a cluster has a number of logs equal to its replication, so in double it would have 2 logs. If you are going to go the route of configuring some processes to act specifically as logs, then I would have at least 3 processes configured as transaction class so that you have a backup if one fails. In triple replication, I would have 5 (3 + 2 backup). It\u2019s also possible to configure your cluster to run more logs to support a higher write throughput (e.g. using <code>configure logs=8</code> in fdbcli), in which case you would want to have that many transaction class processes, plus some backups.</p>",
        "post_number": 12,
        "post_type": 1,
        "posts_count": 17,
        "updated_at": "2018-06-05T16:06:44.873Z",
        "reply_count": 1,
        "reply_to_post_number": 11,
        "quote_count": 1,
        "incoming_link_count": 2,
        "reads": 64,
        "readers_count": 63,
        "score": 27.8,
        "yours": false,
        "topic_id": 483,
        "topic_slug": "segmentation-fault-error-and-broken-cluster",
        "display_username": "A.J. Beamon",
        "primary_group_name": null,
        "flair_name": null,
        "flair_url": null,
        "flair_bg_color": null,
        "flair_color": null,
        "flair_group_id": null,
        "badges_granted": [],
        "version": 1,
        "can_edit": false,
        "can_delete": false,
        "can_recover": false,
        "can_see_hidden_post": false,
        "can_wiki": false,
        "link_counts": [
          {
            "url": "https://github.com/apple/foundationdb/issues/377",
            "internal": false,
            "reflection": false,
            "title": "Batch priority enhancements \u00b7 Issue #377 \u00b7 apple/foundationdb \u00b7 GitHub",
            "clicks": 3
          }
        ],
        "read": true,
        "user_title": null,
        "bookmarked": false,
        "actions_summary": [],
        "moderator": false,
        "admin": true,
        "staff": true,
        "user_id": 12,
        "hidden": false,
        "trust_level": 4,
        "deleted_at": null,
        "user_deleted": false,
        "edit_reason": null,
        "can_view_edit_history": true,
        "wiki": false,
        "post_url": "/t/segmentation-fault-error-and-broken-cluster/483/12",
        "can_accept_answer": false,
        "can_unaccept_answer": false,
        "accepted_answer": false,
        "topic_accepted_answer": null
      },
      {
        "id": 1391,
        "name": "Viacheslav Biriukov",
        "username": "brk0v",
        "avatar_template": "/user_avatar/forums.foundationdb.org/brk0v/{size}/173_2.png",
        "created_at": "2018-06-05T17:53:20.188Z",
        "cooked": "<aside class=\"quote no-group\" data-username=\"ajbeamon\" data-post=\"12\" data-topic=\"483\">\n<div class=\"title\">\n<div class=\"quote-controls\"></div>\n<img loading=\"lazy\" alt=\"\" width=\"24\" height=\"24\" src=\"https://sea1.discourse-cdn.com/foundationdb/user_avatar/forums.foundationdb.org/ajbeamon/48/13_2.png\" class=\"avatar\"> ajbeamon:</div>\n<blockquote>\n<p>What about the disk IO errors? I\u2019d like to get an idea what the IO errors were to form a more complete picture of what happened.</p>\n</blockquote>\n</aside>\n<p>Now I can see only \u201cNo space left on device\u201d errors. But I think, it\u2019s not a cause. My data set is about 40GB, as I mentioned before.</p>\n<pre><code class=\"lang-auto\">&lt;Event Severity=\"10\" Time=\"1528154524.618570\" Type=\"AsyncFileKAIOOpenFailed\" Machine=\"129.168.1.100:4500\" ID=\"0000000000000000\" Filename=\"/var/lib/foundationdb/data/4500/logqueue-8b2b67814ccc537bc3635f6bae188ff4-0.fdq\" Flags=\"f0006\" OSFlags=\"4242\" mode=\"02600\" Error=\"io_error\" ErrorDescription=\"Disk i/o operation failed\" ErrorCode=\"1510\" UnixErrorCode=\"1c\" UnixError=\"No space left on device\" logGroup=\"default\"/&gt;\n</code></pre>\n<aside class=\"quote no-group\" data-username=\"ajbeamon\" data-post=\"12\" data-topic=\"483\">\n<div class=\"title\">\n<div class=\"quote-controls\"></div>\n<img loading=\"lazy\" alt=\"\" width=\"24\" height=\"24\" src=\"https://sea1.discourse-cdn.com/foundationdb/user_avatar/forums.foundationdb.org/ajbeamon/48/13_2.png\" class=\"avatar\"> ajbeamon:</div>\n<blockquote>\n<p>Are there any <code>Severity=\"40\"</code> events in this process\u2019s logs?</p>\n</blockquote>\n</aside>\n<p>I have logs with  <code>Severity=\"40\"</code> but they all after above space issues.</p>\n<p>I\u2019m going to update setting for holding more logs and restart my load process to reproduce the issue. I\u2019ve done it before with 5.1 version.</p>\n<aside class=\"quote no-group quote-modified\" data-username=\"ajbeamon\" data-post=\"12\" data-topic=\"483\">\n<div class=\"title\">\n<div class=\"quote-controls\"></div>\n<img loading=\"lazy\" alt=\"\" width=\"24\" height=\"24\" src=\"https://sea1.discourse-cdn.com/foundationdb/user_avatar/forums.foundationdb.org/ajbeamon/48/13_2.png\" class=\"avatar\"> ajbeamon:</div>\n<blockquote>\n<p>\u2026 is it having disk issues</p>\n</blockquote>\n</aside>\n<p>I don\u2019t see any errors in logs and dmesg.</p>\n<aside class=\"quote no-group\" data-username=\"ajbeamon\" data-post=\"12\" data-topic=\"483\">\n<div class=\"title\">\n<div class=\"quote-controls\"></div>\n<img loading=\"lazy\" alt=\"\" width=\"24\" height=\"24\" src=\"https://sea1.discourse-cdn.com/foundationdb/user_avatar/forums.foundationdb.org/ajbeamon/48/13_2.png\" class=\"avatar\"> ajbeamon:</div>\n<blockquote>\n<p>No, reads are done from the storage servers. The storage servers get their data from the logs, and typically this data is served straight out of memory. If we have to spill some data from memory onto disk (into this B-tree for the <code>ssd</code> storage engine), then the log will serve the data out of the B-tree instea</p>\n</blockquote>\n</aside>\n<p>Mmm\u2026 Sorry for architecture question, I\u2019ve read <a href=\"https://github.com/apple/foundationdb/blob/master/documentation/sphinx/source/kv-architecture.rst\" rel=\"noopener nofollow ugc\">https://github.com/apple/foundationdb/blob/master/documentation/sphinx/source/kv-architecture.rst</a>, but still want to clarify commit path and your comment.</p>\n<p>So with a slow disk and/or high write rate, I can get in a situation, where I successfully set a key/value pair into a saturated cluster. But can\u2019t get key from the storage servers in the next transaction? Or the first transaction returns no errors only if the storage engines already got all changes?</p>\n<aside class=\"quote no-group\" data-username=\"ajbeamon\" data-post=\"12\" data-topic=\"483\">\n<div class=\"title\">\n<div class=\"quote-controls\"></div>\n<img loading=\"lazy\" alt=\"\" width=\"24\" height=\"24\" src=\"https://sea1.discourse-cdn.com/foundationdb/user_avatar/forums.foundationdb.org/ajbeamon/48/13_2.png\" class=\"avatar\"> ajbeamon:</div>\n<blockquote>\n<p>There is a proposed feature that will make it easier to set up what we call batch workloads to run at higher rates. These run at a lower priority and the goal is to make them automatically shut off at a point lower than saturation. See <a href=\"https://github.com/apple/foundationdb/issues/377\" class=\"inline-onebox\" rel=\"noopener nofollow ugc\">Batch priority enhancements \u00b7 Issue #377 \u00b7 apple/foundationdb \u00b7 GitHub</a>.</p>\n</blockquote>\n</aside>\n<p>Interesting, thank you for the link.</p>\n<aside class=\"quote no-group\" data-username=\"ajbeamon\" data-post=\"12\" data-topic=\"483\">\n<div class=\"title\">\n<div class=\"quote-controls\"></div>\n<img loading=\"lazy\" alt=\"\" width=\"24\" height=\"24\" src=\"https://sea1.discourse-cdn.com/foundationdb/user_avatar/forums.foundationdb.org/ajbeamon/48/13_2.png\" class=\"avatar\"> ajbeamon:</div>\n<blockquote>\n<p>At any rate, as I mentioned, this is not the intended behavior.</p>\n</blockquote>\n</aside>\n<p>As I mentioned before, I\u2019ll achieve more logs during next try of load.</p>\n<aside class=\"quote no-group\" data-username=\"ajbeamon\" data-post=\"12\" data-topic=\"483\">\n<div class=\"title\">\n<div class=\"quote-controls\"></div>\n<img loading=\"lazy\" alt=\"\" width=\"24\" height=\"24\" src=\"https://sea1.discourse-cdn.com/foundationdb/user_avatar/forums.foundationdb.org/ajbeamon/48/13_2.png\" class=\"avatar\"> ajbeamon:</div>\n<blockquote>\n<p>It is not required to have storage servers on every node. By default, a cluster has a number of logs equal to its replication, so in double it would have 2 logs. If you are going to go the route of configuring some processes to act specifically as logs, then I would have at least 3 processes configured as transaction class so that you have a backup if one fails. In triple replication, I would have 5 (3 + 2 backup). It\u2019s also possible to configure your cluster to run more logs to support a higher write throughput (e.g. using <code>configure logs=8</code> in fdbcli), in which case you would want to have that many transaction class processes, plus some backups.</p>\n</blockquote>\n</aside>\n<p>So if I configure some process with a log class, these processes could not do any other work and could not be promoted as a proxy for instance, right?</p>",
        "post_number": 13,
        "post_type": 1,
        "posts_count": 17,
        "updated_at": "2018-06-05T17:53:20.188Z",
        "reply_count": 1,
        "reply_to_post_number": 12,
        "quote_count": 1,
        "incoming_link_count": 6,
        "reads": 54,
        "readers_count": 53,
        "score": 45.8,
        "yours": false,
        "topic_id": 483,
        "topic_slug": "segmentation-fault-error-and-broken-cluster",
        "display_username": "Viacheslav Biriukov",
        "primary_group_name": null,
        "flair_name": null,
        "flair_url": null,
        "flair_bg_color": null,
        "flair_color": null,
        "flair_group_id": null,
        "badges_granted": [],
        "version": 1,
        "can_edit": false,
        "can_delete": false,
        "can_recover": false,
        "can_see_hidden_post": false,
        "can_wiki": false,
        "link_counts": [
          {
            "url": "https://github.com/apple/foundationdb/blob/master/documentation/sphinx/source/kv-architecture.rst",
            "internal": false,
            "reflection": false,
            "title": "foundationdb/kv-architecture.rst at master \u00b7 apple/foundationdb \u00b7 GitHub",
            "clicks": 2
          }
        ],
        "read": true,
        "user_title": null,
        "bookmarked": false,
        "actions_summary": [],
        "moderator": false,
        "admin": false,
        "staff": false,
        "user_id": 211,
        "hidden": false,
        "trust_level": 1,
        "deleted_at": null,
        "user_deleted": false,
        "edit_reason": null,
        "can_view_edit_history": true,
        "wiki": false,
        "post_url": "/t/segmentation-fault-error-and-broken-cluster/483/13",
        "can_accept_answer": false,
        "can_unaccept_answer": false,
        "accepted_answer": false,
        "topic_accepted_answer": null
      },
      {
        "id": 1393,
        "name": "A.J. Beamon",
        "username": "ajbeamon",
        "avatar_template": "/user_avatar/forums.foundationdb.org/ajbeamon/{size}/13_2.png",
        "created_at": "2018-06-05T20:03:27.859Z",
        "cooked": "<aside class=\"quote no-group\" data-username=\"brk0v\" data-post=\"13\" data-topic=\"483\">\n<div class=\"title\">\n<div class=\"quote-controls\"></div>\n<img loading=\"lazy\" alt=\"\" width=\"24\" height=\"24\" src=\"https://sea1.discourse-cdn.com/foundationdb/user_avatar/forums.foundationdb.org/brk0v/48/173_2.png\" class=\"avatar\"> brk0v:</div>\n<blockquote>\n<p>Now I can see only \u201cNo space left on device\u201d errors. But I think, it\u2019s not a cause. My data set is about 40GB, as I mentioned before.</p>\n</blockquote>\n</aside>\n<p>Was the earlier IO error you posted also caused by the disk being out of space? It unfortunately doesn\u2019t say in the SharedTLogFailed event it seems. If so, then I agree it seems like a symptom rather than a cause.</p>\n<aside class=\"quote no-group\" data-username=\"brk0v\" data-post=\"13\" data-topic=\"483\">\n<div class=\"title\">\n<div class=\"quote-controls\"></div>\n<img loading=\"lazy\" alt=\"\" width=\"24\" height=\"24\" src=\"https://sea1.discourse-cdn.com/foundationdb/user_avatar/forums.foundationdb.org/brk0v/48/173_2.png\" class=\"avatar\"> brk0v:</div>\n<blockquote>\n<p>So with a slow disk and/or high write rate, I can get in a situation, where I successfully set a key/value pair into a saturated cluster. But can\u2019t get key from the storage servers in the next transaction? Or the first transaction returns no errors only if the storage engines already got all changes?</p>\n</blockquote>\n</aside>\n<p>When you commit mutations to the database, you get back a response when that data is durable on the logs at the desired replication factor. The data is moved from the logs to the storage servers asynchronously, and this process does not block the commit at all.</p>\n<p>When you start a new transaction after you\u2019ve committed something, your new transaction will be assigned a read version that is at least as large as your recent commit, meaning that your transaction will see the results of that commit. It is possible that the storage servers don\u2019t yet have this version, so if you try to read it from them the read will block waiting for it to arrive or even fail back out to the client with a retryable error (called <code>future_version</code>). In practice, I think it\u2019s rare to have to be subjected to a delay when reading data, although you have reported seeing the <code>future_version</code> error (1009). It may just be more common when saturating the cluster.</p>\n<p>In the case where we allow a single fault domain to fall behind (this requires double or higher replication), then it\u2019s possible that at read time that you try to read from the storage server that is behind. In this case, it will answer quickly to tell you that it has fallen behind and the client will automatically make the request to the another replica that has the data (which Ratekeeper shouldn\u2019t be allowing to fall behind).</p>\n<aside class=\"quote no-group\" data-username=\"brk0v\" data-post=\"13\" data-topic=\"483\">\n<div class=\"title\">\n<div class=\"quote-controls\"></div>\n<img loading=\"lazy\" alt=\"\" width=\"24\" height=\"24\" src=\"https://sea1.discourse-cdn.com/foundationdb/user_avatar/forums.foundationdb.org/brk0v/48/173_2.png\" class=\"avatar\"> brk0v:</div>\n<blockquote>\n<p>So if I configure some process with a log class, these processes could not do any other work and could not be promoted as a proxy for instance, right?</p>\n</blockquote>\n</aside>\n<p>The transaction class processes can actually run some other roles, though it should avoid creating storage roles on them. If you want to separate other types, such as proxies, we recommend also creating processes with the stateless class. See <a href=\"https://apple.github.io/foundationdb/configuration.html?#guidelines-for-setting-process-class\" class=\"inline-onebox\">Configuration \u2014 FoundationDB 7.1</a>, although the numbers here are specific to triple-replicated clusters and assume you are trying to run a largish cluster. It may be more trouble than it\u2019s worth to try to configure these classes on smaller clusters, though you can certainly try it to see if it makes a difference.</p>",
        "post_number": 14,
        "post_type": 1,
        "posts_count": 17,
        "updated_at": "2018-06-05T20:03:27.859Z",
        "reply_count": 1,
        "reply_to_post_number": 13,
        "quote_count": 1,
        "incoming_link_count": 0,
        "reads": 60,
        "readers_count": 59,
        "score": 17.0,
        "yours": false,
        "topic_id": 483,
        "topic_slug": "segmentation-fault-error-and-broken-cluster",
        "display_username": "A.J. Beamon",
        "primary_group_name": null,
        "flair_name": null,
        "flair_url": null,
        "flair_bg_color": null,
        "flair_color": null,
        "flair_group_id": null,
        "badges_granted": [],
        "version": 1,
        "can_edit": false,
        "can_delete": false,
        "can_recover": false,
        "can_see_hidden_post": false,
        "can_wiki": false,
        "link_counts": [
          {
            "url": "https://apple.github.io/foundationdb/configuration.html?#guidelines-for-setting-process-class",
            "internal": false,
            "reflection": false,
            "title": "Configuration \u2014 FoundationDB 5.1",
            "clicks": 1
          }
        ],
        "read": true,
        "user_title": null,
        "bookmarked": false,
        "actions_summary": [],
        "moderator": false,
        "admin": true,
        "staff": true,
        "user_id": 12,
        "hidden": false,
        "trust_level": 4,
        "deleted_at": null,
        "user_deleted": false,
        "edit_reason": null,
        "can_view_edit_history": true,
        "wiki": false,
        "post_url": "/t/segmentation-fault-error-and-broken-cluster/483/14",
        "can_accept_answer": false,
        "can_unaccept_answer": false,
        "accepted_answer": false,
        "topic_accepted_answer": null
      },
      {
        "id": 1402,
        "name": "Viacheslav Biriukov",
        "username": "brk0v",
        "avatar_template": "/user_avatar/forums.foundationdb.org/brk0v/{size}/173_2.png",
        "created_at": "2018-06-06T14:01:36.328Z",
        "cooked": "<aside class=\"quote no-group\" data-username=\"ajbeamon\" data-post=\"14\" data-topic=\"483\">\n<div class=\"title\">\n<div class=\"quote-controls\"></div>\n<img loading=\"lazy\" alt=\"\" width=\"24\" height=\"24\" src=\"https://sea1.discourse-cdn.com/foundationdb/user_avatar/forums.foundationdb.org/ajbeamon/48/13_2.png\" class=\"avatar\"> ajbeamon:</div>\n<blockquote>\n<p>Was the earlier IO error you posted also caused by the disk being out of space? It unfortunately doesn\u2019t say in the SharedTLogFailed event it seems. If so, then I agree it seems like a symptom rather than a cause.</p>\n</blockquote>\n</aside>\n<p>At this time I used a lower write rate: less threads and a smaller bulk chunk for one transaction. Also I set 3 log roles instead of 2 by default for my double replication. So all data was inserted without strange memory and disk usage. But now I see weird behaviour with cluster roles. I think this could be a cause of the issue from my previous tries.</p>\n<p>So I have following roles among my process:</p>\n<pre><code class=\"lang-auto\">    \"address\": \"192.168.1.76:4501:tls\",\n        \"role\": \"master\"\n        \"role\": \"log\"\n        \"role\": \"storage\",\n    \"address\": \"192.168.1.29:4500:tls\",\n        \"role\": \"log\"\n        \"role\": \"storage\",\n    \"address\": \"192.168.1.29:4501:tls\",\n        \"role\": \"storage\",\n        \"role\": \"resolver\"\n    \"address\": \"192.168.1.78:4500:tls\",\n        \"role\": \"log\"\n        \"role\": \"storage\",\n    \"address\": \"192.168.1.76:4500:tls\",\n        \"role\": \"cluster_controller\"\n        \"role\": \"storage\",\n    \"address\": \"192.168.1.78:4501:tls\",\n        \"role\": \"proxy\"\n        \"role\": \"storage\",\n</code></pre>\n<p>And after 10 seconds all roles have been migrated to other processes:</p>\n<pre><code class=\"lang-auto\">\n    \"address\": \"192.168.1.76:4501:tls\",\n        \"role\": \"master\"\n        \"role\": \"log\"\n        \"role\": \"storage\",\n    \"address\": \"192.168.1.29:4500:tls\",\n        \"role\": \"cluster_controller\"\n        \"role\": \"log\"\n        \"role\": \"storage\",\n    \"address\": \"192.168.1.29:4501:tls\",\n        \"role\": \"proxy\"\n        \"role\": \"storage\",\n    \"address\": \"192.168.1.78:4500:tls\",\n        \"role\": \"log\"\n        \"role\": \"storage\",\n    \"address\": \"192.168.1.76:4500:tls\",\n        \"role\": \"proxy\"\n        \"role\": \"storage\",\n    \"address\": \"192.168.1.78:4501:tls\",\n        \"role\": \"storage\",\n        \"role\": \"resolver\"\n</code></pre>\n<p>According to the documentation Cluster Controller is in charge of setting roles. So when I get a new cluster controller I\u2019ll get a whole new topology and abort all current transaction. But I can\u2019t figure out the reason why. I see a lot of <code>SlowTask</code>, <code>TLogQueueCommitSlow</code>  and <code>ConnectionTimeout</code> in the logs.</p>\n<p>Can I increase these timeouts?</p>\n<p>UPDATE: and I see how memory usage is increasing after restart. I think the reason is this frequent role changes.</p>\n<p>UPDATE2: I found following timeout for TLogs:</p>\n<p><a href=\"https://github.com/apple/foundationdb/blob/master/fdbserver/Knobs.cpp#L30\" class=\"onebox\" target=\"_blank\" rel=\"noopener nofollow ugc\">https://github.com/apple/foundationdb/blob/master/fdbserver/Knobs.cpp#L30</a></p>\n<p>What do you think about increasing this one?</p>\n<aside class=\"quote no-group\" data-username=\"ajbeamon\" data-post=\"14\" data-topic=\"483\">\n<div class=\"title\">\n<div class=\"quote-controls\"></div>\n<img loading=\"lazy\" alt=\"\" width=\"24\" height=\"24\" src=\"https://sea1.discourse-cdn.com/foundationdb/user_avatar/forums.foundationdb.org/ajbeamon/48/13_2.png\" class=\"avatar\"> ajbeamon:</div>\n<blockquote>\n<p>future_version</p>\n</blockquote>\n</aside>\n<p>Thank you for clarification, yes I see this retrieable errors time to time.</p>\n<aside class=\"quote no-group\" data-username=\"ajbeamon\" data-post=\"14\" data-topic=\"483\">\n<div class=\"title\">\n<div class=\"quote-controls\"></div>\n<img loading=\"lazy\" alt=\"\" width=\"24\" height=\"24\" src=\"https://sea1.discourse-cdn.com/foundationdb/user_avatar/forums.foundationdb.org/ajbeamon/48/13_2.png\" class=\"avatar\"> ajbeamon:</div>\n<blockquote>\n<p>In the case where we allow a single fault domain to fall behind (this requires double or higher replication), then it\u2019s possible that at read time that you try to read from the storage server that is behind. In this case, it will answer quickly to tell you that it has fallen behind and the client will automatically make the request to the another replica that has the data (which Ratekeeper shouldn\u2019t be allowing to fall behind).</p>\n</blockquote>\n</aside>\n<p>Ok, I see, thank you.</p>\n<p>UPD: Some greps from logs that looks suspicious:</p>\n<pre><code class=\"lang-auto\">&lt;Event Severity=\"10\" Time=\"1528299228.998529\" Type=\"MasterProxyTerminated\" Machine=\"192.168.1.29:4500\" ID=\"ce3a32509802dc79\" Error=\"master_tlog_failed\" ErrorDescription=\"Master terminating because a TLog failed\" ErrorCode=\"1205\" logGroup=\"default\"/&gt;\n\n&lt;Event Severity=\"20\" Time=\"1528299665.950467\" Type=\"clusterWatchDatabaseRetrying\" Machine=\"192.168.1.29:4500\" ID=\"11fbe6492ef4e0f5\" Error=\"no_more_servers\" ErrorDescription=\"Not enough physical servers available\" ErrorCode=\"1008\" logGroup=\"default\"/&gt;\n\n&lt;Event Severity=\"20\" Time=\"1528298683.457009\" Type=\"N2_ReadProbeError\" Machine=\"192.168.1.29:4500\" ID=\"e47fd45a318e7a4c\" Message=\"125\" SuppressedEventCount=\"0\" logGroup=\"default\"/&gt;\n\n&lt;Event Severity=\"10\" Time=\"1528299485.977833\" Type=\"TLSConnectionRecvError\" Machine=\"192.168.1.29:4500\" ID=\"9a01b9f61228f725\" Error=\"connection_failed\" ErrorDescription=\"Network connection failed\" ErrorCode=\"1026\" logGroup=\"default\"/&gt;\n\n&lt;Event Severity=\"10\" Time=\"1528304144.520750\" Type=\"FKBlockFail\" Machine=\"192.168.1.76:4501\" ID=\"dd664403aa073383\" FKID=\"d48d2b6589785ada\" Error=\"operation_cancelled\" ErrorDescription=\"Asynchronous operation cancelled\" ErrorCode=\"1101\" SuppressedEventCount=\"0\" logGroup=\"default\"/&gt;\n\n&lt;Event Severity=\"20\" Time=\"1528304127.760103\" Type=\"FailureMonitorClientSlow\" Machine=\"192.168.1.76:4501\" ID=\"0000000000000000\" Elapsed=\"0.391167\" Expected=\"0.1\" logGroup=\"default\"/&gt;\n</code></pre>",
        "post_number": 15,
        "post_type": 1,
        "posts_count": 17,
        "updated_at": "2018-06-06T17:54:31.984Z",
        "reply_count": 0,
        "reply_to_post_number": 14,
        "quote_count": 1,
        "incoming_link_count": 3,
        "reads": 69,
        "readers_count": 68,
        "score": 28.8,
        "yours": false,
        "topic_id": 483,
        "topic_slug": "segmentation-fault-error-and-broken-cluster",
        "display_username": "Viacheslav Biriukov",
        "primary_group_name": null,
        "flair_name": null,
        "flair_url": null,
        "flair_bg_color": null,
        "flair_color": null,
        "flair_group_id": null,
        "badges_granted": [],
        "version": 6,
        "can_edit": false,
        "can_delete": false,
        "can_recover": false,
        "can_see_hidden_post": false,
        "can_wiki": false,
        "link_counts": [
          {
            "url": "https://github.com/apple/foundationdb/blob/master/fdbserver/Knobs.cpp#L30",
            "internal": false,
            "reflection": false,
            "title": "foundationdb/Knobs.cpp at master \u00b7 apple/foundationdb \u00b7 GitHub",
            "clicks": 3
          }
        ],
        "read": true,
        "user_title": null,
        "bookmarked": false,
        "actions_summary": [],
        "moderator": false,
        "admin": false,
        "staff": false,
        "user_id": 211,
        "hidden": false,
        "trust_level": 1,
        "deleted_at": null,
        "user_deleted": false,
        "edit_reason": null,
        "can_view_edit_history": true,
        "wiki": false,
        "post_url": "/t/segmentation-fault-error-and-broken-cluster/483/15",
        "can_accept_answer": false,
        "can_unaccept_answer": false,
        "accepted_answer": false,
        "topic_accepted_answer": null
      },
      {
        "id": 1404,
        "name": "Sam Pullara",
        "username": "spullara",
        "avatar_template": "/user_avatar/forums.foundationdb.org/spullara/{size}/125_2.png",
        "created_at": "2018-06-06T16:02:55.016Z",
        "cooked": "<p>I think that it is possible to fill a memory engine such that it crashes on restart. The only way I have gotten out of that situation is to increase the memory limit.</p>",
        "post_number": 16,
        "post_type": 1,
        "posts_count": 17,
        "updated_at": "2018-06-06T16:02:55.016Z",
        "reply_count": 0,
        "reply_to_post_number": null,
        "quote_count": 0,
        "incoming_link_count": 0,
        "reads": 66,
        "readers_count": 65,
        "score": 13.2,
        "yours": false,
        "topic_id": 483,
        "topic_slug": "segmentation-fault-error-and-broken-cluster",
        "display_username": "Sam Pullara",
        "primary_group_name": null,
        "flair_name": null,
        "flair_url": null,
        "flair_bg_color": null,
        "flair_color": null,
        "flair_group_id": null,
        "badges_granted": [],
        "version": 1,
        "can_edit": false,
        "can_delete": false,
        "can_recover": false,
        "can_see_hidden_post": false,
        "can_wiki": false,
        "read": true,
        "user_title": null,
        "bookmarked": false,
        "actions_summary": [],
        "moderator": false,
        "admin": false,
        "staff": false,
        "user_id": 156,
        "hidden": false,
        "trust_level": 2,
        "deleted_at": null,
        "user_deleted": false,
        "edit_reason": null,
        "can_view_edit_history": true,
        "wiki": false,
        "post_url": "/t/segmentation-fault-error-and-broken-cluster/483/16",
        "can_accept_answer": false,
        "can_unaccept_answer": false,
        "accepted_answer": false,
        "topic_accepted_answer": null
      },
      {
        "id": 1449,
        "name": "Viacheslav Biriukov",
        "username": "brk0v",
        "avatar_template": "/user_avatar/forums.foundationdb.org/brk0v/{size}/173_2.png",
        "created_at": "2018-06-11T17:31:13.656Z",
        "cooked": "<p>Yes, but additional memory doesn\u2019t fix issue with continuously migration roles among cluster nodes.<br>\nLooks like some timeout issues, but I can\u2019t find the cause.</p>",
        "post_number": 17,
        "post_type": 1,
        "posts_count": 17,
        "updated_at": "2018-06-11T17:31:13.656Z",
        "reply_count": 0,
        "reply_to_post_number": null,
        "quote_count": 0,
        "incoming_link_count": 3,
        "reads": 65,
        "readers_count": 64,
        "score": 28.0,
        "yours": false,
        "topic_id": 483,
        "topic_slug": "segmentation-fault-error-and-broken-cluster",
        "display_username": "Viacheslav Biriukov",
        "primary_group_name": null,
        "flair_name": null,
        "flair_url": null,
        "flair_bg_color": null,
        "flair_color": null,
        "flair_group_id": null,
        "badges_granted": [],
        "version": 1,
        "can_edit": false,
        "can_delete": false,
        "can_recover": false,
        "can_see_hidden_post": false,
        "can_wiki": false,
        "link_counts": [
          {
            "url": "https://forums.foundationdb.org/t/production-deployment/522/2",
            "internal": true,
            "reflection": true,
            "title": "Production deployment",
            "clicks": 6
          }
        ],
        "read": true,
        "user_title": null,
        "bookmarked": false,
        "actions_summary": [],
        "moderator": false,
        "admin": false,
        "staff": false,
        "user_id": 211,
        "hidden": false,
        "trust_level": 1,
        "deleted_at": null,
        "user_deleted": false,
        "edit_reason": null,
        "can_view_edit_history": true,
        "wiki": false,
        "post_url": "/t/segmentation-fault-error-and-broken-cluster/483/17",
        "can_accept_answer": false,
        "can_unaccept_answer": false,
        "accepted_answer": false,
        "topic_accepted_answer": null
      }
    ],
    "stream": [
      1365,
      1368,
      1369,
      1371,
      1372,
      1373,
      1374,
      1376,
      1377,
      1380,
      1387,
      1390,
      1391,
      1393,
      1402,
      1404,
      1449
    ]
  },
  "timeline_lookup": [
    [
      1,
      2700
    ],
    [
      2,
      2699
    ],
    [
      4,
      2697
    ],
    [
      5,
      2696
    ],
    [
      11,
      2695
    ],
    [
      15,
      2694
    ],
    [
      17,
      2689
    ]
  ],
  "suggested_topics": [],
  "tags": [],
  "tags_descriptions": {},
  "fancy_title": "Segmentation fault error and broken cluster",
  "id": 483,
  "title": "Segmentation fault error and broken cluster",
  "posts_count": 17,
  "created_at": "2018-05-31T15:34:28.123Z",
  "views": 4331,
  "reply_count": 12,
  "like_count": 2,
  "last_posted_at": "2018-06-11T17:31:13.656Z",
  "visible": true,
  "closed": false,
  "archived": false,
  "has_summary": false,
  "archetype": "regular",
  "slug": "segmentation-fault-error-and-broken-cluster",
  "category_id": 7,
  "word_count": 10229,
  "deleted_at": null,
  "user_id": 211,
  "featured_link": null,
  "pinned_globally": false,
  "pinned_at": null,
  "pinned_until": null,
  "image_url": null,
  "slow_mode_seconds": 0,
  "draft": null,
  "draft_key": "topic_483",
  "draft_sequence": null,
  "unpinned": null,
  "pinned": false,
  "current_post_number": 1,
  "highest_post_number": 17,
  "deleted_by": null,
  "actions_summary": [
    {
      "id": 4,
      "count": 0,
      "hidden": false,
      "can_act": false
    },
    {
      "id": 8,
      "count": 0,
      "hidden": false,
      "can_act": false
    },
    {
      "id": 10,
      "count": 0,
      "hidden": false,
      "can_act": false
    },
    {
      "id": 7,
      "count": 0,
      "hidden": false,
      "can_act": false
    }
  ],
  "chunk_size": 20,
  "bookmarked": false,
  "topic_timer": null,
  "message_bus_last_id": 0,
  "participant_count": 3,
  "show_read_indicator": false,
  "thumbnails": null,
  "slow_mode_enabled_until": null,
  "tags_disable_ads": false,
  "related_topics": [
    {
      "fancy_title": "Foundationdb 6.2 - fdbserver going out of memory",
      "id": 2080,
      "title": "Foundationdb 6.2 - fdbserver going out of memory",
      "slug": "foundationdb-6-2-fdbserver-going-out-of-memory",
      "posts_count": 10,
      "reply_count": 5,
      "highest_post_number": 10,
      "image_url": null,
      "created_at": "2020-04-20T14:55:39.274Z",
      "last_posted_at": "2020-04-23T04:34:49.858Z",
      "bumped": true,
      "bumped_at": "2020-04-23T04:34:49.858Z",
      "archetype": "regular",
      "unseen": false,
      "pinned": false,
      "unpinned": null,
      "visible": true,
      "closed": false,
      "archived": false,
      "bookmarked": null,
      "liked": null,
      "tags": [],
      "tags_descriptions": {},
      "like_count": 0,
      "views": 1037,
      "category_id": 7,
      "featured_link": null,
      "has_accepted_answer": false,
      "posters": [
        {
          "extras": "latest",
          "description": "Original Poster, Most Recent Poster",
          "user": {
            "id": 714,
            "username": "tuk",
            "name": "",
            "avatar_template": "https://avatars.discourse-cdn.com/v4/letter/t/b5ac83/{size}.png",
            "trust_level": 2
          }
        },
        {
          "extras": null,
          "description": "Frequent Poster",
          "user": {
            "id": 12,
            "username": "ajbeamon",
            "name": "A.J. Beamon",
            "avatar_template": "/user_avatar/forums.foundationdb.org/ajbeamon/{size}/13_2.png",
            "admin": true,
            "trust_level": 4
          }
        },
        {
          "extras": null,
          "description": "Frequent Poster",
          "user": {
            "id": 13,
            "username": "alexmiller",
            "name": "Alex Miller",
            "avatar_template": "/user_avatar/forums.foundationdb.org/alexmiller/{size}/326_2.png",
            "trust_level": 4
          }
        }
      ]
    },
    {
      "fancy_title": "Database unavailable after shutting down a foundationdb node",
      "id": 2113,
      "title": "Database unavailable after shutting down a foundationdb node",
      "slug": "database-unavailable-after-shutting-down-a-foundationdb-node",
      "posts_count": 18,
      "reply_count": 8,
      "highest_post_number": 18,
      "image_url": null,
      "created_at": "2020-05-11T16:09:39.373Z",
      "last_posted_at": "2021-02-05T22:16:50.767Z",
      "bumped": true,
      "bumped_at": "2021-02-05T22:18:40.780Z",
      "archetype": "regular",
      "unseen": false,
      "pinned": false,
      "unpinned": null,
      "visible": true,
      "closed": false,
      "archived": false,
      "bookmarked": null,
      "liked": null,
      "tags": [],
      "tags_descriptions": {},
      "like_count": 3,
      "views": 8569,
      "category_id": 7,
      "featured_link": null,
      "has_accepted_answer": false,
      "posters": [
        {
          "extras": null,
          "description": "Original Poster",
          "user": {
            "id": 714,
            "username": "tuk",
            "name": "",
            "avatar_template": "https://avatars.discourse-cdn.com/v4/letter/t/b5ac83/{size}.png",
            "trust_level": 2
          }
        },
        {
          "extras": null,
          "description": "Frequent Poster",
          "user": {
            "id": 12,
            "username": "ajbeamon",
            "name": "A.J. Beamon",
            "avatar_template": "/user_avatar/forums.foundationdb.org/ajbeamon/{size}/13_2.png",
            "admin": true,
            "trust_level": 4
          }
        },
        {
          "extras": null,
          "description": "Frequent Poster",
          "user": {
            "id": 13,
            "username": "alexmiller",
            "name": "Alex Miller",
            "avatar_template": "/user_avatar/forums.foundationdb.org/alexmiller/{size}/326_2.png",
            "trust_level": 4
          }
        },
        {
          "extras": "latest",
          "description": "Most Recent Poster",
          "user": {
            "id": 810,
            "username": "amanda",
            "name": "Amanda",
            "avatar_template": "https://avatars.discourse-cdn.com/v4/letter/a/67e7ee/{size}.png",
            "trust_level": 2
          }
        }
      ]
    },
    {
      "fancy_title": "FDB out of memory",
      "id": 3460,
      "title": "FDB out of memory",
      "slug": "fdb-out-of-memory",
      "posts_count": 6,
      "reply_count": 2,
      "highest_post_number": 6,
      "image_url": null,
      "created_at": "2022-07-20T03:12:58.094Z",
      "last_posted_at": "2022-07-22T12:33:26.077Z",
      "bumped": true,
      "bumped_at": "2022-07-22T12:54:40.104Z",
      "archetype": "regular",
      "unseen": false,
      "pinned": false,
      "unpinned": null,
      "visible": true,
      "closed": false,
      "archived": false,
      "bookmarked": null,
      "liked": null,
      "tags": [],
      "tags_descriptions": {},
      "like_count": 0,
      "views": 962,
      "category_id": 17,
      "featured_link": null,
      "has_accepted_answer": false,
      "posters": [
        {
          "extras": null,
          "description": "Original Poster",
          "user": {
            "id": 1126,
            "username": "CodingSuen",
            "name": "CodingSuen",
            "avatar_template": "/user_avatar/forums.foundationdb.org/codingsuen/{size}/1367_2.png",
            "trust_level": 1
          }
        },
        {
          "extras": null,
          "description": "Frequent Poster",
          "user": {
            "id": 454,
            "username": "jzhou",
            "name": "Jingyu Zhou",
            "avatar_template": "/user_avatar/forums.foundationdb.org/jzhou/{size}/445_2.png",
            "admin": true,
            "moderator": true,
            "trust_level": 2
          }
        },
        {
          "extras": "latest",
          "description": "Most Recent Poster",
          "user": {
            "id": 164,
            "username": "Imperatorx",
            "name": "",
            "avatar_template": "https://avatars.discourse-cdn.com/v4/letter/i/d2c977/{size}.png",
            "trust_level": 2
          }
        }
      ]
    },
    {
      "fancy_title": "Large spikes in memory usage on storage processes, 6.0.18",
      "id": 2115,
      "title": "Large spikes in memory usage on storage processes, 6.0.18",
      "slug": "large-spikes-in-memory-usage-on-storage-processes-6-0-18",
      "posts_count": 3,
      "reply_count": 1,
      "highest_post_number": 3,
      "image_url": "https://global.discourse-cdn.com/foundationdb/optimized/1X/4c7f8a022ee38e69df8abe772878aff823a76550_2_1024x320.png",
      "created_at": "2020-05-12T19:17:47.329Z",
      "last_posted_at": "2020-05-12T21:58:14.570Z",
      "bumped": true,
      "bumped_at": "2020-05-12T21:58:14.570Z",
      "archetype": "regular",
      "unseen": false,
      "pinned": false,
      "unpinned": null,
      "visible": true,
      "closed": false,
      "archived": false,
      "bookmarked": null,
      "liked": null,
      "tags": [],
      "tags_descriptions": {},
      "like_count": 1,
      "views": 582,
      "category_id": 7,
      "featured_link": null,
      "has_accepted_answer": false,
      "posters": [
        {
          "extras": "latest",
          "description": "Original Poster, Most Recent Poster",
          "user": {
            "id": 490,
            "username": "rjenkins",
            "name": "Ray Jenkins",
            "avatar_template": "/user_avatar/forums.foundationdb.org/rjenkins/{size}/487_2.png",
            "trust_level": 2
          }
        },
        {
          "extras": null,
          "description": "Frequent Poster",
          "user": {
            "id": 12,
            "username": "ajbeamon",
            "name": "A.J. Beamon",
            "avatar_template": "/user_avatar/forums.foundationdb.org/ajbeamon/{size}/13_2.png",
            "admin": true,
            "trust_level": 4
          }
        }
      ]
    },
    {
      "fancy_title": "Cluster tuning cookbook",
      "id": 520,
      "title": "Cluster tuning cookbook",
      "slug": "cluster-tuning-cookbook",
      "posts_count": 27,
      "reply_count": 19,
      "highest_post_number": 27,
      "image_url": null,
      "created_at": "2018-06-19T14:35:25.802Z",
      "last_posted_at": "2019-02-01T12:38:24.733Z",
      "bumped": true,
      "bumped_at": "2019-02-01T12:38:24.733Z",
      "archetype": "regular",
      "unseen": false,
      "pinned": false,
      "unpinned": null,
      "visible": true,
      "closed": false,
      "archived": false,
      "bookmarked": null,
      "liked": null,
      "tags": [],
      "tags_descriptions": {},
      "like_count": 12,
      "views": 8885,
      "category_id": 7,
      "featured_link": null,
      "has_accepted_answer": false,
      "posters": [
        {
          "extras": null,
          "description": "Original Poster",
          "user": {
            "id": 310,
            "username": "shamatar",
            "name": "Alexander",
            "avatar_template": "/user_avatar/forums.foundationdb.org/shamatar/{size}/315_2.png",
            "trust_level": 1
          }
        },
        {
          "extras": null,
          "description": "Frequent Poster",
          "user": {
            "id": 13,
            "username": "alexmiller",
            "name": "Alex Miller",
            "avatar_template": "/user_avatar/forums.foundationdb.org/alexmiller/{size}/326_2.png",
            "trust_level": 4
          }
        },
        {
          "extras": null,
          "description": "Frequent Poster",
          "user": {
            "id": 53,
            "username": "KrzysFR",
            "name": "Christophe Chevalier",
            "avatar_template": "/user_avatar/forums.foundationdb.org/krzysfr/{size}/43_2.png",
            "trust_level": 2
          }
        },
        {
          "extras": null,
          "description": "Frequent Poster",
          "user": {
            "id": 41,
            "username": "amirouche",
            "name": "Amirouche",
            "avatar_template": "/user_avatar/forums.foundationdb.org/amirouche/{size}/1911_2.png",
            "trust_level": 2
          }
        },
        {
          "extras": "latest",
          "description": "Most Recent Poster",
          "user": {
            "id": 502,
            "username": "nikolas.ioannou",
            "name": "",
            "avatar_template": "https://avatars.discourse-cdn.com/v4/letter/n/5daacb/{size}.png",
            "trust_level": 1
          }
        }
      ]
    }
  ],
  "summarizable": false,
  "can_vote": false,
  "vote_count": 0,
  "user_voted": false,
  "discourse_zendesk_plugin_zendesk_id": null,
  "discourse_zendesk_plugin_zendesk_url": "https://your-url.zendesk.com/agent/tickets/",
  "details": {
    "can_edit": false,
    "notification_level": 1,
    "participants": [
      {
        "id": 211,
        "username": "brk0v",
        "name": "Viacheslav Biriukov",
        "avatar_template": "/user_avatar/forums.foundationdb.org/brk0v/{size}/173_2.png",
        "post_count": 11,
        "primary_group_name": null,
        "flair_name": null,
        "flair_url": null,
        "flair_color": null,
        "flair_bg_color": null,
        "flair_group_id": null,
        "trust_level": 1
      },
      {
        "id": 12,
        "username": "ajbeamon",
        "name": "A.J. Beamon",
        "avatar_template": "/user_avatar/forums.foundationdb.org/ajbeamon/{size}/13_2.png",
        "post_count": 5,
        "primary_group_name": null,
        "flair_name": null,
        "flair_url": null,
        "flair_color": null,
        "flair_bg_color": null,
        "flair_group_id": null,
        "admin": true,
        "trust_level": 4
      },
      {
        "id": 156,
        "username": "spullara",
        "name": "Sam Pullara",
        "avatar_template": "/user_avatar/forums.foundationdb.org/spullara/{size}/125_2.png",
        "post_count": 1,
        "primary_group_name": null,
        "flair_name": null,
        "flair_url": null,
        "flair_color": null,
        "flair_bg_color": null,
        "flair_group_id": null,
        "trust_level": 2
      }
    ],
    "created_by": {
      "id": 211,
      "username": "brk0v",
      "name": "Viacheslav Biriukov",
      "avatar_template": "/user_avatar/forums.foundationdb.org/brk0v/{size}/173_2.png"
    },
    "last_poster": {
      "id": 211,
      "username": "brk0v",
      "name": "Viacheslav Biriukov",
      "avatar_template": "/user_avatar/forums.foundationdb.org/brk0v/{size}/173_2.png"
    },
    "links": [
      {
        "url": "https://github.com/apple/foundationdb/issues/321",
        "title": "Database object creation leaks memory on coordinators \u00b7 Issue #321 \u00b7 apple/foundationdb \u00b7 GitHub",
        "internal": false,
        "attachment": false,
        "reflection": false,
        "clicks": 11,
        "user_id": 12,
        "domain": "github.com",
        "root_domain": "github.com"
      },
      {
        "url": "https://forums.foundationdb.org/t/production-deployment/522/2",
        "title": "Production deployment",
        "internal": true,
        "attachment": false,
        "reflection": true,
        "clicks": 6,
        "user_id": 211,
        "domain": "forums.foundationdb.org",
        "root_domain": "foundationdb.org"
      },
      {
        "url": "https://github.com/apple/foundationdb/issues/370",
        "title": "Aggressive writes can run the proxy out of memory \u00b7 Issue #370 \u00b7 apple/foundationdb \u00b7 GitHub",
        "internal": false,
        "attachment": false,
        "reflection": false,
        "clicks": 6,
        "user_id": 12,
        "domain": "github.com",
        "root_domain": "github.com"
      },
      {
        "url": "https://raw.githubusercontent.com/brk0v/logs/master/trace.192.168.001.100.4501.1528107868.HvCax5.6.xml",
        "title": null,
        "internal": false,
        "attachment": false,
        "reflection": false,
        "clicks": 3,
        "user_id": 211,
        "domain": "raw.githubusercontent.com",
        "root_domain": "raw.githubusercontent.com"
      },
      {
        "url": "https://github.com/apple/foundationdb/blob/master/fdbserver/Knobs.cpp#L30",
        "title": "foundationdb/Knobs.cpp at master \u00b7 apple/foundationdb \u00b7 GitHub",
        "internal": false,
        "attachment": false,
        "reflection": false,
        "clicks": 3,
        "user_id": 211,
        "domain": "github.com",
        "root_domain": "github.com"
      },
      {
        "url": "https://github.com/apple/foundationdb/issues/377",
        "title": "Batch priority enhancements \u00b7 Issue #377 \u00b7 apple/foundationdb \u00b7 GitHub",
        "internal": false,
        "attachment": false,
        "reflection": false,
        "clicks": 3,
        "user_id": 12,
        "domain": "github.com",
        "root_domain": "github.com"
      },
      {
        "url": "https://gist.github.com/brk0v/e97bf5650503c1924618ffeefea2dd39",
        "title": "log \u00b7 GitHub",
        "internal": false,
        "attachment": false,
        "reflection": false,
        "clicks": 2,
        "user_id": 211,
        "domain": "gist.github.com",
        "root_domain": "github.com"
      },
      {
        "url": "https://godoc.org/github.com/apple/foundationdb/bindings/go/src/fdb#MustOpen",
        "title": "fdb - GoDoc",
        "internal": false,
        "attachment": false,
        "reflection": false,
        "clicks": 2,
        "user_id": 12,
        "domain": "godoc.org",
        "root_domain": "godoc.org"
      },
      {
        "url": "https://github.com/apple/foundationdb/blob/master/documentation/sphinx/source/kv-architecture.rst",
        "title": "foundationdb/kv-architecture.rst at master \u00b7 apple/foundationdb \u00b7 GitHub",
        "internal": false,
        "attachment": false,
        "reflection": false,
        "clicks": 2,
        "user_id": 211,
        "domain": "github.com",
        "root_domain": "github.com"
      },
      {
        "url": "https://apple.github.io/foundationdb/configuration.html?#guidelines-for-setting-process-class",
        "title": "Configuration \u2014 FoundationDB 5.1",
        "internal": false,
        "attachment": false,
        "reflection": false,
        "clicks": 1,
        "user_id": 12,
        "domain": "apple.github.io",
        "root_domain": "apple.github.io"
      }
    ]
  },
  "bookmarks": []
}