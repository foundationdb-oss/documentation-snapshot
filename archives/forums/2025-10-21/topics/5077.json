{
  "post_stream": {
    "posts": [
      {
        "id": 15345,
        "name": "Han Xu",
        "username": "hxu",
        "avatar_template": "/user_avatar/forums.foundationdb.org/hxu/{size}/1934_2.png",
        "created_at": "2025-09-18T01:04:34.260Z",
        "cooked": "<p>Hey all, we have a cluster in kubernetes that is in three_data_hall configuration with 9 cluster coordinators. If one of the cluster coordinator processes is unexpectedly killed (i.e. the pod is deleted), clients of the cluster seem to be unable to start or commit transactions for ~5-10 seconds as the FDB kubernetes operator selects new coordinators.</p>\n<p>This does not happen when we ask the operator to exclude a process and reselect the coordinators.</p>\n<p>Is this normal? How do we avoid this?</p>",
        "post_number": 1,
        "post_type": 1,
        "posts_count": 6,
        "updated_at": "2025-09-18T01:05:26.732Z",
        "reply_count": 0,
        "reply_to_post_number": null,
        "quote_count": 0,
        "incoming_link_count": 16,
        "reads": 23,
        "readers_count": 22,
        "score": 49.4,
        "yours": false,
        "topic_id": 5077,
        "topic_slug": "are-short-outages-when-you-lose-a-coordinator-normal",
        "display_username": "Han Xu",
        "primary_group_name": null,
        "flair_name": null,
        "flair_url": null,
        "flair_bg_color": null,
        "flair_color": null,
        "flair_group_id": null,
        "badges_granted": [],
        "version": 1,
        "can_edit": false,
        "can_delete": false,
        "can_recover": false,
        "can_see_hidden_post": false,
        "can_wiki": false,
        "read": true,
        "user_title": null,
        "bookmarked": false,
        "actions_summary": [],
        "moderator": false,
        "admin": false,
        "staff": false,
        "user_id": 1525,
        "hidden": false,
        "trust_level": 1,
        "deleted_at": null,
        "user_deleted": false,
        "edit_reason": null,
        "can_view_edit_history": true,
        "wiki": false,
        "post_url": "/t/are-short-outages-when-you-lose-a-coordinator-normal/5077/1",
        "can_accept_answer": false,
        "can_unaccept_answer": false,
        "accepted_answer": false,
        "topic_accepted_answer": null,
        "can_vote": false
      },
      {
        "id": 15348,
        "name": "Johannes Scheuermann",
        "username": "johscheuer",
        "avatar_template": "https://avatars.discourse-cdn.com/v4/letter/j/f475e1/{size}.png",
        "created_at": "2025-09-18T07:43:07.253Z",
        "cooked": "<p>Part of this is normal. When the pod is deleted and the operator notices that the process is not reporting anymore it will select a new set of coordinators, this will cause a recovery. If the process is down long enough and the automatic replacements are enabled (default is enabled) the operator would \u201creplace\u201d the bad pod by creating a new one and doing an exclusion for the processes that were running on this pod. The exclusion could cause another recovery (depending on the process type). Seeing recoveries between 5-10s is not normal, usually those should be faster, the recovery time also depends a bit on your setup and the size of the cluster.</p>\n<p>I think the interesting bit is that you\u2019re not seeing this if you\u2019re doing a replacement of the pod. I wonder if you have enough \u201cstandby\u201d processes (or rather pods) that can be used. Per default the coordinators will preferable run on log processes. Assuming that the pod that gets deleted is a log process and you might not have enough standby pods, it could be possible that you\u2019re not seeing one recovery but actually two (or more), e.g. one recovery for the coordinator change and another recovery when the process comes back again (not sure if that would correlate with the 5-10s of scheduling time).</p>\n<p>Debugging recoveries and finding the root cause of a long recovery can be a bit tricky, this document has the internals of the recovery process: <a href=\"https://github.com/apple/foundationdb/blob/main/design/recovery-internals.md\" class=\"inline-onebox\" rel=\"noopener nofollow ugc\">foundationdb/design/recovery-internals.md at main \u00b7 apple/foundationdb \u00b7 GitHub</a> + this dashboard might we helpful <a href=\"https://github.com/apple/foundationdb/blob/main/contrib/observability_splunk_dashboard/recovery.xml\" class=\"inline-onebox\" rel=\"noopener nofollow ugc\">foundationdb/contrib/observability_splunk_dashboard/recovery.xml at main \u00b7 apple/foundationdb \u00b7 GitHub</a> (at least to get an idea what trace events are important to look at).</p>",
        "post_number": 2,
        "post_type": 1,
        "posts_count": 6,
        "updated_at": "2025-09-18T07:43:07.253Z",
        "reply_count": 0,
        "reply_to_post_number": null,
        "quote_count": 0,
        "incoming_link_count": 3,
        "reads": 23,
        "readers_count": 22,
        "score": 19.4,
        "yours": false,
        "topic_id": 5077,
        "topic_slug": "are-short-outages-when-you-lose-a-coordinator-normal",
        "display_username": "Johannes Scheuermann",
        "primary_group_name": null,
        "flair_name": null,
        "flair_url": null,
        "flair_bg_color": null,
        "flair_color": null,
        "flair_group_id": null,
        "badges_granted": [],
        "version": 1,
        "can_edit": false,
        "can_delete": false,
        "can_recover": false,
        "can_see_hidden_post": false,
        "can_wiki": false,
        "link_counts": [
          {
            "url": "https://github.com/apple/foundationdb/blob/main/contrib/observability_splunk_dashboard/recovery.xml",
            "internal": false,
            "reflection": false,
            "title": "foundationdb/contrib/observability_splunk_dashboard/recovery.xml at main \u00b7 apple/foundationdb \u00b7 GitHub",
            "clicks": 3
          },
          {
            "url": "https://github.com/apple/foundationdb/blob/main/design/recovery-internals.md",
            "internal": false,
            "reflection": false,
            "title": "foundationdb/design/recovery-internals.md at main \u00b7 apple/foundationdb \u00b7 GitHub",
            "clicks": 2
          }
        ],
        "read": true,
        "user_title": "",
        "bookmarked": false,
        "actions_summary": [],
        "moderator": false,
        "admin": false,
        "staff": false,
        "user_id": 849,
        "hidden": false,
        "trust_level": 2,
        "deleted_at": null,
        "user_deleted": false,
        "edit_reason": null,
        "can_view_edit_history": true,
        "wiki": false,
        "post_url": "/t/are-short-outages-when-you-lose-a-coordinator-normal/5077/2",
        "can_accept_answer": false,
        "can_unaccept_answer": false,
        "accepted_answer": false,
        "topic_accepted_answer": null
      },
      {
        "id": 15351,
        "name": "Han Xu",
        "username": "hxu",
        "avatar_template": "/user_avatar/forums.foundationdb.org/hxu/{size}/1934_2.png",
        "created_at": "2025-09-18T16:16:57.369Z",
        "cooked": "<p>Thanks for the tips. I went back and tried a few other things and it\u2019s not actually the loss of the coordinator that causes this, it\u2019s actually the loss of a log role that then triggers the recovery.</p>\n<p>We had 9 logs, 3 in each data hall, so I thought it could be that there wasn\u2019t enough slack in the logs processes to handle a failure. So I increased the log roles (using the operator\u2019s RoleCounts configuration) to 15, but still a few seconds of downtime when I lost a log role.</p>\n<p>Maybe what I need to is have a standby log process that doesn\u2019t have a log role assigned to it. I think I can achieve this by setting ProcessCounts.log to something more than the RoleCount.logs.</p>",
        "post_number": 3,
        "post_type": 1,
        "posts_count": 6,
        "updated_at": "2025-09-18T16:16:57.369Z",
        "reply_count": 0,
        "reply_to_post_number": null,
        "quote_count": 0,
        "incoming_link_count": 0,
        "reads": 22,
        "readers_count": 21,
        "score": 4.2,
        "yours": false,
        "topic_id": 5077,
        "topic_slug": "are-short-outages-when-you-lose-a-coordinator-normal",
        "display_username": "Han Xu",
        "primary_group_name": null,
        "flair_name": null,
        "flair_url": null,
        "flair_bg_color": null,
        "flair_color": null,
        "flair_group_id": null,
        "badges_granted": [],
        "version": 1,
        "can_edit": false,
        "can_delete": false,
        "can_recover": false,
        "can_see_hidden_post": false,
        "can_wiki": false,
        "read": true,
        "user_title": null,
        "bookmarked": false,
        "actions_summary": [],
        "moderator": false,
        "admin": false,
        "staff": false,
        "user_id": 1525,
        "hidden": false,
        "trust_level": 1,
        "deleted_at": null,
        "user_deleted": false,
        "edit_reason": null,
        "can_view_edit_history": true,
        "wiki": false,
        "post_url": "/t/are-short-outages-when-you-lose-a-coordinator-normal/5077/3",
        "can_accept_answer": false,
        "can_unaccept_answer": false,
        "accepted_answer": false,
        "topic_accepted_answer": null
      },
      {
        "id": 15359,
        "name": "Han Xu",
        "username": "hxu",
        "avatar_template": "/user_avatar/forums.foundationdb.org/hxu/{size}/1934_2.png",
        "created_at": "2025-09-22T15:45:45.877Z",
        "cooked": "<p>OK, the dashboard was helpful and I\u2019ve got a more detailed timeline of what was happening. It turns out that we had 3 recoveries in one instance, but there are still some things that are puzzling about it.  Here\u2019s a timeline, and some logs that I found:</p>\n<ol>\n<li>00:35:37.422 - I manually deleted one of the log process pods</li>\n<li>00:35:37.571 - other FDB machines start getting N2_ConnectError and N2_ReadError with the machine I killed as the peer</li>\n<li>00:35:39 -  <strong>First downtime period starts</strong> - our load testing service stops being able to read / commit transactions</li>\n<li>00:35:39.250 - The operator starts to recreate the pod</li>\n<li>00:35:42 - <strong>First downtime period stops</strong> - our load testing service is again able to make transactions.</li>\n<li>00:35:42.550 - We get our first <code>WaitFailureClient</code> from the cluster controller. This is accompanied by a <code>ClusterRecoveryRetrying</code> . What\u2019s a bit strange about this log is that there is no log indicating a recovery has started. The first recovery I see only happens <em>after</em> this log line.</li>\n</ol>\n<pre><code class=\"lang-auto\">\n{\n    \"DateTime\": \"2025-09-18T16:35:42Z\",\n    \"Error\": \"tlog_failed\",\n    \"ErrorCode\": \"1205\",\n    \"ErrorDescription\": \"Cluster recovery terminating because a TLog failed\",\n    \"ID\": \"3459f5d1f72f910d\",\n    \"LogGroup\": \"foundationdb-cluster-main\",\n    \"Machine\": \"10.0.208.42:4500\",\n    \"Roles\": \"CC\",\n    \"Severity\": \"20\",\n    \"ThreadID\": \"16997965542817237771\",\n    \"Time\": \"1758213342.550678\",\n    \"Type\": \"ClusterRecoveryRetrying\"\n}\n</code></pre>\n<ol start=\"7\">\n<li>00:35:42.587 - <code>MasterRecoveryState</code> with <code>reading_coordinated_state</code> - I think this is when the first recovery starts</li>\n<li>00:35:42.598 - We get a \u201cNot enough physical servers available\u201d. This occurs with different types of trace logs (<code>RecruitStorageNotAvailable</code> , <code>CCWDB</code>, and <code>ClusteryRecoveryRetrying</code>). and occurs quite a lot until the cluster fully recovers ~20 seconds later</li>\n</ol>\n<pre><code class=\"lang-auto\">\n{\n    \"DateTime\": \"2025-09-18T16:35:44Z\",\n    \"Error\": \"no_more_servers\",\n    \"ErrorCode\": \"1008\",\n    \"ErrorDescription\": \"Not enough physical servers available\",\n    \"ID\": \"35163ad87d48095f\",\n    \"LogGroup\": \"foundationdb-cluster-main\",\n    \"Machine\": \"10.0.208.42:4500\",\n    \"Roles\": \"CC\",\n    \"Severity\": \"20\",\n    \"ThreadID\": \"16997965542817237771\",\n    \"Time\": \"1758213344.776349\",\n    \"Type\": \"ClusterRecoveryRetrying\"\n}\n</code></pre>\n<ol start=\"9\">\n<li>00:35:42.735 - <code>MasterRecoveryDuration</code> - shows the recovery finishes in 148ms</li>\n<li>00:35:44.620 - <code>RestartingTxnSubsystem</code> - with stage <code>AwaitCommit</code> . Maybe I am reading this line wrong, but we just did a recovery, so why is the transaction subsystem restarting?</li>\n<li>00:35:44.812 - Another recovery starts</li>\n<li>00:35:45.212 - Not sure if this is an error, but it was in the Splunk dashboard:</li>\n</ol>\n<pre><code class=\"lang-auto\">{\n    \"DateTime\": \"2025-09-18T16:35:45Z\",\n    \"Error\": \"operation_failed\",\n    \"ErrorCode\": \"1000\",\n    \"ErrorDescription\": \"Operation failed\",\n    \"GoodRecruitmentTimeReady\": \"0\",\n    \"ID\": \"41168f4fb8efbfb1\",\n    \"LogGroup\": \"foundationdb-cluster-main\",\n    \"Machine\": \"10.0.120.245:4500\",\n    \"Roles\": \"CC,DD\",\n    \"Severity\": \"10\",\n    \"ThreadID\": \"17276620476305664854\",\n    \"Time\": \"1758213345.212184\",\n    \"Type\": \"RecruitFromConfigurationRetry\"\n}\n</code></pre>\n<ol start=\"13\">\n<li>00:35:46 - <strong>Second period of downtime starts</strong> - this one is 14 seconds</li>\n<li>00:35:46.915 - The second recovery finishes. This one takes 2 seconds</li>\n<li>00:35:49.705 - Sometime around here, the recreated pod starts up and rejoins the cluster.  I see the <code>Net2Starting</code> and other log lines from the node. I see the <code>WorkerRegister</code> log at 35:53.369, after the next recovery starts</li>\n<li>00:35:51.258 - There seems to be another recovery here \u2013 several different nodes report a <code>MasterRecoveryState</code>, but I never get a <code>MasterRecoveryDuration</code> log from this</li>\n<li>00:36:00 - <strong>Second period of downtime end</strong></li>\n<li>00:36:00.191 - The third recovery finishes. This one takes 357ms</li>\n</ol>\n<p>In total, there was 17 seconds of downtime:</p>\n<ol>\n<li>3 seconds initially when the log process was dead, but it seems that the cluster didn\u2019t detect the pod was dead.</li>\n<li>14 seconds around the second recovery. I\u2019m not sure why this one was so long</li>\n</ol>\n<p>Some questions that I have from my investigations:</p>\n<ol>\n<li>I notice that there is a knob for <code>TLOG_TIMEOUT</code> and the default value is 0.4. So why did it take almost 5 seconds to get the <code>WaitFailureClient</code> for the killed log process?</li>\n<li>Why are there so many recoveries, and maybe a couple of failed recoveries?</li>\n<li>Does the \u201cNot enough physical servers available\u201d error indicate a configuration issue in our cluster topology?</li>\n</ol>\n<p>I will continue to dig at this.</p>",
        "post_number": 4,
        "post_type": 1,
        "posts_count": 6,
        "updated_at": "2025-09-23T13:09:06.541Z",
        "reply_count": 0,
        "reply_to_post_number": null,
        "quote_count": 0,
        "incoming_link_count": 0,
        "reads": 20,
        "readers_count": 19,
        "score": 3.6,
        "yours": false,
        "topic_id": 5077,
        "topic_slug": "are-short-outages-when-you-lose-a-coordinator-normal",
        "display_username": "Han Xu",
        "primary_group_name": null,
        "flair_name": null,
        "flair_url": null,
        "flair_bg_color": null,
        "flair_color": null,
        "flair_group_id": null,
        "badges_granted": [],
        "version": 2,
        "can_edit": false,
        "can_delete": false,
        "can_recover": false,
        "can_see_hidden_post": false,
        "can_wiki": false,
        "read": true,
        "user_title": null,
        "bookmarked": false,
        "actions_summary": [],
        "moderator": false,
        "admin": false,
        "staff": false,
        "user_id": 1525,
        "hidden": false,
        "trust_level": 1,
        "deleted_at": null,
        "user_deleted": false,
        "edit_reason": null,
        "can_view_edit_history": true,
        "wiki": false,
        "post_url": "/t/are-short-outages-when-you-lose-a-coordinator-normal/5077/4",
        "can_accept_answer": false,
        "can_unaccept_answer": false,
        "accepted_answer": false,
        "topic_accepted_answer": null
      },
      {
        "id": 15362,
        "name": "Han Xu",
        "username": "hxu",
        "avatar_template": "/user_avatar/forums.foundationdb.org/hxu/{size}/1934_2.png",
        "created_at": "2025-09-23T13:15:26.954Z",
        "cooked": "<p>I had another hypothesis that I tested out regarding the distribution of log servers. We are in three data hall, so this requires at least four log roles, two in two zones. I thought that the recoveries could be minimized if we ensured that we have enough standby log <em>processes</em> (previously with 9 log roles, we were using every log process).</p>\n<p>So I configured out cluster to have:</p>\n<ul>\n<li>The default four log roles</li>\n<li>12 log processes total (with a topology spread constraint resulting in 4 in each zone, so at least 2 standby in each zone).</li>\n</ul>\n<p>When I manually killed one of the log roles, I ended up with only one recovery, which is better. But our client that was hitting the database still experienced ~5 seconds of downtime. I am wondering if this is may be due to the transactions that were inflight getting timed out after 5 seconds instead of an actual 5 second outage on the server.</p>",
        "post_number": 5,
        "post_type": 1,
        "posts_count": 6,
        "updated_at": "2025-09-23T13:15:26.954Z",
        "reply_count": 0,
        "reply_to_post_number": null,
        "quote_count": 0,
        "incoming_link_count": 3,
        "reads": 17,
        "readers_count": 16,
        "score": 18.2,
        "yours": false,
        "topic_id": 5077,
        "topic_slug": "are-short-outages-when-you-lose-a-coordinator-normal",
        "display_username": "Han Xu",
        "primary_group_name": null,
        "flair_name": null,
        "flair_url": null,
        "flair_bg_color": null,
        "flair_color": null,
        "flair_group_id": null,
        "badges_granted": [],
        "version": 1,
        "can_edit": false,
        "can_delete": false,
        "can_recover": false,
        "can_see_hidden_post": false,
        "can_wiki": false,
        "read": true,
        "user_title": null,
        "bookmarked": false,
        "actions_summary": [],
        "moderator": false,
        "admin": false,
        "staff": false,
        "user_id": 1525,
        "hidden": false,
        "trust_level": 1,
        "deleted_at": null,
        "user_deleted": false,
        "edit_reason": null,
        "can_view_edit_history": true,
        "wiki": false,
        "post_url": "/t/are-short-outages-when-you-lose-a-coordinator-normal/5077/5",
        "can_accept_answer": false,
        "can_unaccept_answer": false,
        "accepted_answer": false,
        "topic_accepted_answer": null
      },
      {
        "id": 15374,
        "name": "Han Xu",
        "username": "hxu",
        "avatar_template": "/user_avatar/forums.foundationdb.org/hxu/{size}/1934_2.png",
        "created_at": "2025-09-29T07:52:44.163Z",
        "cooked": "<p>After some more testing, I found another reason why we were getting two recoveries. Just to recap:</p>\n<ul>\n<li>We were deployed in three data hall, with 9 log roles requested. Not processes, we were actually requesting 9 log roles using the <code>databaseConfiguration</code>field in the operator. So this gave us exactly 9 log processes with no standbys.\n<ul>\n<li>If a log died, it would recovery once to rebuild the 8 logs, then recover again when the 9th log process pod was recreated.</li>\n<li>We fixed this by requesting 9 log processes and only 4 log roles, so we have 5 standbys (3 in the AZ that has no log roles, and 1 in the AZ with the log roles. I think this is the only way to do it with k8s topology constraints)</li>\n</ul>\n</li>\n<li>With 9 log processes, the operator will choose all the log processes to be coordinators. It prefers logs over storage classes\n<ul>\n<li>So if you lose a log role, this also means you lose a coordinator</li>\n<li>The cluster does a recovery to recruit a new log role from the standby</li>\n<li>The operator chooses new coordinators, which again triggers a second recovery</li>\n<li>I believe the solution to this is to have dedicated coordinator process classes, or to prefer storage processes (but this can be <a href=\"https://github.com/FoundationDB/fdb-kubernetes-operator/pull/2017\" rel=\"noopener nofollow ugc\">disruptive during an upgrade</a>. I don\u2019t think it will break an upgrade, but will cause more recoveries than necessary).\n<ul>\n<li><a class=\"mention\" href=\"/u/johscheuer\">@johscheuer</a> since log roles are preferred as the default, I think this will cause most replacements of a log process to trigger more than one recovery</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<p>Solving these two issues should get rid of the multiple recoveries in the case of a log role.</p>\n<p>So the last issue here is why do recoveries seem to take about 5 seconds from a client\u2019s perspective when it the metrics show it completes in ~200ms. I think that this has to do with the failure detection delay. It seems there is a knob <code>FAILURE_DETECTION_DELAY</code> that is set to 4 seconds before a role is detected as failed.</p>",
        "post_number": 6,
        "post_type": 1,
        "posts_count": 6,
        "updated_at": "2025-09-29T07:52:44.163Z",
        "reply_count": 0,
        "reply_to_post_number": null,
        "quote_count": 0,
        "incoming_link_count": 3,
        "reads": 13,
        "readers_count": 12,
        "score": 2.4,
        "yours": false,
        "topic_id": 5077,
        "topic_slug": "are-short-outages-when-you-lose-a-coordinator-normal",
        "display_username": "Han Xu",
        "primary_group_name": null,
        "flair_name": null,
        "flair_url": null,
        "flair_bg_color": null,
        "flair_color": null,
        "flair_group_id": null,
        "badges_granted": [],
        "version": 1,
        "can_edit": false,
        "can_delete": false,
        "can_recover": false,
        "can_see_hidden_post": false,
        "can_wiki": false,
        "link_counts": [
          {
            "url": "https://github.com/FoundationDB/fdb-kubernetes-operator/pull/2017",
            "internal": false,
            "reflection": false,
            "clicks": 0
          }
        ],
        "read": true,
        "user_title": null,
        "bookmarked": false,
        "actions_summary": [
          {
            "id": 2,
            "count": 1
          }
        ],
        "moderator": false,
        "admin": false,
        "staff": false,
        "user_id": 1525,
        "hidden": false,
        "trust_level": 1,
        "deleted_at": null,
        "user_deleted": false,
        "edit_reason": null,
        "can_view_edit_history": true,
        "wiki": false,
        "post_url": "/t/are-short-outages-when-you-lose-a-coordinator-normal/5077/6",
        "can_accept_answer": false,
        "can_unaccept_answer": false,
        "accepted_answer": false,
        "topic_accepted_answer": null
      }
    ],
    "stream": [
      15345,
      15348,
      15351,
      15359,
      15362,
      15374
    ]
  },
  "timeline_lookup": [
    [
      1,
      34
    ],
    [
      3,
      33
    ],
    [
      4,
      29
    ],
    [
      5,
      28
    ],
    [
      6,
      23
    ]
  ],
  "suggested_topics": [],
  "tags": [],
  "tags_descriptions": {},
  "fancy_title": "Are short outages when you lose a coordinator normal?",
  "id": 5077,
  "title": "Are short outages when you lose a coordinator normal?",
  "posts_count": 6,
  "created_at": "2025-09-18T01:04:34.188Z",
  "views": 132,
  "reply_count": 0,
  "like_count": 1,
  "last_posted_at": "2025-09-29T07:52:44.163Z",
  "visible": true,
  "closed": false,
  "archived": false,
  "has_summary": false,
  "archetype": "regular",
  "slug": "are-short-outages-when-you-lose-a-coordinator-normal",
  "category_id": 7,
  "word_count": 1687,
  "deleted_at": null,
  "user_id": 1525,
  "featured_link": null,
  "pinned_globally": false,
  "pinned_at": null,
  "pinned_until": null,
  "image_url": null,
  "slow_mode_seconds": 0,
  "draft": null,
  "draft_key": "topic_5077",
  "draft_sequence": null,
  "unpinned": null,
  "pinned": false,
  "current_post_number": 1,
  "highest_post_number": 6,
  "deleted_by": null,
  "actions_summary": [
    {
      "id": 4,
      "count": 0,
      "hidden": false,
      "can_act": false
    },
    {
      "id": 8,
      "count": 0,
      "hidden": false,
      "can_act": false
    },
    {
      "id": 10,
      "count": 0,
      "hidden": false,
      "can_act": false
    },
    {
      "id": 7,
      "count": 0,
      "hidden": false,
      "can_act": false
    }
  ],
  "chunk_size": 20,
  "bookmarked": false,
  "topic_timer": null,
  "message_bus_last_id": 3,
  "participant_count": 2,
  "show_read_indicator": false,
  "thumbnails": null,
  "slow_mode_enabled_until": null,
  "tags_disable_ads": false,
  "related_topics": [
    {
      "fancy_title": "FoundationDB @ Kubernetes having &ldquo;issues&rdquo;",
      "id": 383,
      "title": "FoundationDB @ Kubernetes having \"issues\"",
      "slug": "foundationdb-kubernetes-having-issues",
      "posts_count": 4,
      "reply_count": 2,
      "highest_post_number": 4,
      "image_url": null,
      "created_at": "2018-05-09T10:17:53.797Z",
      "last_posted_at": "2018-05-11T17:28:05.081Z",
      "bumped": true,
      "bumped_at": "2018-05-11T17:28:05.081Z",
      "archetype": "regular",
      "unseen": false,
      "pinned": false,
      "unpinned": null,
      "visible": true,
      "closed": false,
      "archived": false,
      "bookmarked": null,
      "liked": null,
      "tags": [],
      "tags_descriptions": {},
      "like_count": 1,
      "views": 2031,
      "category_id": 7,
      "featured_link": null,
      "has_accepted_answer": false,
      "posters": [
        {
          "extras": null,
          "description": "Original Poster",
          "user": {
            "id": 247,
            "username": "Chr1st0ph",
            "name": "Chr1st0ph",
            "avatar_template": "/user_avatar/forums.foundationdb.org/chr1st0ph/{size}/353_2.png",
            "trust_level": 2
          }
        },
        {
          "extras": "latest",
          "description": "Most Recent Poster",
          "user": {
            "id": 12,
            "username": "ajbeamon",
            "name": "A.J. Beamon",
            "avatar_template": "/user_avatar/forums.foundationdb.org/ajbeamon/{size}/13_2.png",
            "admin": true,
            "trust_level": 4
          }
        }
      ]
    },
    {
      "fancy_title": "Database unavailable after shutting down a foundationdb node",
      "id": 2113,
      "title": "Database unavailable after shutting down a foundationdb node",
      "slug": "database-unavailable-after-shutting-down-a-foundationdb-node",
      "posts_count": 18,
      "reply_count": 8,
      "highest_post_number": 18,
      "image_url": null,
      "created_at": "2020-05-11T16:09:39.373Z",
      "last_posted_at": "2021-02-05T22:16:50.767Z",
      "bumped": true,
      "bumped_at": "2021-02-05T22:18:40.780Z",
      "archetype": "regular",
      "unseen": false,
      "pinned": false,
      "unpinned": null,
      "visible": true,
      "closed": false,
      "archived": false,
      "bookmarked": null,
      "liked": null,
      "tags": [],
      "tags_descriptions": {},
      "like_count": 3,
      "views": 8569,
      "category_id": 7,
      "featured_link": null,
      "has_accepted_answer": false,
      "posters": [
        {
          "extras": null,
          "description": "Original Poster",
          "user": {
            "id": 714,
            "username": "tuk",
            "name": "",
            "avatar_template": "https://avatars.discourse-cdn.com/v4/letter/t/b5ac83/{size}.png",
            "trust_level": 2
          }
        },
        {
          "extras": null,
          "description": "Frequent Poster",
          "user": {
            "id": 12,
            "username": "ajbeamon",
            "name": "A.J. Beamon",
            "avatar_template": "/user_avatar/forums.foundationdb.org/ajbeamon/{size}/13_2.png",
            "admin": true,
            "trust_level": 4
          }
        },
        {
          "extras": null,
          "description": "Frequent Poster",
          "user": {
            "id": 13,
            "username": "alexmiller",
            "name": "Alex Miller",
            "avatar_template": "/user_avatar/forums.foundationdb.org/alexmiller/{size}/326_2.png",
            "trust_level": 4
          }
        },
        {
          "extras": "latest",
          "description": "Most Recent Poster",
          "user": {
            "id": 810,
            "username": "amanda",
            "name": "Amanda",
            "avatar_template": "https://avatars.discourse-cdn.com/v4/letter/a/67e7ee/{size}.png",
            "trust_level": 2
          }
        }
      ]
    },
    {
      "fancy_title": "30 server cluster just died",
      "id": 2731,
      "title": "30 server cluster just died",
      "slug": "30-server-cluster-just-died",
      "posts_count": 8,
      "reply_count": 3,
      "highest_post_number": 8,
      "image_url": null,
      "created_at": "2021-06-05T16:22:25.332Z",
      "last_posted_at": "2021-06-06T18:34:11.621Z",
      "bumped": true,
      "bumped_at": "2021-06-06T18:34:11.621Z",
      "archetype": "regular",
      "unseen": false,
      "pinned": false,
      "unpinned": null,
      "visible": true,
      "closed": false,
      "archived": false,
      "bookmarked": null,
      "liked": null,
      "tags": [],
      "tags_descriptions": {},
      "like_count": 0,
      "views": 738,
      "category_id": 7,
      "featured_link": null,
      "has_accepted_answer": false,
      "posters": [
        {
          "extras": null,
          "description": "Original Poster",
          "user": {
            "id": 867,
            "username": "espaiz",
            "name": "David",
            "avatar_template": "https://avatars.discourse-cdn.com/v4/letter/e/ad7895/{size}.png",
            "trust_level": 1
          }
        },
        {
          "extras": null,
          "description": "Frequent Poster",
          "user": {
            "id": 14,
            "username": "andrew.noyes",
            "name": "",
            "avatar_template": "/user_avatar/forums.foundationdb.org/andrew.noyes/{size}/443_2.png",
            "trust_level": 2
          }
        },
        {
          "extras": null,
          "description": "Frequent Poster",
          "user": {
            "id": 12,
            "username": "ajbeamon",
            "name": "A.J. Beamon",
            "avatar_template": "/user_avatar/forums.foundationdb.org/ajbeamon/{size}/13_2.png",
            "admin": true,
            "trust_level": 4
          }
        },
        {
          "extras": "latest",
          "description": "Most Recent Poster",
          "user": {
            "id": 337,
            "username": "mengxu",
            "name": "Meng Xu",
            "avatar_template": "/user_avatar/forums.foundationdb.org/mengxu/{size}/893_2.png",
            "trust_level": 2
          }
        }
      ]
    },
    {
      "fancy_title": "Cluster stuck in recovery",
      "id": 2574,
      "title": "Cluster stuck in recovery",
      "slug": "cluster-stuck-in-recovery",
      "posts_count": 4,
      "reply_count": 1,
      "highest_post_number": 4,
      "image_url": null,
      "created_at": "2021-02-25T12:08:58.232Z",
      "last_posted_at": "2021-03-12T13:58:22.038Z",
      "bumped": true,
      "bumped_at": "2021-03-12T13:58:22.038Z",
      "archetype": "regular",
      "unseen": false,
      "pinned": false,
      "unpinned": null,
      "visible": true,
      "closed": false,
      "archived": false,
      "bookmarked": null,
      "liked": null,
      "tags": [],
      "tags_descriptions": {},
      "like_count": 0,
      "views": 696,
      "category_id": 17,
      "featured_link": null,
      "has_accepted_answer": false,
      "posters": [
        {
          "extras": null,
          "description": "Original Poster",
          "user": {
            "id": 724,
            "username": "larshagen",
            "name": "Lars Hagen",
            "avatar_template": "/user_avatar/forums.foundationdb.org/larshagen/{size}/776_2.png",
            "trust_level": 1
          }
        },
        {
          "extras": null,
          "description": "Frequent Poster",
          "user": {
            "id": 3,
            "username": "john_brownlee",
            "name": "John Brownlee",
            "avatar_template": "/user_avatar/forums.foundationdb.org/john_brownlee/{size}/22_2.png",
            "admin": true,
            "trust_level": 4
          }
        },
        {
          "extras": "latest",
          "description": "Most Recent Poster",
          "user": {
            "id": 892,
            "username": "jkylling",
            "name": "",
            "avatar_template": "/user_avatar/forums.foundationdb.org/jkylling/{size}/1029_2.png",
            "trust_level": 1
          }
        }
      ]
    },
    {
      "fancy_title": "Cluster stuck in recovery after crash of one node",
      "id": 3216,
      "title": "Cluster stuck in recovery after crash of one node",
      "slug": "cluster-stuck-in-recovery-after-crash-of-one-node",
      "posts_count": 2,
      "reply_count": 0,
      "highest_post_number": 2,
      "image_url": null,
      "created_at": "2022-03-17T11:59:52.372Z",
      "last_posted_at": "2022-03-18T03:45:59.162Z",
      "bumped": true,
      "bumped_at": "2022-03-18T03:45:59.162Z",
      "archetype": "regular",
      "unseen": false,
      "pinned": false,
      "unpinned": null,
      "visible": true,
      "closed": false,
      "archived": false,
      "bookmarked": null,
      "liked": null,
      "tags": [],
      "tags_descriptions": {},
      "like_count": 1,
      "views": 560,
      "category_id": 7,
      "featured_link": null,
      "has_accepted_answer": false,
      "posters": [
        {
          "extras": null,
          "description": "Original Poster",
          "user": {
            "id": 1079,
            "username": "xozzslip",
            "name": "",
            "avatar_template": "/user_avatar/forums.foundationdb.org/xozzslip/{size}/1298_2.png",
            "trust_level": 1
          }
        },
        {
          "extras": "latest",
          "description": "Most Recent Poster",
          "user": {
            "id": 454,
            "username": "jzhou",
            "name": "Jingyu Zhou",
            "avatar_template": "/user_avatar/forums.foundationdb.org/jzhou/{size}/445_2.png",
            "admin": true,
            "moderator": true,
            "trust_level": 2
          }
        }
      ]
    }
  ],
  "summarizable": false,
  "can_vote": false,
  "vote_count": 0,
  "user_voted": false,
  "discourse_zendesk_plugin_zendesk_id": null,
  "discourse_zendesk_plugin_zendesk_url": "https://your-url.zendesk.com/agent/tickets/",
  "details": {
    "can_edit": false,
    "notification_level": 1,
    "participants": [
      {
        "id": 1525,
        "username": "hxu",
        "name": "Han Xu",
        "avatar_template": "/user_avatar/forums.foundationdb.org/hxu/{size}/1934_2.png",
        "post_count": 5,
        "primary_group_name": null,
        "flair_name": null,
        "flair_url": null,
        "flair_color": null,
        "flair_bg_color": null,
        "flair_group_id": null,
        "trust_level": 1
      },
      {
        "id": 849,
        "username": "johscheuer",
        "name": "Johannes Scheuermann",
        "avatar_template": "https://avatars.discourse-cdn.com/v4/letter/j/f475e1/{size}.png",
        "post_count": 1,
        "primary_group_name": null,
        "flair_name": null,
        "flair_url": null,
        "flair_color": null,
        "flair_bg_color": null,
        "flair_group_id": null,
        "trust_level": 2
      }
    ],
    "created_by": {
      "id": 1525,
      "username": "hxu",
      "name": "Han Xu",
      "avatar_template": "/user_avatar/forums.foundationdb.org/hxu/{size}/1934_2.png"
    },
    "last_poster": {
      "id": 1525,
      "username": "hxu",
      "name": "Han Xu",
      "avatar_template": "/user_avatar/forums.foundationdb.org/hxu/{size}/1934_2.png"
    },
    "links": [
      {
        "url": "https://github.com/apple/foundationdb/blob/main/contrib/observability_splunk_dashboard/recovery.xml",
        "title": "foundationdb/contrib/observability_splunk_dashboard/recovery.xml at main \u00b7 apple/foundationdb \u00b7 GitHub",
        "internal": false,
        "attachment": false,
        "reflection": false,
        "clicks": 3,
        "user_id": 849,
        "domain": "github.com",
        "root_domain": "github.com"
      },
      {
        "url": "https://github.com/apple/foundationdb/blob/main/design/recovery-internals.md",
        "title": "foundationdb/design/recovery-internals.md at main \u00b7 apple/foundationdb \u00b7 GitHub",
        "internal": false,
        "attachment": false,
        "reflection": false,
        "clicks": 2,
        "user_id": 849,
        "domain": "github.com",
        "root_domain": "github.com"
      }
    ]
  },
  "bookmarks": []
}