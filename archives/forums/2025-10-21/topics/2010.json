{
  "post_stream": {
    "posts": [
      {
        "id": 6465,
        "name": "Kyle Snavely",
        "username": "ksnavely",
        "avatar_template": "/user_avatar/forums.foundationdb.org/ksnavely/{size}/483_2.png",
        "created_at": "2020-03-17T19:48:25.877Z",
        "cooked": "<p>Hey all,</p>\n<p>I\u2019ve been working through failure scenarios with our operations team and I wanted to describe a storage topology and various maintenance scenarios.</p>\n<p>We run in three data hall mode with our minimum footprint being 6 tlog-oriented boxes (2 tlogs each + stateless/proxy/resolver roles) and 3 storage machines (hosting 8 SSDs running at 4 storage processes per SSD based on our benchmarking and SSD saturation observations \u2013 32 storage processes each \u2013 plus a couple of stateless processes). This machine/process layout allows us to survive an AZ/hall failure plus any other machine in another AZ/hall nicely.</p>\n<p>We are looking at launching a public environment with 6 storage nodes to help make up for the write throughput hit that continuous backups cause, plus just generally relieving the storage queue bottlenecks we see at high ingest rates (300k+ writes per second on 3 storage nodes being typically achievable in our benchmarks w/o backup running \u2013 I\u2019m looking to crack 500k+ with 6 hopefully).</p>\n<p>But rather than performance, my question is about operations. We are examining the case in which a storage node fails altogether, taking down all 8 of the 3.8 TB SSDs.</p>\n<p>In the case of 3 storage nodes, we just run with 2 storage nodes while performing maintenance (see later tlog concerns though).</p>\n<p>In the case of 6 storage nodes (2 per AZ/data hall) we\u2019d be left with 1 functioning storage node in the affected AZ if its comrade goes down.</p>\n<p>Now, after <code>DATA_DISTRIBUTION_FAILURE_REACTION_TIME</code>/60s we expect the surviving replicas affected by the down storage machine to begin replicating data to the survivor in the affected AZ. But this isn\u2019t always desirable for us and may have disk-space-used concerns.</p>\n<p>The most likely case for an entire storage machine failure is either an OS disk failure or networking issue. We run the OS in RAID1 so we can bring back a machine suffering from that failure mode with a pretty quick rebuild. Network issues could be transient as unusual but not unheard of as that may be for 60s+.</p>\n<p>The ops team raises the concern --*would it be unreasonable to use ~&gt;50% disk usage on these storage machines given that storage failures will trigger replication of the now n=2 replica data to the survivor of the affected AZ?</p>\n<p>Now, you can see these machines are very storage dense. When we are 5-10% full sure, it\u2019s nice to maybe be able to replicate data to the survivor if recovery is taking a while for some reason. But at 50% full we\u2019re talking about ~30.4TB of data to replicate. Filling the survivors disks aside, that\u2019s just a long time and a lot of data for redistribution.</p>\n<p>In this case it\u2019s likely we want to leverage the maintenance mode ability for zones. While we haven\u2019t yet configured this in our test environments I\u2019m thinking we\u2019d want to set the zones == data halls == AZs for us. This way an operator which is paged about a storage machine failure could apply the maintenance state to the affected zone to prevent data redistribution (of many TBs) if we know it\u2019s just going to be a short wait on an OS RAID rebuild or whatever.</p>\n<p>Does that sound right? Are are folks in the wild embracing the data redistribution? With these dense storage nodes (read: cost effective and performant) it seems a bit inefficient to embrace data redistribution unless the affected storage machine has been melted into a puddle and a replacement isn\u2019t available for $REASONS for some amount of time much greater than the time to redistribute data.</p>\n<p>Finally, one more concern regarding tlogs and storage during a storage failure. I mentioned we have the separate tlog-oriented boxes. Naturally during storage failures in a data hall FDB may attempt to recruit storage processes on these boxes. In our FDB machine layout this isn\u2019t really desirable \u2013 the tlog-oriented boxes have much less overall disk space. I worry that storage failures leading to data redistribution will wind up pushing storage data to both the tlog boxes in an affected AZ as well as the storage survivor (in the 2 storage per AZ scenario). If the tlogs are busy this could also limit the CPU resources available between tlog/storage processes on the tlog machines after storage is recruited on the tlog-intended disks, plus lowering IO performance with the mix of high-frequency fsyncs and storage access. After recovering the failed storage machine I worry about the \u2018unique\u2019 state a cluster might be left in, mixing tlogs and storage until maybe FDB is able to ~restore the initial state before the storage failure.</p>\n<p>Is maintenance mode for a zone the answer to prevent the recruitment of storage on the tlogs boxes in a storage-machine failure scenario? In architectures with specialized machines for tlogs/storage hosting, have operators observed an eventual restoration of the original desired process role assignment after restoring affected storage processes?</p>\n<p>Alright that was quite a few thoughts so I\u2019ll leave it there for now. Thanks for your time,</p>\n<p>Kyle</p>",
        "post_number": 1,
        "post_type": 1,
        "posts_count": 7,
        "updated_at": "2020-03-17T19:48:25.877Z",
        "reply_count": 2,
        "reply_to_post_number": null,
        "quote_count": 0,
        "incoming_link_count": 154,
        "reads": 44,
        "readers_count": 43,
        "score": 788.8,
        "yours": false,
        "topic_id": 2010,
        "topic_slug": "questions-regarding-maintenance-for-multiple-storage-oriented-machines-in-a-data-hall",
        "display_username": "Kyle Snavely",
        "primary_group_name": null,
        "flair_name": null,
        "flair_url": null,
        "flair_bg_color": null,
        "flair_color": null,
        "flair_group_id": null,
        "badges_granted": [],
        "version": 1,
        "can_edit": false,
        "can_delete": false,
        "can_recover": false,
        "can_see_hidden_post": false,
        "can_wiki": false,
        "read": true,
        "user_title": null,
        "bookmarked": false,
        "actions_summary": [],
        "moderator": false,
        "admin": false,
        "staff": false,
        "user_id": 484,
        "hidden": false,
        "trust_level": 1,
        "deleted_at": null,
        "user_deleted": false,
        "edit_reason": null,
        "can_view_edit_history": true,
        "wiki": false,
        "post_url": "/t/questions-regarding-maintenance-for-multiple-storage-oriented-machines-in-a-data-hall/2010/1",
        "can_accept_answer": false,
        "can_unaccept_answer": false,
        "accepted_answer": false,
        "topic_accepted_answer": null,
        "can_vote": false
      },
      {
        "id": 6466,
        "name": "Kyle Snavely",
        "username": "ksnavely",
        "avatar_template": "/user_avatar/forums.foundationdb.org/ksnavely/{size}/483_2.png",
        "created_at": "2020-03-17T20:57:24.112Z",
        "cooked": "<aside class=\"quote no-group\" data-username=\"ksnavely\" data-post=\"1\" data-topic=\"2010\">\n<div class=\"title\">\n<div class=\"quote-controls\"></div>\n<img loading=\"lazy\" alt=\"\" width=\"24\" height=\"24\" src=\"https://sea1.discourse-cdn.com/foundationdb/user_avatar/forums.foundationdb.org/ksnavely/48/483_2.png\" class=\"avatar\"> ksnavely:</div>\n<blockquote>\n<p>We are looking at launching a public environment with 6 storage nodes to help make up for the write throughput hit that continuous backups cause</p>\n</blockquote>\n</aside>\n<p>Ah yes, I think I recall know the extra write hit might be happening in the tlog layer? So maybe the extra storage machines won\u2019t help with the backup write hit v. extra tlogs. We\u2019re testing that ~soon regardless.</p>\n<p>The extra write throughput (disregarding backup) is still appealing to us.</p>",
        "post_number": 2,
        "post_type": 1,
        "posts_count": 7,
        "updated_at": "2020-03-17T20:57:56.777Z",
        "reply_count": 0,
        "reply_to_post_number": null,
        "quote_count": 1,
        "incoming_link_count": 0,
        "reads": 40,
        "readers_count": 39,
        "score": 8.0,
        "yours": false,
        "topic_id": 2010,
        "topic_slug": "questions-regarding-maintenance-for-multiple-storage-oriented-machines-in-a-data-hall",
        "display_username": "Kyle Snavely",
        "primary_group_name": null,
        "flair_name": null,
        "flair_url": null,
        "flair_bg_color": null,
        "flair_color": null,
        "flair_group_id": null,
        "badges_granted": [],
        "version": 1,
        "can_edit": false,
        "can_delete": false,
        "can_recover": false,
        "can_see_hidden_post": false,
        "can_wiki": false,
        "read": true,
        "user_title": null,
        "bookmarked": false,
        "actions_summary": [],
        "moderator": false,
        "admin": false,
        "staff": false,
        "user_id": 484,
        "hidden": false,
        "trust_level": 1,
        "deleted_at": null,
        "user_deleted": false,
        "edit_reason": null,
        "can_view_edit_history": true,
        "wiki": false,
        "post_url": "/t/questions-regarding-maintenance-for-multiple-storage-oriented-machines-in-a-data-hall/2010/2",
        "can_accept_answer": false,
        "can_unaccept_answer": false,
        "accepted_answer": false,
        "topic_accepted_answer": null
      },
      {
        "id": 6468,
        "name": "Alex Miller",
        "username": "alexmiller",
        "avatar_template": "/user_avatar/forums.foundationdb.org/alexmiller/{size}/326_2.png",
        "created_at": "2020-03-18T05:31:25.561Z",
        "cooked": "<p>I\u2019m going to summarize this a few questions:</p>\n<ol>\n<li>How should I best handle storage servers running on very large, reliable disks?</li>\n<li>How can I prevent storage servers from being recruited on my transaction logs?</li>\n<li>What is the overhead of continuous backups and where is it paid?</li>\n</ol>\n<hr>\n<h3>Large and reliable disks</h3>\n<p>There\u2019s a few things to think about here, all of which are about how various pieces of the system will react to a failed storage server.  One aspect is how data distribution will react, as you\u2019ve discussed.  The tradeoff to consider is the impact on transaction logs.</p>\n<p>For moving data, I agree with your assessment that, given the strong belief that you can bring back a <strong>very</strong> large amount of data \u201clost\u201d from a failed machine, beginning data redistribution after 60s isn\u2019t the best for you.  I think that in your case, changing the exact knob that you found, <code>DATA_DISTRIBUTION_FAILURE_REACTION_TIME</code>, to the 90th percentile of what a RAID rebuild takes could make sense.  In a sense, rather than having a person or automation invoke maintenance mode in reaction to a host failure, chainging the failure reaction time would automate that response, but inside of FDB.  If you\u2019re intentionally removing a machine, you should be excluding it first, and then if its failure is noticed or not when it\u2019s finally removed shouldn\u2019t matter.  This is assuming that in your specific situation, you can RAID rebuild your way out of most failures.</p>\n<p>However, there is a tradeoff.  When you bring your dead machine back online, and the storage servers rejoin the cluster, they begin pulling all the mutations that they missed from the transaction logs so that they can catch up.  This means that transaction logs are required to hold all mutations destined to an offline storage server until it comes back online.  Data Distribution trying to heal the storage server failure by copying the data to a new machine doesn\u2019t only restore the desired replication factor, it also frees the transaction logs from having to keep the mutation log for the failed, and now unnecessary storage server.  Whatever you end up setting <code>DATA_DISTRIBUTION_FAILURE_REACTION_TIME</code> to, you also need to make sure that your TLogs can buffer the incoming writes for that amount of time plus the time it will take to do the full data copy between storage servers.  We discussed this some on <a href=\"https://forums.foundationdb.org/t/quick-question-on-tlog-disk-space-for-large-clusters/1962\" class=\"inline-onebox\">Quick question on tlog disk space for large clusters</a>, and I\u2019ll assume that math is still roughly valid.</p>\n<p>If you do have a permanent machine failure and add a new machine to the cluster to replace the now forever gone one, do be aware that disks will on average get more full for a bit before starting to decline in space.  Data distribution does not currently do a great job in deciding what teams of servers to build, and will do a larger data shuffling between servers than the minimum necessary to replace the failed machine.  In the next major release, there will be a <code>failed</code> parameter that you can add to exclude to have FDB drop the queued mutations in the transaction log for an excluded machine that you know is never coming back before the data distribution finishes.</p>\n<p>And lastly, to cover some of your specific questions:</p>\n<p>I think data redistribution as a reaction to a failure is embraced by most people because they fall into one or more of three categories:</p>\n<ol>\n<li>They run larger clusters, where the free space reserve that\u2019s needed for a failure is less than 50%.</li>\n<li>They run on ephemeral or un-RAID\u2019d disks, where there\u2019s no strong belief that a machine that died will reappear after a minute with its data intact.</li>\n<li>They have smaller disks for tlogs, and thus can\u2019t buffer as much data during storage server failures.</li>\n</ol>\n<p>Your case sounds somewhat unique that you\u2019re planning for small clusters on very reliable disks, and thus there\u2019s fun quirks to examine about that setup as a result. <img src=\"https://emoji.discourse-cdn.com/twitter/slight_smile.png?v=9\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\"></p>\n<h3>Storage server recruitment</h3>\n<p>The code agrees with your fears.  If you lose both storage servers in one datahall, but not the transaction log, then FDB will try to recruit storage servers on the transaction log processes.  This will probably murder your cluster.</p>\n<p>Specifically, the loss of a datahall will cause all teams to appear unhealthy.  In the <a href=\"https://github.com/apple/foundationdb/blob/a234e4693bc6af0b053024f37402874f199352ed/fdbserver/DataDistribution.actor.cpp#L3983\">data distribution code</a>, this will cause us to flag our request for storage servers as a critical recruitment.  On the <a href=\"https://github.com/apple/foundationdb/blob/291b6c3a53a1e1092d51f27400f587a9db3da196/fdbserver/ClusterController.actor.cpp#L277\">cluster controller side</a> answering that request, we then consider any alive stateful process.  There\u2019s also\u2026 no knob to toggle to avoid this.  Uniquely in this situation, a <code>DDRecruitingEmergency</code> trace event will be logged, that you could use as a paging event.  Please file an issue if you\u2019d like a knob to be added to make critical storage recruitments to not be treated as critical.</p>\n<p>It looks like <code>fdbcli&gt; datadistribution off</code> will give you an emergency out in this situation while you prepare other mitigations, but note the warning below about continuous backup.  The proper solution here is what you already mentioned: to use <code>fdbcli&gt; maintenance</code>. Maintenance mode will mark the failed zones as healthy, and keep them that way for a specified amount of time, but you\u2019ll need to know the exact zoneID(s) that were affected.  This <em>should</em> undo any effects of having recruited a storage server on a transaction log, as those storage servers will now be viewed as undesireable as the failed storage teams will become healthy again.</p>\n<h3>Continuous backup</h3>\n<p>The overhead of continuous backup is that it doubles the writes done to the cluster.  Every key and value is written once as the kv pair, and once as a block of mutations into a subspace in <code>\\xff\\x02</code> that holds the backup data waiting to be read by backup or DR agents.  These <code>\\xff\\x02</code> keys also get written to the storage servers responsible for shards in that range, so this is a tax paid by all TLogs, and some storage servers.  If your backup falls behind, or your S3-like store is unavailable, then mutations will accumulate in the mutation stream subspace, which will show up as an increasing amount of space used by storage servers and status will show your backup lag as increasing.</p>\n<p>The mutations for backup are batched together, so it\u2019s not quite a 2x overhead, but it\u2019s a reasonable approximation.  The commit version/1000000 is \u201chashed\u201d into 256 buckets to provide somewhat of an even load distribution over the keyspace.  As we\u2019ve discovered in running backup for some time, backup creates a lot of data distribution churn, as it dumps writes into a bucket for 1s, and then some seconds later, a backup agent clears the data after it consumed it.  This puts a decent amount of pressure on data distribution to do splits and merges, which normally is fine.</p>\n<p>Now, an important aspect of <code>three_datahall_mode</code> that we haven\u2019t discussed yet, is that when one datahall fails (including TLogs in this case), other data movement (ie. splits and merges) won\u2019t be allowed for any current shard, because there are no longer any healthy teams to move data into.  When combined with backup, this means that losing a datahall can mean that backup will start to hotspot a shard, and data distribution won\u2019t be able to split to save you.  Because this shows up as a high storage queue or the storage server failing to keep up in applying versions, ratekeeper will limit based on this.  This has bitten us in the past when trying to disable data distribution for causing other issues.</p>\n<p>Also be aware that there are incoming changes to how backup is implemented to solve a good number of these issues.  <a class=\"mention\" href=\"/u/jzhou\">@jzhou</a> is implementing a version of backup, to be included in the next release, that reuses the mechanisms of how mutations are streamed in multi-region setups to make backup not have a 2x write bandwidth tax.  Backup agents in that model become FDB processes that tail the mutation stream directly from the transaction logs, which means less overhead all around.</p>\n<hr>\n<p>That was a lot, and I might have missed something, so if there was a question you had that I missed above, please quote it, and I\u2019ll get back to you on that also. <img src=\"https://emoji.discourse-cdn.com/twitter/slight_smile.png?v=9\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\"></p>",
        "post_number": 3,
        "post_type": 1,
        "posts_count": 7,
        "updated_at": "2020-03-18T05:42:22.965Z",
        "reply_count": 1,
        "reply_to_post_number": 1,
        "quote_count": 0,
        "incoming_link_count": 14,
        "reads": 37,
        "readers_count": 36,
        "score": 97.4,
        "yours": false,
        "topic_id": 2010,
        "topic_slug": "questions-regarding-maintenance-for-multiple-storage-oriented-machines-in-a-data-hall",
        "display_username": "Alex Miller",
        "primary_group_name": null,
        "flair_name": null,
        "flair_url": null,
        "flair_bg_color": null,
        "flair_color": null,
        "flair_group_id": null,
        "badges_granted": [],
        "version": 2,
        "can_edit": false,
        "can_delete": false,
        "can_recover": false,
        "can_see_hidden_post": false,
        "can_wiki": false,
        "link_counts": [
          {
            "url": "https://forums.foundationdb.org/t/quick-question-on-tlog-disk-space-for-large-clusters/1962",
            "internal": true,
            "reflection": false,
            "title": "Quick question on tlog disk space for large clusters",
            "clicks": 4
          },
          {
            "url": "https://github.com/apple/foundationdb/blob/291b6c3a53a1e1092d51f27400f587a9db3da196/fdbserver/ClusterController.actor.cpp#L277",
            "internal": false,
            "reflection": false,
            "title": "foundationdb/ClusterController.actor.cpp at 291b6c3a53a1e1092d51f27400f587a9db3da196 \u00b7 apple/foundationdb \u00b7 GitHub",
            "clicks": 2
          },
          {
            "url": "https://github.com/apple/foundationdb/blob/a234e4693bc6af0b053024f37402874f199352ed/fdbserver/DataDistribution.actor.cpp#L3983",
            "internal": false,
            "reflection": false,
            "title": "foundationdb/DataDistribution.actor.cpp at a234e4693bc6af0b053024f37402874f199352ed \u00b7 apple/foundationdb \u00b7 GitHub",
            "clicks": 0
          }
        ],
        "read": true,
        "user_title": null,
        "reply_to_user": {
          "id": 484,
          "username": "ksnavely",
          "name": "Kyle Snavely",
          "avatar_template": "/user_avatar/forums.foundationdb.org/ksnavely/{size}/483_2.png"
        },
        "bookmarked": false,
        "actions_summary": [
          {
            "id": 2,
            "count": 1
          }
        ],
        "moderator": false,
        "admin": false,
        "staff": false,
        "user_id": 13,
        "hidden": false,
        "trust_level": 4,
        "deleted_at": null,
        "user_deleted": false,
        "edit_reason": null,
        "can_view_edit_history": true,
        "wiki": false,
        "post_url": "/t/questions-regarding-maintenance-for-multiple-storage-oriented-machines-in-a-data-hall/2010/3",
        "can_accept_answer": false,
        "can_unaccept_answer": false,
        "accepted_answer": false,
        "topic_accepted_answer": null
      },
      {
        "id": 6471,
        "name": "Kyle Snavely",
        "username": "ksnavely",
        "avatar_template": "/user_avatar/forums.foundationdb.org/ksnavely/{size}/483_2.png",
        "created_at": "2020-03-18T15:02:29.159Z",
        "cooked": "<p>Alex, thank you for the detailed and thoughtful reply. We\u2019ll digest it and come back with any questions or comments.</p>\n<p>I\u2019ll clarify a little bit too for posterity that only the OS disks are in RAID1, all storage are just JBOD.</p>\n<p>We\u2019re still not made a final decision on bigger/smaller TLogs so we\u2019ll consider the implications you have outlined here.</p>\n<p>We are open to smaller and more storage oriented machines as well so we\u2019ll continue to ponder that, although the current setup has its advantages for us.</p>\n<p>Thank you!</p>",
        "post_number": 4,
        "post_type": 1,
        "posts_count": 7,
        "updated_at": "2020-03-18T15:02:29.159Z",
        "reply_count": 0,
        "reply_to_post_number": 3,
        "quote_count": 0,
        "incoming_link_count": 0,
        "reads": 29,
        "readers_count": 28,
        "score": 5.8,
        "yours": false,
        "topic_id": 2010,
        "topic_slug": "questions-regarding-maintenance-for-multiple-storage-oriented-machines-in-a-data-hall",
        "display_username": "Kyle Snavely",
        "primary_group_name": null,
        "flair_name": null,
        "flair_url": null,
        "flair_bg_color": null,
        "flair_color": null,
        "flair_group_id": null,
        "badges_granted": [],
        "version": 1,
        "can_edit": false,
        "can_delete": false,
        "can_recover": false,
        "can_see_hidden_post": false,
        "can_wiki": false,
        "read": true,
        "user_title": null,
        "reply_to_user": {
          "id": 13,
          "username": "alexmiller",
          "name": "Alex Miller",
          "avatar_template": "/user_avatar/forums.foundationdb.org/alexmiller/{size}/326_2.png"
        },
        "bookmarked": false,
        "actions_summary": [],
        "moderator": false,
        "admin": false,
        "staff": false,
        "user_id": 484,
        "hidden": false,
        "trust_level": 1,
        "deleted_at": null,
        "user_deleted": false,
        "edit_reason": null,
        "can_view_edit_history": true,
        "wiki": false,
        "post_url": "/t/questions-regarding-maintenance-for-multiple-storage-oriented-machines-in-a-data-hall/2010/4",
        "can_accept_answer": false,
        "can_unaccept_answer": false,
        "accepted_answer": false,
        "topic_accepted_answer": null
      },
      {
        "id": 6474,
        "name": "Kyle Snavely",
        "username": "ksnavely",
        "avatar_template": "/user_avatar/forums.foundationdb.org/ksnavely/{size}/483_2.png",
        "created_at": "2020-03-19T21:47:17.653Z",
        "cooked": "<p>Quick question: we can set the zone ids to the data halls in order to use maintenance mode correct? That\u2019s not verboten when running with data halls?</p>",
        "post_number": 5,
        "post_type": 1,
        "posts_count": 7,
        "updated_at": "2020-03-19T21:47:17.653Z",
        "reply_count": 1,
        "reply_to_post_number": null,
        "quote_count": 0,
        "incoming_link_count": 2,
        "reads": 27,
        "readers_count": 26,
        "score": 20.4,
        "yours": false,
        "topic_id": 2010,
        "topic_slug": "questions-regarding-maintenance-for-multiple-storage-oriented-machines-in-a-data-hall",
        "display_username": "Kyle Snavely",
        "primary_group_name": null,
        "flair_name": null,
        "flair_url": null,
        "flair_bg_color": null,
        "flair_color": null,
        "flair_group_id": null,
        "badges_granted": [],
        "version": 1,
        "can_edit": false,
        "can_delete": false,
        "can_recover": false,
        "can_see_hidden_post": false,
        "can_wiki": false,
        "read": true,
        "user_title": null,
        "bookmarked": false,
        "actions_summary": [],
        "moderator": false,
        "admin": false,
        "staff": false,
        "user_id": 484,
        "hidden": false,
        "trust_level": 1,
        "deleted_at": null,
        "user_deleted": false,
        "edit_reason": null,
        "can_view_edit_history": true,
        "wiki": false,
        "post_url": "/t/questions-regarding-maintenance-for-multiple-storage-oriented-machines-in-a-data-hall/2010/5",
        "can_accept_answer": false,
        "can_unaccept_answer": false,
        "accepted_answer": false,
        "topic_accepted_answer": null
      },
      {
        "id": 6475,
        "name": "Alex Miller",
        "username": "alexmiller",
        "avatar_template": "/user_avatar/forums.foundationdb.org/alexmiller/{size}/326_2.png",
        "created_at": "2020-03-19T21:58:16.179Z",
        "cooked": "<p>ZoneID and Data Hall are two different components of locality, with ZoneID being hierarchically nested within Data Hall.  maintenance mode operates on ZoneIDs, so if you wish to put a data hall into maintenance mode, you\u2019ll need to put each individual zoneID that\u2019s in that data hall into maintenance mode.</p>\n<p>If you set zoneid == datahall, then your three_datahall_mode cluster will break, because the TLog policy for three datahall mode is \u201cIn each of two different data halls, give me two different zoneids\u201d.  So you\u2019ll need at least 2 zoneIDs per datahall.  Be careful that you have enough TLog processes such that you can survive the loss of one datahall and one machine at the same time, and still be able to satisfy the TLog recruitment policy.</p>",
        "post_number": 6,
        "post_type": 1,
        "posts_count": 7,
        "updated_at": "2020-03-19T21:58:16.179Z",
        "reply_count": 1,
        "reply_to_post_number": 5,
        "quote_count": 0,
        "incoming_link_count": 18,
        "reads": 26,
        "readers_count": 25,
        "score": 100.2,
        "yours": false,
        "topic_id": 2010,
        "topic_slug": "questions-regarding-maintenance-for-multiple-storage-oriented-machines-in-a-data-hall",
        "display_username": "Alex Miller",
        "primary_group_name": null,
        "flair_name": null,
        "flair_url": null,
        "flair_bg_color": null,
        "flair_color": null,
        "flair_group_id": null,
        "badges_granted": [],
        "version": 1,
        "can_edit": false,
        "can_delete": false,
        "can_recover": false,
        "can_see_hidden_post": false,
        "can_wiki": false,
        "read": true,
        "user_title": null,
        "reply_to_user": {
          "id": 484,
          "username": "ksnavely",
          "name": "Kyle Snavely",
          "avatar_template": "/user_avatar/forums.foundationdb.org/ksnavely/{size}/483_2.png"
        },
        "bookmarked": false,
        "actions_summary": [],
        "moderator": false,
        "admin": false,
        "staff": false,
        "user_id": 13,
        "hidden": false,
        "trust_level": 4,
        "deleted_at": null,
        "user_deleted": false,
        "edit_reason": null,
        "can_view_edit_history": true,
        "wiki": false,
        "post_url": "/t/questions-regarding-maintenance-for-multiple-storage-oriented-machines-in-a-data-hall/2010/6",
        "can_accept_answer": false,
        "can_unaccept_answer": false,
        "accepted_answer": false,
        "topic_accepted_answer": null
      },
      {
        "id": 6476,
        "name": "Kyle Snavely",
        "username": "ksnavely",
        "avatar_template": "/user_avatar/forums.foundationdb.org/ksnavely/{size}/483_2.png",
        "created_at": "2020-03-19T22:03:23.897Z",
        "cooked": "<p>OK great, thanks Alex, yeah it was smelling fishy to me to use a hall for the zone id. We run four tlogs across two machines per AZ, in three AZs, so we can survive that failure mode and be available.</p>\n<p>EDIT: Alex points out to me that because the zone ids map to machines, what I say above isn\u2019t really the clean case I described, but is a bit more messy e.g. tlogs being recruited on storage-oriented machines in the estate.</p>",
        "post_number": 7,
        "post_type": 1,
        "posts_count": 7,
        "updated_at": "2020-03-19T22:09:57.754Z",
        "reply_count": 0,
        "reply_to_post_number": 6,
        "quote_count": 0,
        "incoming_link_count": 2,
        "reads": 23,
        "readers_count": 22,
        "score": 14.6,
        "yours": false,
        "topic_id": 2010,
        "topic_slug": "questions-regarding-maintenance-for-multiple-storage-oriented-machines-in-a-data-hall",
        "display_username": "Kyle Snavely",
        "primary_group_name": null,
        "flair_name": null,
        "flair_url": null,
        "flair_bg_color": null,
        "flair_color": null,
        "flair_group_id": null,
        "badges_granted": [],
        "version": 2,
        "can_edit": false,
        "can_delete": false,
        "can_recover": false,
        "can_see_hidden_post": false,
        "can_wiki": false,
        "read": true,
        "user_title": null,
        "reply_to_user": {
          "id": 13,
          "username": "alexmiller",
          "name": "Alex Miller",
          "avatar_template": "/user_avatar/forums.foundationdb.org/alexmiller/{size}/326_2.png"
        },
        "bookmarked": false,
        "actions_summary": [],
        "moderator": false,
        "admin": false,
        "staff": false,
        "user_id": 484,
        "hidden": false,
        "trust_level": 1,
        "deleted_at": null,
        "user_deleted": false,
        "edit_reason": null,
        "can_view_edit_history": true,
        "wiki": false,
        "post_url": "/t/questions-regarding-maintenance-for-multiple-storage-oriented-machines-in-a-data-hall/2010/7",
        "can_accept_answer": false,
        "can_unaccept_answer": false,
        "accepted_answer": false,
        "topic_accepted_answer": null
      }
    ],
    "stream": [
      6465,
      6466,
      6468,
      6471,
      6474,
      6475,
      6476
    ]
  },
  "timeline_lookup": [
    [
      1,
      2044
    ],
    [
      4,
      2043
    ],
    [
      5,
      2042
    ]
  ],
  "suggested_topics": [],
  "tags": [],
  "tags_descriptions": {},
  "fancy_title": "Questions regarding maintenance for multiple storage-oriented machines in a data hall",
  "id": 2010,
  "title": "Questions regarding maintenance for multiple storage-oriented machines in a data hall",
  "posts_count": 7,
  "created_at": "2020-03-17T19:48:25.801Z",
  "views": 1217,
  "reply_count": 4,
  "like_count": 1,
  "last_posted_at": "2020-03-19T22:03:23.897Z",
  "visible": true,
  "closed": false,
  "archived": false,
  "has_summary": false,
  "archetype": "regular",
  "slug": "questions-regarding-maintenance-for-multiple-storage-oriented-machines-in-a-data-hall",
  "category_id": 7,
  "word_count": 2714,
  "deleted_at": null,
  "user_id": 484,
  "featured_link": null,
  "pinned_globally": false,
  "pinned_at": null,
  "pinned_until": null,
  "image_url": null,
  "slow_mode_seconds": 0,
  "draft": null,
  "draft_key": "topic_2010",
  "draft_sequence": null,
  "unpinned": null,
  "pinned": false,
  "current_post_number": 1,
  "highest_post_number": 7,
  "deleted_by": null,
  "actions_summary": [
    {
      "id": 4,
      "count": 0,
      "hidden": false,
      "can_act": false
    },
    {
      "id": 8,
      "count": 0,
      "hidden": false,
      "can_act": false
    },
    {
      "id": 10,
      "count": 0,
      "hidden": false,
      "can_act": false
    },
    {
      "id": 7,
      "count": 0,
      "hidden": false,
      "can_act": false
    }
  ],
  "chunk_size": 20,
  "bookmarked": false,
  "topic_timer": null,
  "message_bus_last_id": 0,
  "participant_count": 2,
  "show_read_indicator": false,
  "thumbnails": null,
  "slow_mode_enabled_until": null,
  "tags_disable_ads": false,
  "related_topics": [
    {
      "fancy_title": "Storage node failure test",
      "id": 2385,
      "title": "Storage node failure test",
      "slug": "storage-node-failure-test",
      "posts_count": 10,
      "reply_count": 4,
      "highest_post_number": 10,
      "image_url": "https://global.discourse-cdn.com/foundationdb/optimized/1X/4102d40bd87b8652cec4b589fde3adc206780acc_2_1024x435.jpeg",
      "created_at": "2020-10-11T19:45:24.831Z",
      "last_posted_at": "2020-11-05T16:27:46.292Z",
      "bumped": true,
      "bumped_at": "2020-11-05T16:27:46.292Z",
      "archetype": "regular",
      "unseen": false,
      "pinned": false,
      "unpinned": null,
      "visible": true,
      "closed": false,
      "archived": false,
      "bookmarked": null,
      "liked": null,
      "tags": [],
      "tags_descriptions": {},
      "like_count": 0,
      "views": 1081,
      "category_id": 17,
      "featured_link": null,
      "has_accepted_answer": false,
      "posters": [
        {
          "extras": "latest",
          "description": "Original Poster, Most Recent Poster",
          "user": {
            "id": 769,
            "username": "ajames",
            "name": "Alwin",
            "avatar_template": "https://avatars.discourse-cdn.com/v4/letter/a/9de0a6/{size}.png",
            "trust_level": 2
          }
        },
        {
          "extras": null,
          "description": "Frequent Poster",
          "user": {
            "id": 12,
            "username": "ajbeamon",
            "name": "A.J. Beamon",
            "avatar_template": "/user_avatar/forums.foundationdb.org/ajbeamon/{size}/13_2.png",
            "admin": true,
            "trust_level": 4
          }
        }
      ]
    },
    {
      "fancy_title": "6.0.18 Reporting incorrect Fault Tolerance via fdbcli with triple redundancy mode?",
      "id": 1282,
      "title": "6.0.18 Reporting incorrect Fault Tolerance via fdbcli with triple redundancy mode?",
      "slug": "6-0-18-reporting-incorrect-fault-tolerance-via-fdbcli-with-triple-redundancy-mode",
      "posts_count": 15,
      "reply_count": 8,
      "highest_post_number": 16,
      "image_url": null,
      "created_at": "2019-04-04T19:04:42.341Z",
      "last_posted_at": "2019-04-06T00:41:42.940Z",
      "bumped": true,
      "bumped_at": "2019-04-06T00:41:42.940Z",
      "archetype": "regular",
      "unseen": false,
      "pinned": false,
      "unpinned": null,
      "visible": true,
      "closed": false,
      "archived": false,
      "bookmarked": null,
      "liked": null,
      "tags": [],
      "tags_descriptions": {},
      "like_count": 2,
      "views": 1976,
      "category_id": 7,
      "featured_link": null,
      "has_accepted_answer": false,
      "posters": [
        {
          "extras": null,
          "description": "Original Poster",
          "user": {
            "id": 490,
            "username": "rjenkins",
            "name": "Ray Jenkins",
            "avatar_template": "/user_avatar/forums.foundationdb.org/rjenkins/{size}/487_2.png",
            "trust_level": 2
          }
        },
        {
          "extras": null,
          "description": "Frequent Poster",
          "user": {
            "id": 12,
            "username": "ajbeamon",
            "name": "A.J. Beamon",
            "avatar_template": "/user_avatar/forums.foundationdb.org/ajbeamon/{size}/13_2.png",
            "admin": true,
            "trust_level": 4
          }
        },
        {
          "extras": null,
          "description": "Frequent Poster",
          "user": {
            "id": 13,
            "username": "alexmiller",
            "name": "Alex Miller",
            "avatar_template": "/user_avatar/forums.foundationdb.org/alexmiller/{size}/326_2.png",
            "trust_level": 4
          }
        },
        {
          "extras": null,
          "description": "Frequent Poster",
          "user": {
            "id": 81,
            "username": "ryanworl",
            "name": "Ryan Worl",
            "avatar_template": "/user_avatar/forums.foundationdb.org/ryanworl/{size}/440_2.png",
            "trust_level": 3
          }
        },
        {
          "extras": "latest",
          "description": "Most Recent Poster",
          "user": {
            "id": 54,
            "username": "Evan",
            "name": "Evan Tschannen",
            "avatar_template": "/user_avatar/forums.foundationdb.org/evan/{size}/104_2.png",
            "moderator": true,
            "trust_level": 1
          }
        }
      ]
    },
    {
      "fancy_title": "Storage server running out of space",
      "id": 1655,
      "title": "Storage server running out of space",
      "slug": "storage-server-running-out-of-space",
      "posts_count": 17,
      "reply_count": 14,
      "highest_post_number": 17,
      "image_url": null,
      "created_at": "2019-09-28T02:44:46.227Z",
      "last_posted_at": "2019-10-02T20:48:03.731Z",
      "bumped": true,
      "bumped_at": "2019-10-02T20:48:03.731Z",
      "archetype": "regular",
      "unseen": false,
      "pinned": false,
      "unpinned": null,
      "visible": true,
      "closed": false,
      "archived": false,
      "bookmarked": null,
      "liked": null,
      "tags": [],
      "tags_descriptions": {},
      "like_count": 3,
      "views": 4053,
      "category_id": 7,
      "featured_link": null,
      "has_accepted_answer": false,
      "posters": [
        {
          "extras": null,
          "description": "Original Poster",
          "user": {
            "id": 311,
            "username": "ThomasJ",
            "name": "Thomas Johson",
            "avatar_template": "https://avatars.discourse-cdn.com/v4/letter/t/6f9a4e/{size}.png",
            "trust_level": 2
          }
        },
        {
          "extras": null,
          "description": "Frequent Poster",
          "user": {
            "id": 13,
            "username": "alexmiller",
            "name": "Alex Miller",
            "avatar_template": "/user_avatar/forums.foundationdb.org/alexmiller/{size}/326_2.png",
            "trust_level": 4
          }
        },
        {
          "extras": null,
          "description": "Frequent Poster",
          "user": {
            "id": 612,
            "username": "fzhjon",
            "name": "Jon Fu",
            "avatar_template": "https://avatars.discourse-cdn.com/v4/letter/f/9d8465/{size}.png",
            "trust_level": 1
          }
        },
        {
          "extras": "latest",
          "description": "Most Recent Poster",
          "user": {
            "id": 12,
            "username": "ajbeamon",
            "name": "A.J. Beamon",
            "avatar_template": "/user_avatar/forums.foundationdb.org/ajbeamon/{size}/13_2.png",
            "admin": true,
            "trust_level": 4
          }
        }
      ]
    },
    {
      "fancy_title": "WARNING: A single process is both a transaction log and a storage server",
      "id": 1580,
      "title": "WARNING: A single process is both a transaction log and a storage server",
      "slug": "warning-a-single-process-is-both-a-transaction-log-and-a-storage-server",
      "posts_count": 17,
      "reply_count": 14,
      "highest_post_number": 17,
      "image_url": null,
      "created_at": "2019-08-11T17:20:33.378Z",
      "last_posted_at": "2019-08-13T20:43:59.991Z",
      "bumped": true,
      "bumped_at": "2019-08-13T20:43:59.991Z",
      "archetype": "regular",
      "unseen": false,
      "pinned": false,
      "unpinned": null,
      "visible": true,
      "closed": false,
      "archived": false,
      "bookmarked": null,
      "liked": null,
      "tags": [],
      "tags_descriptions": {},
      "like_count": 6,
      "views": 1783,
      "category_id": 7,
      "featured_link": null,
      "has_accepted_answer": false,
      "posters": [
        {
          "extras": null,
          "description": "Original Poster",
          "user": {
            "id": 311,
            "username": "ThomasJ",
            "name": "Thomas Johson",
            "avatar_template": "https://avatars.discourse-cdn.com/v4/letter/t/6f9a4e/{size}.png",
            "trust_level": 2
          }
        },
        {
          "extras": null,
          "description": "Frequent Poster",
          "user": {
            "id": 15,
            "username": "markus.pilman",
            "name": "Markus Pilman",
            "avatar_template": "/user_avatar/forums.foundationdb.org/markus.pilman/{size}/379_2.png",
            "admin": true,
            "trust_level": 4
          }
        },
        {
          "extras": "latest",
          "description": "Most Recent Poster",
          "user": {
            "id": 12,
            "username": "ajbeamon",
            "name": "A.J. Beamon",
            "avatar_template": "/user_avatar/forums.foundationdb.org/ajbeamon/{size}/13_2.png",
            "admin": true,
            "trust_level": 4
          }
        }
      ]
    },
    {
      "fancy_title": "Production optimizations",
      "id": 601,
      "title": "Production optimizations",
      "slug": "production-optimizations",
      "posts_count": 21,
      "reply_count": 14,
      "highest_post_number": 21,
      "image_url": null,
      "created_at": "2018-07-30T21:18:56.894Z",
      "last_posted_at": "2018-08-15T04:47:23.743Z",
      "bumped": true,
      "bumped_at": "2018-08-15T04:47:23.743Z",
      "archetype": "regular",
      "unseen": false,
      "pinned": false,
      "unpinned": null,
      "visible": true,
      "closed": false,
      "archived": false,
      "bookmarked": null,
      "liked": null,
      "tags": [],
      "tags_descriptions": {},
      "like_count": 6,
      "views": 6473,
      "category_id": 7,
      "featured_link": null,
      "has_accepted_answer": false,
      "posters": [
        {
          "extras": "latest",
          "description": "Original Poster, Most Recent Poster",
          "user": {
            "id": 311,
            "username": "ThomasJ",
            "name": "Thomas Johson",
            "avatar_template": "https://avatars.discourse-cdn.com/v4/letter/t/6f9a4e/{size}.png",
            "trust_level": 2
          }
        },
        {
          "extras": null,
          "description": "Frequent Poster",
          "user": {
            "id": 81,
            "username": "ryanworl",
            "name": "Ryan Worl",
            "avatar_template": "/user_avatar/forums.foundationdb.org/ryanworl/{size}/440_2.png",
            "trust_level": 3
          }
        },
        {
          "extras": null,
          "description": "Frequent Poster",
          "user": {
            "id": 13,
            "username": "alexmiller",
            "name": "Alex Miller",
            "avatar_template": "/user_avatar/forums.foundationdb.org/alexmiller/{size}/326_2.png",
            "trust_level": 4
          }
        },
        {
          "extras": null,
          "description": "Frequent Poster",
          "user": {
            "id": 255,
            "username": "aqua",
            "name": "Matt Lohier",
            "avatar_template": "https://avatars.discourse-cdn.com/v4/letter/a/b9bd4f/{size}.png",
            "trust_level": 1
          }
        }
      ]
    }
  ],
  "summarizable": false,
  "can_vote": false,
  "vote_count": 0,
  "user_voted": false,
  "discourse_zendesk_plugin_zendesk_id": null,
  "discourse_zendesk_plugin_zendesk_url": "https://your-url.zendesk.com/agent/tickets/",
  "details": {
    "can_edit": false,
    "notification_level": 1,
    "participants": [
      {
        "id": 484,
        "username": "ksnavely",
        "name": "Kyle Snavely",
        "avatar_template": "/user_avatar/forums.foundationdb.org/ksnavely/{size}/483_2.png",
        "post_count": 5,
        "primary_group_name": null,
        "flair_name": null,
        "flair_url": null,
        "flair_color": null,
        "flair_bg_color": null,
        "flair_group_id": null,
        "trust_level": 1
      },
      {
        "id": 13,
        "username": "alexmiller",
        "name": "Alex Miller",
        "avatar_template": "/user_avatar/forums.foundationdb.org/alexmiller/{size}/326_2.png",
        "post_count": 2,
        "primary_group_name": null,
        "flair_name": null,
        "flair_url": null,
        "flair_color": null,
        "flair_bg_color": null,
        "flair_group_id": null,
        "trust_level": 4
      }
    ],
    "created_by": {
      "id": 484,
      "username": "ksnavely",
      "name": "Kyle Snavely",
      "avatar_template": "/user_avatar/forums.foundationdb.org/ksnavely/{size}/483_2.png"
    },
    "last_poster": {
      "id": 484,
      "username": "ksnavely",
      "name": "Kyle Snavely",
      "avatar_template": "/user_avatar/forums.foundationdb.org/ksnavely/{size}/483_2.png"
    },
    "links": [
      {
        "url": "https://forums.foundationdb.org/t/quick-question-on-tlog-disk-space-for-large-clusters/1962",
        "title": "Quick question on tlog disk space for large clusters",
        "internal": true,
        "attachment": false,
        "reflection": false,
        "clicks": 4,
        "user_id": 13,
        "domain": "forums.foundationdb.org",
        "root_domain": "foundationdb.org"
      },
      {
        "url": "https://github.com/apple/foundationdb/blob/291b6c3a53a1e1092d51f27400f587a9db3da196/fdbserver/ClusterController.actor.cpp#L277",
        "title": "foundationdb/ClusterController.actor.cpp at 291b6c3a53a1e1092d51f27400f587a9db3da196 \u00b7 apple/foundationdb \u00b7 GitHub",
        "internal": false,
        "attachment": false,
        "reflection": false,
        "clicks": 2,
        "user_id": 13,
        "domain": "github.com",
        "root_domain": "github.com"
      }
    ]
  },
  "bookmarks": []
}